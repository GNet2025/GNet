{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e424002f-89af-4a88-ae34-10cb60f4aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from ConvBN1d import ConvBN\n",
    "from LinearBN import LinearBN\n",
    "from source import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126236b9-4f47-4d58-9941-65e1f63b4a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3601, 500), Test shape: (1320, 500)\n"
     ]
    }
   ],
   "source": [
    "def load_ucr(file):\n",
    "    data = np.loadtxt(file)\n",
    "    X = data[:, 1:]\n",
    "    y = data[:, 0]\n",
    "    y = np.where(y == 1, 1, 0)  # convert labels to 0/1\n",
    "    return X, y\n",
    "\n",
    "# Adjust file paths to your local files\n",
    "X_train, y_train = load_ucr(\"../FordA_TRAIN.txt\")\n",
    "X_test, y_test = load_ucr(\"../FordA_TEST.txt\")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73eb1645-2bda-46d3-8a2f-ccdb954f7136",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6aefdea-25d0-456b-b3a7-4530cac9737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train_tensor.mean()\n",
    "std = X_train_tensor.std()\n",
    "X_train_tensor = (X_train_tensor - mean) / std\n",
    "X_test_tensor = (X_test_tensor - mean) / std\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71d57a4-c1a2-43ea-abde-58b4e1246a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanH(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(10.0)) \n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.tanh(self.alpha*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7935713b-32d7-4008-b872-e200bf0dcfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1_out = 16\n",
    "        self.conv1_size = 15\n",
    "        self.conv1_padding = 7\n",
    "\n",
    "\n",
    "        self.conv2_out = 16\n",
    "        self.conv2_size = 15\n",
    "        self.conv2_padding = 7\n",
    "\n",
    "        self.conv3_out = 25\n",
    "        self.conv3_size = 13\n",
    "        self.conv3_padding = 6\n",
    "\n",
    "        self.fc1_out = 2\n",
    "\n",
    "        self.q = 1e-6\n",
    "        self.bias_trick_par = nn.Parameter(torch.tensor(0.00005))\n",
    "\n",
    "        # First Convolutional Block\n",
    "\n",
    "        self.block1 = ConvBN(in_channels=1, out_channels=self.conv1_out, kernel_size=self.conv1_size, padding=self.conv1_padding, std = .05, bias_par_init=0.0015)\n",
    "        self.block2 = ConvBN(in_channels=self.conv1_out, out_channels=self.conv2_out, kernel_size=self.conv2_size, padding=self.conv2_padding, std = .05, bias_par_init=0.0015)\n",
    "        self.block3 = ConvBN(in_channels=self.conv2_out, out_channels=self.conv3_out, kernel_size=self.conv3_size, padding=self.conv3_padding, std = .05, bias_par_init=0.0015)\n",
    "               \n",
    "        \n",
    "        # torch.manual_seed(0)\n",
    "        self.w2 = nn.Parameter(torch.randn(self.conv3_out * (500//2//2//2), self.fc1_out))\n",
    "        nn.init.normal_(self.w2, mean=0.0, std=.05)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.tanh = TanH()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool1d(self.tanh(self.block1(x)), 2)\n",
    "        x = F.max_pool1d(self.tanh(self.block2(x)), 2)\n",
    "        x = F.max_pool1d(self.tanh(self.block3(x)), 2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # x = self.relu(self.block3(x))\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = x + self.bias_trick_par\n",
    "        x_norm = x / (x.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize input x\n",
    "        w2_norm = self.w2 / (self.w2.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize weights\n",
    "        x = torch.matmul(x_norm, w2_norm) # Matrix multiplication \n",
    "\n",
    "        # Return raw logits (no softmax here, CrossEntropyLoss handles it)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5583dac-102b-42ed-8bad-060ac3288b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.01711 accuracy: 0.6995 time: 0.77 seconds\n",
      "[epoch 2] loss: 0.00700 accuracy: 0.9056 time: 0.77 seconds\n",
      "[epoch 3] loss: 0.00603 accuracy: 0.9247 time: 0.77 seconds\n",
      "[epoch 4] loss: 0.00530 accuracy: 0.9306 time: 0.77 seconds\n",
      "[epoch 5] loss: 0.00458 accuracy: 0.9475 time: 0.77 seconds\n",
      "[epoch 6] loss: 0.00427 accuracy: 0.9478 time: 0.77 seconds\n",
      "[epoch 7] loss: 0.00422 accuracy: 0.9497 time: 0.77 seconds\n",
      "[epoch 8] loss: 0.00364 accuracy: 0.9595 time: 0.77 seconds\n",
      "[epoch 9] loss: 0.00314 accuracy: 0.9664 time: 0.77 seconds\n",
      "[epoch 10] loss: 0.00309 accuracy: 0.9656 time: 0.77 seconds\n",
      "[epoch 11] loss: 0.00292 accuracy: 0.9686 time: 0.77 seconds\n",
      "[epoch 12] loss: 0.00269 accuracy: 0.9722 time: 0.77 seconds\n",
      "[epoch 13] loss: 0.00259 accuracy: 0.9745 time: 0.77 seconds\n",
      "[epoch 14] loss: 0.00236 accuracy: 0.9770 time: 0.79 seconds\n",
      "[epoch 15] loss: 0.00218 accuracy: 0.9817 time: 0.77 seconds\n",
      "[epoch 16] loss: 0.00207 accuracy: 0.9819 time: 0.78 seconds\n",
      "[epoch 17] loss: 0.00195 accuracy: 0.9858 time: 0.76 seconds\n",
      "[epoch 18] loss: 0.00199 accuracy: 0.9833 time: 0.76 seconds\n",
      "[epoch 19] loss: 0.00170 accuracy: 0.9881 time: 0.80 seconds\n",
      "[epoch 20] loss: 0.00159 accuracy: 0.9900 time: 0.76 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time  # Import time module\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "training = True\n",
    "model = Network().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Trained 100 Epochs with lr=0.025, 50 epochs with 0.005 and 50 epochs with 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "if training:\n",
    "    model.train()\n",
    "    loss_hist, acc_hist = [], []    \n",
    "    \n",
    "    for epoch in range(20):\n",
    "        start_time = time.time()  # Record the start time of the epoch\n",
    "    \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        for data in train_loader:\n",
    "            batch, labels = data\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Compute training statistics\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "        avg_loss = running_loss / len(train_dataset)\n",
    "        avg_acc = correct / len(train_dataset)\n",
    "        loss_hist.append(avg_loss)\n",
    "        acc_hist.append(avg_acc)\n",
    "        \n",
    "    \n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.time() - start_time  # Calculate the time taken for this epoch\n",
    "    \n",
    "        print('[epoch %d] loss: %.5f accuracy: %.4f time: %.2f seconds' %\n",
    "              (epoch + 1, avg_loss, avg_acc, elapsed_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e391882c-356f-4a96-a307-4800714ee335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.00580, Test accuracy: 0.9288\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Get predictions and update the correct count\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute average loss and accuracy for the test set\n",
    "avg_test_loss = test_loss / len(test_dataset)\n",
    "avg_test_acc = correct_test / len(test_dataset)\n",
    "\n",
    "print(f\"Test loss: {avg_test_loss:.5f}, Test accuracy: {avg_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef7bcb8-b18c-4c03-b250-1122487e742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'FordA_GNet_Training.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffde7b2-e032-482b-a087-d192af609789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb42aeb-5d9d-4852-b5f9-41e2bbaa8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from ConvBN1d import ConvBN\n",
    "from LinearBN import LinearBN\n",
    "from source import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0f73ef-c40f-4c66-88e8-d79ba92e1722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3601, 500), Test shape: (1320, 500)\n"
     ]
    }
   ],
   "source": [
    "def load_ucr(file):\n",
    "    data = np.loadtxt(file)\n",
    "    X = data[:, 1:]\n",
    "    y = data[:, 0]\n",
    "    y = np.where(y == 1, 1, 0)  # convert labels to 0/1\n",
    "    return X, y\n",
    "\n",
    "# Adjust file paths to your local files\n",
    "X_train, y_train = load_ucr(\"../FordA_TRAIN.txt\")\n",
    "X_test, y_test = load_ucr(\"../FordA_TEST.txt\")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e19080-8e31-4cd1-a971-148fa5b061eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8b0480-0365-4a55-ba08-275a4cde5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train_tensor.mean()\n",
    "std = X_train_tensor.std()\n",
    "X_train_tensor = (X_train_tensor - mean) / std\n",
    "X_test_tensor = (X_test_tensor - mean) / std\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f57619b-c5d6-45a7-b655-154f25f3e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LReLU, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(5.0)) \n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.alpha*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6604d6-f1f9-4f5a-93db-1911a80137da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1_out = 16\n",
    "        self.conv1_size = 15\n",
    "        self.conv1_padding = 7\n",
    "\n",
    "\n",
    "        self.conv2_out = 16\n",
    "        self.conv2_size = 15\n",
    "        self.conv2_padding = 7\n",
    "\n",
    "        self.conv3_out = 25\n",
    "        self.conv3_size = 13\n",
    "        self.conv3_padding = 6\n",
    "\n",
    "        self.fc1_out = 2\n",
    "\n",
    "        self.q = 1e-6\n",
    "        self.bias_trick_par = nn.Parameter(torch.tensor(0.00005))\n",
    "\n",
    "        # First Convolutional Block\n",
    "\n",
    "        self.block1 = ConvBN(in_channels=1, out_channels=self.conv1_out, kernel_size=self.conv1_size, padding=self.conv1_padding, std = .05, bias_par_init=0.0015)\n",
    "        self.block2 = ConvBN(in_channels=self.conv1_out, out_channels=self.conv2_out, kernel_size=self.conv2_size, padding=self.conv2_padding, std = .15, bias_par_init=0.0015)\n",
    "        self.block3 = ConvBN(in_channels=self.conv2_out, out_channels=self.conv3_out, kernel_size=self.conv3_size, padding=self.conv3_padding, std = .15, bias_par_init=0.0015)\n",
    "               \n",
    "        \n",
    "        # torch.manual_seed(0)\n",
    "        self.w2 = nn.Parameter(torch.randn(self.conv3_out * (500//2//2//2), self.fc1_out))\n",
    "        nn.init.normal_(self.w2, mean=0.0, std=.6)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.relu = LReLU()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool1d(self.relu(self.block1(x)), 2)\n",
    "        x = F.max_pool1d(self.relu(self.block2(x)), 2)\n",
    "        x = F.max_pool1d(self.relu(self.block3(x)), 2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # x = self.relu(self.block3(x))\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = x + self.bias_trick_par\n",
    "        x_norm = x / (x.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize input x\n",
    "        w2_norm = self.w2 / (self.w2.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize weights\n",
    "        x = torch.matmul(x_norm, w2_norm) # Matrix multiplication \n",
    "\n",
    "        # Return raw logits (no softmax here, CrossEntropyLoss handles it)\n",
    "        return x\n",
    "\n",
    "    def custom_round(self, n):\n",
    "        remainder = n % 1000\n",
    "        base = n - remainder\n",
    "        if remainder >= 101:\n",
    "            return base + 1000\n",
    "        elif remainder <= 100:\n",
    "            return base\n",
    "\n",
    "    @torch.no_grad()             # no autograd graph\n",
    "    def flip_sign_(self, tensor: torch.Tensor, percentage: float) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Flip the sign of a random subset of elements *in place*.\n",
    "    \n",
    "        Args:\n",
    "            tensor (torch.Tensor): Any shape, modified in place.\n",
    "            percentage (float): 0‒1 fraction of elements to flip.\n",
    "    \n",
    "        Returns:\n",
    "            torch.Tensor: The same tensor object (for chaining).\n",
    "        \"\"\"\n",
    "        if percentage <= 0.0:\n",
    "            return tensor\n",
    "        if percentage >= 1.0:\n",
    "            tensor.mul_(-1)\n",
    "            return tensor                    # all elements flipped\n",
    "    \n",
    "        numel = tensor.numel()\n",
    "        num_to_flip = int(numel * percentage)\n",
    "        if num_to_flip == 0:\n",
    "            return tensor\n",
    "    \n",
    "        flat = tensor.view(-1)               # view ↔ no copy\n",
    "        idx = torch.randint(0, numel, (num_to_flip,),\n",
    "                            device=flat.device)\n",
    "        flat[idx] *= -1                      # in-place sign change\n",
    "        return tensor\n",
    "\n",
    "    def init_hdc(self, ratio, seed, flip_perc=None):\n",
    "        if not isinstance(ratio, (tuple, int)):\n",
    "            raise TypeError(\"ratio must be a tuple of size 4 or and integer\")\n",
    "\n",
    "        elif isinstance(ratio, (int)):\n",
    "            ratio = (ratio, ratio, ratio, ratio)\n",
    "            \n",
    "        if not isinstance(seed, (tuple)):\n",
    "            raise TypeError(\"seed must be a tuple of size 4\")\n",
    "        \n",
    "        self.block1.init_hdc(ratio = ratio[0], seed = seed[0], flip_perc=flip_perc)\n",
    "        self.block2.init_hdc(ratio = ratio[1], seed = seed[1], flip_perc=flip_perc)\n",
    "        self.block3.init_hdc(ratio = ratio[2], seed = seed[2], flip_perc=flip_perc)\n",
    "                \n",
    "        self.n_last = self.w2.size(0)\n",
    "        self.nHDC_last = int(self.custom_round(ratio[3] * self.n_last)) if ratio[3]<1000 else int(ratio[3])\n",
    "        torch.manual_seed(seed[3])\n",
    "        self.g = (torch.randn(self.w2.size(0), self.nHDC_last, device=self.w2.device)).to(torch.half)\n",
    "        self.wg = torch.sign(torch.matmul(self.g.t(), self.w2.to(torch.half)))\n",
    "\n",
    "        if flip_perc is not None and flip_perc > 0.0:\n",
    "            self.flip_sign_(self.wg, flip_perc)\n",
    "\n",
    "\n",
    "    def hdc(self, x):\n",
    "        x = F.max_pool1d(self.relu(self.block1.hdc(x)), 2)\n",
    "        x = F.max_pool1d(self.relu(self.block2.hdc(x)), 2)\n",
    "        x = F.max_pool1d(self.relu(self.block3.hdc(x)), 2)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = x + self.bias_trick_par\n",
    "        x = torch.sign(torch.matmul(x.to(torch.half), self.g))\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def classification_layer(self, x):\n",
    "        x = x @ self.wg\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696512f5-24b0-4b98-8e3e-1165b30dd300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.utils.data import Subset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = Network().to(device)\n",
    "model.load_state_dict(torch.load('FordA_GNet_Training.pth', weights_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df8e6271-6353-47b1-a473-7c2b94dfa8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size per split: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:44<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.0, Avg Acc: 91.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:44<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.05, Avg Acc: 91.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:43<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.1, Avg Acc: 91.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:43<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.15000000000000002, Avg Acc: 90.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:43<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.2, Avg Acc: 89.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:44<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.25, Avg Acc: 88.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:43<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.30000000000000004, Avg Acc: 85.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:43<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.35000000000000003, Avg Acc: 80.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:43<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.4, Avg Acc: 74.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:43<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.45, Avg Acc: 67.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:44<00:00,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip Perc: 0.5, Avg Acc: 60.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(torch.half).to(device)\n",
    "model.eval()\n",
    "\n",
    "n_splits = 20\n",
    "subset_size = 500\n",
    "print(f\"Subset size per split: {subset_size}\")\n",
    "\n",
    "times = []\n",
    "num_workers = 2\n",
    "pin_memory = True\n",
    "\n",
    "flip_percs = np.arange(0.0, 0.51, 0.05)\n",
    "accuracies = np.zeros((len(flip_percs), n_splits))\n",
    "hyperdim = 15_000\n",
    "for i, perc in enumerate(flip_percs):\n",
    "    for split_idx in tqdm(range(n_splits)):\n",
    "        # Random sampling using split_idx as seed\n",
    "        np.random.seed(split_idx)\n",
    "        split_indices = np.random.choice(len(test_dataset), size=subset_size, replace=False)\n",
    "        split_subset = Subset(test_dataset, split_indices)\n",
    "        split_loader = torch.utils.data.DataLoader(split_subset, batch_size=15, shuffle=False)\n",
    "        \n",
    "        torch.manual_seed(split_idx+4)\n",
    "        random_seeds = tuple(torch.randint(0, 1000, (1,)).item() for _ in range(4))\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        model.init_hdc(hyperdim, random_seeds, perc)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        t0 = time.time()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in split_loader:\n",
    "                images, labels = images.cuda(non_blocking=True), labels.cuda(non_blocking=True)\n",
    "                output = model.hdc(images.to(torch.half))\n",
    "                output = model.classification_layer(output.to(torch.half))\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        t1 = time.time()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        dt = t1 - t0\n",
    "\n",
    "        accuracies[i, split_idx] = acc\n",
    "        times.append(dt)\n",
    "\n",
    "    print(f'Flip Perc: {perc}, Avg Acc: {np.mean(accuracies[i]):.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00d036d-9a52-4b6c-905b-ed5426811fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([91.32, 91.08, 91.3 , 90.82, 89.68, 88.27, 85.55, 80.78, 74.36,\n",
       "        67.28, 60.42]),\n",
       " array([1.67140659, 1.67140659, 1.51459566, 1.27420563, 1.39341308,\n",
       "        2.02215232, 2.83116584, 3.46635255, 3.36428298, 3.34986567,\n",
       "        3.56308855]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis=1), np.std(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03220a94-07b4-43c2-b2b7-c6e873707b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat('FordA_HDCGNet.mat',{'FordA_HDCGNet':accuracies})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974e645-d445-4d37-a7f0-ad35efa9965c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

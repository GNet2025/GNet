{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f33eed-fc2e-48c2-985a-380baa73efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets import load_classification\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "from ConvBN1d import ConvBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf97cd5b-4051-4b81-924f-ad012a252fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 3, 206) (2947, 3, 206)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset_name = 'WalkingSittingStanding' # Or 'Epilepsy' Or 'FordA'\n",
    "# Load dataset\n",
    "X_train, y_train, metadata = load_classification(dataset_name, return_metadata=True, split='train')\n",
    "X_test, y_test = load_classification(dataset_name, split='test')\n",
    "print(X_train.shape, X_test.shape)\n",
    "if X_train.shape[0] < 200:\n",
    "    train_size = int((X_train.shape[0] + X_test.shape[0]) * 3/4)\n",
    "    x, y = load_classification(dataset_name)\n",
    "    X_train, y_train = x[:train_size, :], y[:train_size]\n",
    "    X_test, y_test = x[train_size:, :], y[train_size:]\n",
    "\n",
    "# Flatten X if shape is (n_samples, 1, series_length) → (n_samples, series_length)\n",
    "input_channels = 1\n",
    "if X_train.ndim == 3:\n",
    "    input_channels = X_train.shape[1]\n",
    "    X_train = np.squeeze(X_train, axis=1) if input_channels == 1 else X_train\n",
    "    X_test = np.squeeze(X_test, axis=1) if input_channels == 1 else X_test\n",
    "\n",
    "seq_length = X_train.shape[-1]  # series length\n",
    "\n",
    "# Encode labels\n",
    "if y_train.dtype == object or isinstance(y_train[0], str):\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "\n",
    "# Standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, seq_length))\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e91b12-1516-4caa-84d2-aa427ac9d698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 3, 206), (2947, 3, 206))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ed5953-e5f0-4bdb-af8f-80cc9817edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- CNN ----\n",
    "if input_channels == 1:\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "else:\n",
    "    # Multichannel → keep original channels\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6456f8-c1d4-4e23-931d-4f312e0f6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LReLU, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(5.0)) \n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.alpha*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c581ad3b-f8e4-48ee-8755-0e7e99b6de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, inpu_channels, seq_length, num_classes):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1_out = 64\n",
    "        self.conv1_size = 11\n",
    "        self.conv1_padding = 5\n",
    "\n",
    "\n",
    "        self.conv2_out = 48\n",
    "        self.conv2_size = 7\n",
    "        self.conv2_padding = 3\n",
    "\n",
    "        self.conv3_out = 32\n",
    "        self.conv3_size = 3\n",
    "        self.conv3_padding = 1\n",
    "\n",
    "        self.fc1_out = num_classes\n",
    "\n",
    "        self.q = 1e-6\n",
    "        self.bias_trick_par = nn.Parameter(torch.tensor(0.00005))\n",
    "\n",
    "        # First Convolutional Block\n",
    "\n",
    "        self.block1 = ConvBN(in_channels=input_channels, out_channels=self.conv1_out, kernel_size=self.conv1_size, padding=self.conv1_padding, std = .05, bias_par_init=0.0015)\n",
    "        self.block2 = ConvBN(in_channels=self.conv1_out, out_channels=self.conv2_out, kernel_size=self.conv2_size, padding=self.conv2_padding, std = .15, bias_par_init=0.0015)\n",
    "               \n",
    "        \n",
    "        # torch.manual_seed(0)\n",
    "        self.w2 = nn.Parameter(torch.randn(self.conv2_out * (seq_length// 2 // 2), self.fc1_out))\n",
    "        nn.init.normal_(self.w2, mean=0.0, std=.6)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.relu = LReLU()\n",
    "\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.block1(x)))\n",
    "        x = self.pool(self.relu(self.block2(x)))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "    \n",
    "        x = x + self.bias_trick_par\n",
    "        x_norm = x / (x.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize input x\n",
    "        w2_norm = self.w2 / (self.w2.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize weights\n",
    "        x = torch.matmul(x_norm, w2_norm) # Matrix multiplication \n",
    "\n",
    "        # Return raw logits (no softmax here, CrossEntropyLoss handles it)\n",
    "        return x\n",
    "\n",
    "    def custom_round(self, n):\n",
    "        remainder = n % 1000\n",
    "        base = n - remainder\n",
    "        if remainder >= 101:\n",
    "            return base + 1000\n",
    "        elif remainder <= 100:\n",
    "            return base\n",
    "\n",
    "    @torch.no_grad()             # no autograd graph\n",
    "    def flip_sign_(self, tensor: torch.Tensor, percentage: float) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Flip the sign of a random subset of elements *in place*.\n",
    "    \n",
    "        Args:\n",
    "            tensor (torch.Tensor): Any shape, modified in place.\n",
    "            percentage (float): 0‒1 fraction of elements to flip.\n",
    "    \n",
    "        Returns:\n",
    "            torch.Tensor: The same tensor object (for chaining).\n",
    "        \"\"\"\n",
    "        if percentage <= 0.0:\n",
    "            return tensor\n",
    "        if percentage >= 1.0:\n",
    "            tensor.mul_(-1)\n",
    "            return tensor                    # all elements flipped\n",
    "    \n",
    "        numel = tensor.numel()\n",
    "        num_to_flip = int(numel * percentage)\n",
    "        if num_to_flip == 0:\n",
    "            return tensor\n",
    "    \n",
    "        flat = tensor.view(-1)               # view ↔ no copy\n",
    "        idx = torch.randint(0, numel, (num_to_flip,),\n",
    "                            device=flat.device)\n",
    "        flat[idx] *= -1                      # in-place sign change\n",
    "        return tensor\n",
    "\n",
    "    def init_hdc(self, ratio, seed, flip_perc=None):\n",
    "        if not isinstance(ratio, (tuple, int)):\n",
    "            raise TypeError(\"ratio must be a tuple of size 4 or and integer\")\n",
    "\n",
    "        elif isinstance(ratio, (int)):\n",
    "            ratio = (ratio, ratio, ratio, ratio)\n",
    "            \n",
    "        if not isinstance(seed, (tuple)):\n",
    "            raise TypeError(\"seed must be a tuple of size 4\")\n",
    "        \n",
    "        self.block1.init_hdc(ratio = ratio[0], seed = seed[0], flip_perc=flip_perc)\n",
    "        self.block2.init_hdc(ratio = ratio[1], seed = seed[1], flip_perc=flip_perc)\n",
    "                \n",
    "        self.n_last = self.w2.size(0)\n",
    "        self.nHDC_last = int(self.custom_round(ratio[2] * self.n_last)) if ratio[2]<1000 else int(ratio[2])\n",
    "        torch.manual_seed(seed[2])\n",
    "        self.g = (torch.randn(self.w2.size(0), self.nHDC_last, device=self.w2.device)).to(torch.half)\n",
    "        self.wg = torch.sign(torch.matmul(self.g.t(), self.w2.to(torch.half)))\n",
    "\n",
    "        if flip_perc is not None and flip_perc > 0.0:\n",
    "            self.flip_sign_(self.wg, flip_perc)\n",
    "\n",
    "\n",
    "    def hdc(self, x):\n",
    "        x = self.pool(self.relu(self.block1.hdc(x)))\n",
    "        x = self.pool(self.relu(self.block2.hdc(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = x + self.bias_trick_par\n",
    "        x = torch.sign(torch.matmul(x.to(torch.half), self.g))\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def classification_layer(self, x):\n",
    "        x = x @ self.wg\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12df9ee0-cf35-493a-a3d0-203b8a0f0aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = Network(input_channels, seq_length, num_classes).to(device)\n",
    "avg_test_acc = torch.load('avg_test_acc.pt', weights_only=True)\n",
    "model.load_state_dict(torch.load(f'{dataset_name}_GNet_Training_{avg_test_acc:.4f}.pth', weights_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6dc0e5a-e8c0-4d53-ad65-46480ef6dde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:20<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 85.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 84.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:20<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 83.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:20<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 80.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:20<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 77.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 69.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:20<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 56.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:20<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 47.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 42.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:20<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 39.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 15000, Block2: 15000, Classification Layer: 15000, Accuracy: 36.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(torch.half).to(device)\n",
    "model.eval()\n",
    "n_splits = 20\n",
    "split_size = len(test_dataset) // n_splits # 10000 // 20 = 500scales = np.arange(0.2, 1.21, 0.1)\n",
    "print(split_size)\n",
    "scales = np.arange(0.0, 0.51, 0.05)\n",
    "hyperdim = 15_000\n",
    "print(len(scales))\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=0, pin_memory=False)\n",
    "NHDC = np.zeros((len(scales), 3))\n",
    "accuracies = np.zeros((len(scales), n_splits)) \n",
    "num_workers = 0\n",
    "pin_memory = False\n",
    "for i, perc in enumerate(scales):\n",
    "    # print(ratio)\n",
    "    indices = list(range(len(test_dataset)))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(indices)  # or random.shuffle(indices)\n",
    "    for split_idx in tqdm(range(n_splits)):\n",
    "        start_idx = split_idx * split_size\n",
    "        end_idx = start_idx + split_size\n",
    "        split_indices = indices[start_idx:end_idx]\n",
    "        split_subset = Subset(test_dataset, split_indices)\n",
    "        split_loader = torch.utils.data.DataLoader(split_subset, batch_size=20, shuffle=False,\n",
    "                                                   num_workers=num_workers, pin_memory=pin_memory)\n",
    "        torch.manual_seed(split_idx+4)\n",
    "        random_seeds = tuple(torch.randint(0, 1000, (1,)).item() for _ in range(4))\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        model.init_hdc(hyperdim, random_seeds, perc)\n",
    "        # model.init_hdc(scale, random_seeds)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for images, labels in (split_loader):\n",
    "                images, labels = images.cuda(non_blocking=True), labels.cuda(non_blocking=True)\n",
    "                output = model.hdc(images.to(torch.half))\n",
    "                output = model.classification_layer(output.to(torch.half))\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        acc = 100 * correct / total\n",
    "    \n",
    "        accuracies[i, split_idx] = acc\n",
    "    \n",
    "        # print(f\"Split {split_idx+1}: accuracy = {acc:.2f}%, time = {dt:.2f} sec\")\n",
    "    print(f'Block1: {model.block1.nHDC}, Block2: {model.block2.nHDC}, Classification Layer: {model.nHDC_last}, Accuracy: {np.mean(accuracies[i]):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a4583d-f3df-40d3-a547-836584ab7ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85.91836735, 84.82993197, 83.23129252, 80.91836735, 77.58503401,\n",
       "       69.45578231, 56.19047619, 47.58503401, 42.78911565, 39.25170068,\n",
       "       36.8707483 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2aa557f-e501-45b4-8744-78ada57a3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat(f'{dataset_name}_HDCGNet.mat', {f'{dataset_name}_HDCGNet': accuracies})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62e964fc-3c0b-4593-94e3-197e69e8ec37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.61794305, 2.6002061 , 3.63977365, 4.08998578, 5.47809153,\n",
       "       6.49615342, 6.92208209, 4.97796989, 5.29957733, 5.63066448,\n",
       "       6.8183494 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38635fbf-061b-4da4-b94a-3e39b712a8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

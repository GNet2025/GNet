{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008281be-1e20-4ebb-bb0d-de9c9705c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.io import savemat, loadmat\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df702028-5f8e-47f7-a4cb-a4e9c468e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load CIFAR-10 into torch Tensors\n",
    "def load_dataset(path: str, device: torch.device):\n",
    "    ds_train = MNIST(path, train=True,  download=True)\n",
    "    ds_test  = MNIST(path, train=False, download=True)\n",
    "\n",
    "    # -- TRAIN --\n",
    "    X_train = (ds_train.data)        \\\n",
    "    .reshape(-1, 1 * 28 * 28)        \\\n",
    "    .to(device)                      \\\n",
    "    .long()                          # (N, 3072)\n",
    "    Y_train = ds_train.targets.to(device)\n",
    "\n",
    "    # -- TEST --\n",
    "    X_test  = (ds_test.data)         \\\n",
    "    .reshape(-1, 1 * 28 * 28)        \\\n",
    "    .to(device)                      \\\n",
    "    .long()                          # (N_test, 3072)\n",
    "    Y_test  = ds_test.targets.to(device)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "# 2. Build bipolar lookup table (torch version)\n",
    "def lookup_generate(dim: int, datatype: str, n_keys: int, device: torch.device):\n",
    "    if datatype != 'bipolar':\n",
    "        raise ValueError(\"Only 'bipolar' supported\")\n",
    "    tbl = torch.randint(0, 2, (n_keys, dim), device=device, dtype=torch.int8)\n",
    "    return tbl * 2 - 1  # map {0,1} → {-1,+1}\n",
    "\n",
    "# 3. Encode a batch of images into hypervectors\n",
    "@torch.no_grad()\n",
    "def encode_batch(X: torch.LongTensor, position_table: torch.Tensor, grayscale_table: torch.Tensor):\n",
    "    \"\"\"\n",
    "    X:               (N,3072) int tensor in [0..255]\n",
    "    position_table:  (3072, dim)\n",
    "    grayscale_table: (256,  dim)\n",
    "    → returns (N, dim) int tensor\n",
    "    \"\"\"\n",
    "    gray = grayscale_table[X]              # (N,3072,dim)\n",
    "    pos  = position_table.unsqueeze(0)     # (1,3072,dim)\n",
    "    hv   = (pos * gray).sum(dim=1)         # (N,dim)\n",
    "    return hv\n",
    "\n",
    "# 4. Train associative memory by summing all encodings per class\n",
    "def train_am(X_train, Y_train, position_table, grayscale_table, dim: int):\n",
    "    H_train = encode_batch(X_train, position_table, grayscale_table).float()  # (N,dim)\n",
    "    C = int(Y_train.max().item()) + 1\n",
    "    am = torch.zeros((C, dim), device=X_train.device, dtype=torch.float32)\n",
    "    am = am.index_add(0, Y_train, H_train)\n",
    "    return am\n",
    "\n",
    "# 5. Single‐image prediction (returns class and query HV)\n",
    "@torch.no_grad()\n",
    "def predict_(am, img, position_table, grayscale_table):\n",
    "    qhv = encode_batch(img.unsqueeze(0), position_table, grayscale_table).squeeze(0).float()\n",
    "    sims = F.cosine_similarity(qhv.unsqueeze(0), am, dim=1)  # (C,)\n",
    "    pred = int(sims.argmax().item())\n",
    "    return pred, qhv\n",
    "\n",
    "def predict(am, img, position_table, grayscale_table):\n",
    "    pred, _ = predict_(am, img, position_table, grayscale_table)\n",
    "    return pred\n",
    "\n",
    "# 6. Test on full set\n",
    "@torch.no_grad()\n",
    "def test(am, X_test, Y_test, position_table, grayscale_table):\n",
    "    H_test = encode_batch(X_test, position_table, grayscale_table).float()  # (N_test,dim)\n",
    "    h_norm = H_test.norm(dim=1, keepdim=True)                              # (N,1)\n",
    "    a_norm = am.norm(dim=1, keepdim=True).t()                              # (1,C)\n",
    "    sims   = (H_test @ am.t()) / (h_norm * a_norm)                         # (N,C)\n",
    "    preds  = sims.argmax(dim=1)                                            # (N,)\n",
    "    acc    = (preds == Y_test).float().mean().item()\n",
    "    print(f\"Testing accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "# 7. Load a saved model (AM + tables)\n",
    "def loadmodel(fpath: str, device: torch.device = None):\n",
    "    with open(fpath, 'rb') as f:\n",
    "        am_np, pos_np, gray_np = pickle.load(f)\n",
    "    am   = torch.from_numpy(am_np)\n",
    "    pos  = torch.from_numpy(pos_np)\n",
    "    gray = torch.from_numpy(gray_np)\n",
    "    if device is not None:\n",
    "        am, pos, gray = am.to(device), pos.to(device), gray.to(device)\n",
    "    return am, pos, gray\n",
    "\n",
    "# 8. Quantize the AM to a lower bit‐width\n",
    "def quantize(am: torch.Tensor, before_bw: int, after_bw: int) -> torch.Tensor:\n",
    "    if before_bw <= after_bw:\n",
    "        return am.clone()\n",
    "    shift = before_bw - after_bw\n",
    "    return torch.round(am.float() / (2 ** shift)).to(am.dtype)\n",
    "\n",
    "# 9. Batched AM training\n",
    "@torch.no_grad()\n",
    "def train_am_batched(\n",
    "    X_train: torch.LongTensor,\n",
    "    Y_train: torch.LongTensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    dim: int,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> torch.Tensor:\n",
    "    N = X_train.size(0)\n",
    "    C = int(Y_train.max().item()) + 1\n",
    "    am = torch.zeros(C, dim, device=device, dtype=torch.float32)\n",
    "    for i in (range(0, N, batch_size)):\n",
    "        xb = X_train[i : i + batch_size]\n",
    "        yb = Y_train[i : i + batch_size]\n",
    "        hb = encode_batch(xb, position_table, grayscale_table).float()\n",
    "        am = am.index_add(0, yb, hb)\n",
    "    return am\n",
    "\n",
    "# 10. Test on a split (non-batched)\n",
    "@torch.no_grad()\n",
    "def test_split(am, X_split, Y_split, position_table, grayscale_table):\n",
    "    Hs   = encode_batch(X_split, position_table, grayscale_table).float()  # (M,dim)\n",
    "    sims = F.cosine_similarity(Hs.unsqueeze(1), am.unsqueeze(0), dim=2)   # (M,C)\n",
    "    preds = sims.argmax(dim=1)                                            # (M,)\n",
    "    return (preds == Y_split).float().mean().item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def flip_rows_(tensor: torch.Tensor, perc: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    In-place sign flip of `perc` fraction of elements in *every* row.\n",
    "\n",
    "    tensor : (B, D)  – any real dtype (+1/-1 HVs work fine)\n",
    "    perc   : 0‒1     – fraction of dimensions to flip per row\n",
    "\n",
    "    Returns the same tensor object (for chaining).\n",
    "    \"\"\"\n",
    "    if not 0.0 <= perc <= 1.0:\n",
    "        raise ValueError(\"perc must be in [0,1]\")\n",
    "\n",
    "    # trivial cases\n",
    "    if perc == 0.0 or tensor.numel() == 0:\n",
    "        return tensor\n",
    "\n",
    "    B, D = tensor.shape\n",
    "    k = int(round(D * perc))            # exact #dims to flip / row\n",
    "    if k == 0:\n",
    "        return tensor\n",
    "\n",
    "    device = tensor.device\n",
    "    # --- vectorised selection of k unique indices per row -------------\n",
    "    # 1) random scores per entry\n",
    "    rnd = torch.rand(B, D, device=device)\n",
    "    # 2) take indices of the largest k scores along each row\n",
    "    _, idx = rnd.topk(k, dim=1, largest=True, sorted=False)  # (B,k)\n",
    "    # 3) convert (row, col) pairs → flat indices\n",
    "    base = torch.arange(B, device=device).unsqueeze(1) * D   # (B,1)\n",
    "    flat_idx = (idx + base).reshape(-1)                      # (B*k,)\n",
    "    # 4) flip in-place\n",
    "    tensor.view(-1)[flat_idx] *= -1\n",
    "    return tensor\n",
    "    \n",
    "# 11. Test on a split (batched)\n",
    "@torch.no_grad()\n",
    "def test_split_batched(\n",
    "    am: torch.Tensor,\n",
    "    X: torch.LongTensor,\n",
    "    Y: torch.LongTensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    encode_fn,\n",
    "    flip_perc=0.0,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> float:\n",
    "    correct, total = 0, 0\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        xb = X[i : i + batch_size].to(device)\n",
    "        yb = Y[i : i + batch_size].to(device)\n",
    "        hb = encode_fn(xb, position_table, grayscale_table).float()\n",
    "        flip_rows_(hb, perc=flip_perc)\n",
    "        sims  = F.cosine_similarity(hb.unsqueeze(1), am.unsqueeze(0), dim=2)\n",
    "        preds = sims.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total   += yb.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b6da55-5a3c-46b6-b0f0-39266d1168a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = '../../Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bb8dd7-b853-481f-bd21-5073a49aa182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyperdims = loadmat('../EHDGNet_MNIST_nHD.mat')['EHDGNet_MNIST_nHD']\n",
    "# hyperdims = np.mean(hyperdims, axis=1, dtype=int)\n",
    "hyperdim = 15_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf94b27-a954-4bd2-9130-68ffdffd58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_dataset(mnist_path, device)\n",
    "\n",
    "n_splits   = 20\n",
    "split_size = X_test.size(0) // n_splits\n",
    "flip_percs = np.arange(0.0, 0.51, 0.05)\n",
    "accuracies = np.zeros((len(flip_percs), n_splits))\n",
    "n_class    = 10\n",
    "q_bit      = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a308187-2827-4782-aa30-51961733cf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Flip Percentage: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.8230999999999999\n",
      "\n",
      "==> Flip Percentage: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.8199\n",
      "\n",
      "==> Flip Percentage: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.8164\n",
      "\n",
      "==> Flip Percentage: 0.15000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.8147000000000002\n",
      "\n",
      "==> Flip Percentage: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.8152000000000001\n",
      "\n",
      "==> Flip Percentage: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.8107\n",
      "\n",
      "==> Flip Percentage: 0.30000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.8031000000000003\n",
      "\n",
      "==> Flip Percentage: 0.35000000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.7859\n",
      "\n",
      "==> Flip Percentage: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.7338\n",
      "\n",
      "==> Flip Percentage: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.5477000000000001\n",
      "\n",
      "==> Flip Percentage: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.10390000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, perc in enumerate(flip_percs):\n",
    "    print(f\"\\n==> Flip Percentage: {perc}\")\n",
    "    # a) lookup tables\n",
    "    position_table  = lookup_generate(hyperdim, 'bipolar', 28*28, device=device)\n",
    "    grayscale_table = lookup_generate(hyperdim, 'bipolar', 256, device=device)\n",
    "\n",
    "    # b) train AM\n",
    "    am = train_am_batched(\n",
    "        X_train, Y_train,\n",
    "        position_table, grayscale_table,\n",
    "        dim=hyperdim,\n",
    "        batch_size=1,\n",
    "        device=device\n",
    "    )\n",
    "    # c) quantize AM\n",
    "    am_q = quantize(am, before_bw=16, after_bw=q_bit)\n",
    "\n",
    "    # d) evaluate on splits\n",
    "    for split_idx in tqdm(range(n_splits)):\n",
    "        start = split_idx * split_size\n",
    "        end   = start + split_size\n",
    "\n",
    "        acc = test_split_batched(\n",
    "            am_q,\n",
    "            X_test[start:end],\n",
    "            Y_test[start:end],\n",
    "            position_table,\n",
    "            grayscale_table,\n",
    "            encode_batch,  \n",
    "            flip_perc=perc,\n",
    "            batch_size=12,\n",
    "            device=device\n",
    "        )\n",
    "        accuracies[i, split_idx] = acc\n",
    "\n",
    "    print(\"Accuracy average for 20 splits:\", accuracies[i].mean())\n",
    "\n",
    "    # ─── Free GPU memory ───────────────────────────────\n",
    "    # Delete the large tensors you no longer need\n",
    "    del position_table, grayscale_table, am, am_q\n",
    "    # Run empty_cache so PyTorch can reuse that memory immediately\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ed59b5-35d0-4aeb-adf8-284e71efc94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8231, 0.8199, 0.8164, 0.8147, 0.8152, 0.8107, 0.8031, 0.7859,\n",
       "       0.7338, 0.5477, 0.1039])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f70c68-27d0-4bf5-8536-f61f1c75c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat('VanillaHDC_MNIST.mat', {'VanillaHHDC_MNIST': accuracies*100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2fcf9-710a-487b-83fb-b3cd079aacef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09bba484-669d-4f7d-8876-f272fcf9addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "# import torch\n",
    "# from torchvision.datasets import FashionMNIST, MNIST\n",
    "# from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.io import loadmat, savemat\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63fe9f4-eba1-4c7f-b7e2-131a31dbec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdims = 15000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e423a0-bdf6-43fe-a882-8f8d3bc2391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Device and hyperparameters\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_splits   = 20\n",
    "hyperdims  = hyperdims\n",
    "batch_size = 10\n",
    "\n",
    "# 2. Load & preprocess MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                           # → [0,1], shape (1,28,28)\n",
    "    transforms.Lambda(lambda x: (x > 0.5).float()),  # binarize\n",
    "    transforms.Lambda(lambda x: x.view(-1))         # flatten → (784,)\n",
    "])\n",
    "\n",
    "train_ds = datasets.MNIST(root='../../Data', train=True,  download=True, transform=transform)\n",
    "test_ds  = datasets.MNIST(root='../../Data', train=False, download=True, transform=transform)\n",
    "\n",
    "X_train = torch.stack([img for img, _ in train_ds], dim=0).to(device)  # (60000, 784)\n",
    "y_train = torch.tensor([lbl for _, lbl in train_ds], device=device)\n",
    "\n",
    "X_test  = torch.stack([img for img, _ in test_ds],  dim=0).to(device)  # (10000, 784)\n",
    "y_test  = torch.tensor([lbl for _, lbl in test_ds],  device=device)\n",
    "\n",
    "B = X_train.size(1)                   # 784 pixels\n",
    "C = len(torch.unique(y_train))        # 10 classes\n",
    "split_size = X_test.size(0) // n_splits\n",
    "\n",
    "# 3. HDC utility functions\n",
    "\n",
    "def generate_base_HDVs(D, B, device):\n",
    "    \"\"\"Generate a (B × D) random binary matrix.\"\"\"\n",
    "    return (torch.rand(B, D, device=device) > 0.5).int()  # intTensor of 0/1\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_dataset_batched(X, base_HDVs, batch_size=128):\n",
    "    \"\"\"\n",
    "    Encode X in chunks to avoid OOM.\n",
    "    X:          (N, B) floatTensor {0,1}\n",
    "    base_HDVs:  (B, D) intTensor {0,1}\n",
    "    returns:    (N, D) intTensor {0,1}\n",
    "    \"\"\"\n",
    "    N, B = X.shape\n",
    "    D    = base_HDVs.shape[1]\n",
    "\n",
    "    # Precompute roll-shifted HDVs once\n",
    "    perm_HDVs = base_HDVs.roll(shifts=1, dims=1)  # (B, D)\n",
    "\n",
    "    # Expand for broadcasting\n",
    "    base = base_HDVs.unsqueeze(0)   # (1, B, D)\n",
    "    perm = perm_HDVs.unsqueeze(0)   # (1, B, D)\n",
    "\n",
    "    chunks = []\n",
    "    for i in (range(0, N, batch_size)):\n",
    "        xb    = X[i : i+batch_size]           # (b, B)\n",
    "        xb_exp= xb.unsqueeze(-1)              # (b, B, 1)\n",
    "\n",
    "        # When pixel==1 pick perm, else pick base\n",
    "        weighted = xb_exp * perm + (1 - xb_exp) * base  # (b, B, D)\n",
    "        H_float  = weighted.mean(dim=1)                 # (b, D)\n",
    "        chunks.append(torch.round(H_float).int())       # (b, D)\n",
    "\n",
    "    return torch.cat(chunks, dim=0)  # (N, D)\n",
    "\n",
    "def encode_class_HDVs(H_train, y_train, C):\n",
    "    \"\"\"\n",
    "    Bundle all train-HDVs per class.\n",
    "    H_train: (N, D), y_train: (N,)\n",
    "    returns: (C, D)\n",
    "    \"\"\"\n",
    "    class_HDVs = []\n",
    "    for c in range(C):\n",
    "        subset = H_train[y_train == c]        # (Nc, D)\n",
    "        m      = subset.float().mean(dim=0)   # (D,)\n",
    "        class_HDVs.append(torch.round(m).int())\n",
    "    return torch.stack(class_HDVs, dim=0)    # (C, D)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(H_test, class_HDVs):\n",
    "    \"\"\"\n",
    "    Nearest-neighbor by Hamming distance.\n",
    "    H_test:     (M, D), class_HDVs: (C, D)\n",
    "    returns:    (M,) predicted labels\n",
    "    \"\"\"\n",
    "    diffs = H_test.unsqueeze(1) != class_HDVs.unsqueeze(0)  # (M, C, D)\n",
    "    dists = diffs.sum(dim=2)                                # (M, C)\n",
    "    return dists.argmin(dim=1)                              # (M,)\n",
    "\n",
    "@torch.no_grad()\n",
    "def flip_bits_indexed_unique(\n",
    "    H: torch.IntTensor,\n",
    "    perc: float,\n",
    "    *,\n",
    "    inplace: bool = True,\n",
    "    generator: Optional[torch.Generator] = None,\n",
    ") -> torch.IntTensor:\n",
    "    \"\"\"\n",
    "    Flip *exactly* k = round(perc·D) unique bits in each row of H,\n",
    "    without allocating an (M×D) mask.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H         (M, D) int tensor of {0,1}\n",
    "    perc      fraction in [0,1)\n",
    "    inplace   modify H if True, otherwise work on a clone\n",
    "    generator optional torch.Generator for deterministic behaviour\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor with same shape/dtype/device as H, bits flipped.\n",
    "    \"\"\"\n",
    "    if perc <= 0.0:\n",
    "        return H if inplace else H.clone()\n",
    "\n",
    "    M, D = H.shape\n",
    "    k = int(round(perc * D))\n",
    "    if k == 0:\n",
    "        return H if inplace else H.clone()\n",
    "\n",
    "    out = H if inplace else H.clone()\n",
    "\n",
    "    # Precompute the row indices once → shape (M·k,)\n",
    "    rows = torch.arange(M, device=H.device).repeat_interleave(k)\n",
    "\n",
    "    # Build column indices chunk-by-chunk; (M·k,) total\n",
    "    cols_chunks = [\n",
    "        torch.multinomial(\n",
    "            torch.ones(D, device=H.device),       # uniform weights\n",
    "            k,\n",
    "            replacement=False,\n",
    "            generator=generator,\n",
    "        )\n",
    "        for _ in range(M)\n",
    "    ]\n",
    "    cols = torch.cat(cols_chunks)\n",
    "\n",
    "    # Flip: XOR with 1 toggles 0 ↔ 1\n",
    "    out[rows, cols] ^= 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecad34f-a084-4791-8cb8-50bd89bf91d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Flip Percentage: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8085 for flip percentage 0.0\n",
      "\n",
      "==> Flip Percentage: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8027 for flip percentage 0.05\n",
      "\n",
      "==> Flip Percentage: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8036 for flip percentage 0.1\n",
      "\n",
      "==> Flip Percentage: 0.15000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7952 for flip percentage 0.15000000000000002\n",
      "\n",
      "==> Flip Percentage: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7973 for flip percentage 0.2\n",
      "\n",
      "==> Flip Percentage: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7894 for flip percentage 0.25\n",
      "\n",
      "==> Flip Percentage: 0.30000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7817 for flip percentage 0.30000000000000004\n",
      "\n",
      "==> Flip Percentage: 0.35000000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7462 for flip percentage 0.35000000000000003\n",
      "\n",
      "==> Flip Percentage: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.6768 for flip percentage 0.4\n",
      "\n",
      "==> Flip Percentage: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.4753 for flip percentage 0.45\n",
      "\n",
      "==> Flip Percentage: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.0959 for flip percentage 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits   = 20\n",
    "percs = np.arange(0.0, 0.55, 0.05)\n",
    "accuracies = np.zeros((len(percs), n_splits), dtype=float)\n",
    "for idx, perc in enumerate(percs):\n",
    "    print(f\"\\n==> Flip Percentage: {perc}\")\n",
    "    base_HDVs  = generate_base_HDVs(hyperdims, B, device)\n",
    "    H_train    = encode_dataset_batched(X_train, base_HDVs, batch_size)\n",
    "    class_HDVs = encode_class_HDVs(H_train, y_train, C)\n",
    "\n",
    "    for i in tqdm(range(n_splits)):\n",
    "        s, e = i * split_size, (i + 1) * split_size\n",
    "        Xs, ys = X_test[s:e], y_test[s:e]\n",
    "\n",
    "        Hs    = encode_dataset_batched(Xs, base_HDVs, batch_size)\n",
    "        flip_bits_indexed_unique(Hs, perc)          # modifies Hs in-place\n",
    "        preds = predict(Hs, class_HDVs)\n",
    "    \n",
    "        accuracies[idx, i] = (preds == ys).float().mean().item()\n",
    "        # print(f'Accuracy for split index {i}: {accuracies[idx, i]}')\n",
    "\n",
    "    print(f\"Average accuracy: {accuracies[idx].mean().item():.4f} for flip percentage {perc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719833bb-f58b-47c9-a9b8-df2157a414ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat, loadmat\n",
    "savemat('HoloGN_MNIST.mat', {'HoloGN_MNIST': accuracies*100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d1f32-7bc9-4212-b389-57f6a5067adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

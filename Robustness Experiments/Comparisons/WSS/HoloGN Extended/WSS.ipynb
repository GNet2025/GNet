{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b69b851-55f7-40d6-a309-4bb3fb2265f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets import load_classification\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat, savemat\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc09c28c-1e2c-4c1f-9490-acd1ee5fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_name = 'WalkingSittingStanding'\n",
    "try:\n",
    "    NHDC = loadmat(f'../{dataset_name}_nHD.mat')[f'{dataset_name}_nHD']\n",
    "    hyperdims = np.mean(NHDC, axis=1, dtype=int)\n",
    "\n",
    "except:\n",
    "    hyperdims = 15_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a8d126-bd31-4614-9598-303feb4cb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'WalkingSittingStanding'\n",
    "# Load dataset\n",
    "X_train, y_train, metadata = load_classification(dataset_name, return_metadata=True, split='train')\n",
    "X_test, y_test = load_classification(dataset_name, split='test')\n",
    "if X_train.shape[0] < 200:\n",
    "    if X_test.shape[0] >= 200:\n",
    "        train_size = (X_train.shape[0] + X_test.shape[0]) * 1/4\n",
    "        x, y = load_classification(dataset_name)\n",
    "        X_train, y_train = x[:train_size, :], y[:train_size]\n",
    "        X_test, y_test = x[train_size:, :], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84c546a0-c91b-48f6-ad06-d2a5ab0f8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "if X_train.ndim == 3:\n",
    "    input_channels = X_train.shape[1]\n",
    "seq_length = X_train.shape[-1]\n",
    "if y_train.dtype == object or isinstance(y_train[0], str):\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11cb8221-2fc5-48dd-899a-86bafc78c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "\n",
    "X_min = X_train_scaled.min(axis=0)\n",
    "X_max = X_train_scaled.max(axis=0)\n",
    "\n",
    "denom = (X_max - X_min)\n",
    "denom[denom == 0] = 1   # avoid division by zero\n",
    "\n",
    "X_train_norm = (X_train_scaled - X_min) / denom\n",
    "X_test_norm  = (X_test_scaled  - X_min) / denom\n",
    "\n",
    "# Optional: clip to [0,1] just in case\n",
    "X_train_norm = np.clip(X_train_norm, 0, 1)\n",
    "X_test_norm  = np.clip(X_test_norm, 0, 1)\n",
    "X_train_tensor = torch.tensor(X_train_norm, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_norm, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5603b7e3-1ea5-4492-a686-623fc080cdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 3, 206), (7352, 618), torch.Size([7352, 618]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_scaled.shape, X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9690abbb-bd05-4f5e-afa3-06967631dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "493da6c1-cb45-47ac-88cb-4916a19b02b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0') tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(X_train_tensor), torch.max(X_train_tensor))\n",
    "\n",
    "B = X_train_tensor.shape[1]    \n",
    "C = len(torch.unique(y_train_tensor))        # 10 classes\n",
    "n_rounds = 5\n",
    "\n",
    "# 3. HDC utility functions\n",
    "\n",
    "def generate_base_HDVs(D, B, device):\n",
    "    \"\"\"Generate a (B × D) random binary matrix.\"\"\"\n",
    "    return (torch.rand(B, D, device=device) > 0.5).int()  # intTensor of 0/1\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_dataset_batched(X, base_HDVs, batch_size=128):\n",
    "    \"\"\"\n",
    "    Encode X in chunks to avoid OOM.\n",
    "    X:          (N, B) floatTensor {0,1}\n",
    "    base_HDVs:  (B, D) intTensor {0,1}\n",
    "    returns:    (N, D) intTensor {0,1}\n",
    "    \"\"\"\n",
    "    N, B = X.shape\n",
    "    D    = base_HDVs.shape[1]\n",
    "\n",
    "    # Precompute roll-shifted HDVs once\n",
    "    perm_HDVs = base_HDVs.roll(shifts=1, dims=1)  # (B, D)\n",
    "\n",
    "    # Expand for broadcasting\n",
    "    base = base_HDVs.unsqueeze(0)   # (1, B, D)\n",
    "    perm = perm_HDVs.unsqueeze(0)   # (1, B, D)\n",
    "\n",
    "    chunks = []\n",
    "    for i in (range(0, N, batch_size)):\n",
    "        xb    = X[i : i+batch_size].to(base_HDVs.device)           # (b, B)\n",
    "        xb_exp= xb.unsqueeze(-1)              # (b, B, 1)\n",
    "\n",
    "        # When pixel==1 pick perm, else pick base\n",
    "        weighted = xb_exp * perm + (1 - xb_exp) * base  # (b, B, D)\n",
    "        H_float  = weighted.mean(dim=1)                 # (b, D)\n",
    "        chunks.append(torch.round(H_float).int())       # (b, D)\n",
    "\n",
    "    return torch.cat(chunks, dim=0)  # (N, D)\n",
    "\n",
    "def encode_class_HDVs(H_train, y_train, C):\n",
    "    \"\"\"\n",
    "    Bundle all train-HDVs per class.\n",
    "    H_train: (N, D), y_train: (N,)\n",
    "    returns: (C, D)\n",
    "    \"\"\"\n",
    "    class_HDVs = []\n",
    "    for c in range(C):\n",
    "        subset = H_train[y_train == c]        # (Nc, D)\n",
    "        m      = subset.float().mean(dim=0)   # (D,)\n",
    "        class_HDVs.append(torch.round(m).int())\n",
    "    return torch.stack(class_HDVs, dim=0)    # (C, D)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(H_test, class_HDVs):\n",
    "    \"\"\"\n",
    "    Nearest-neighbor by Hamming distance.\n",
    "    H_test:     (M, D), class_HDVs: (C, D)\n",
    "    returns:    (M,) predicted labels\n",
    "    \"\"\"\n",
    "    diffs = H_test.unsqueeze(1) != class_HDVs.unsqueeze(0)  # (M, C, D)\n",
    "    dists = diffs.sum(dim=2)                                # (M, C)\n",
    "    return dists.argmin(dim=1)   \n",
    "\n",
    "@torch.no_grad()\n",
    "def flip_bits_indexed_unique(\n",
    "    H: torch.IntTensor,\n",
    "    perc: float,\n",
    "    *,\n",
    "    inplace: bool = True,\n",
    "    generator: Optional[torch.Generator] = None,\n",
    ") -> torch.IntTensor:\n",
    "    \"\"\"\n",
    "    Flip *exactly* k = round(perc·D) unique bits in each row of H,\n",
    "    without allocating an (M×D) mask.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H         (M, D) int tensor of {0,1}\n",
    "    perc      fraction in [0,1)\n",
    "    inplace   modify H if True, otherwise work on a clone\n",
    "    generator optional torch.Generator for deterministic behaviour\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor with same shape/dtype/device as H, bits flipped.\n",
    "    \"\"\"\n",
    "    if perc <= 0.0:\n",
    "        return H if inplace else H.clone()\n",
    "\n",
    "    M, D = H.shape\n",
    "    k = int(round(perc * D))\n",
    "    if k == 0:\n",
    "        return H if inplace else H.clone()\n",
    "\n",
    "    out = H if inplace else H.clone()\n",
    "\n",
    "    # Precompute the row indices once → shape (M·k,)\n",
    "    rows = torch.arange(M, device=H.device).repeat_interleave(k)\n",
    "\n",
    "    # Build column indices chunk-by-chunk; (M·k,) total\n",
    "    cols_chunks = [\n",
    "        torch.multinomial(\n",
    "            torch.ones(D, device=H.device),       # uniform weights\n",
    "            k,\n",
    "            replacement=False,\n",
    "            generator=generator,\n",
    "        )\n",
    "        for _ in range(M)\n",
    "    ]\n",
    "    cols = torch.cat(cols_chunks)\n",
    "\n",
    "    # Flip: XOR with 1 toggles 0 ↔ 1\n",
    "    out[rows, cols] ^= 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e933d059-c1b0-4ac5-a518-71ab27853106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Flipping Percentage: 0.0\n",
      "Average accuracy: 0.4956 for Hyperdim 0.0\n",
      "\n",
      "==> Flipping Percentage: 0.05\n",
      "Average accuracy: 0.5129 for Hyperdim 0.05\n",
      "\n",
      "==> Flipping Percentage: 0.1\n",
      "Average accuracy: 0.5095 for Hyperdim 0.1\n",
      "\n",
      "==> Flipping Percentage: 0.15000000000000002\n",
      "Average accuracy: 0.4963 for Hyperdim 0.15000000000000002\n",
      "\n",
      "==> Flipping Percentage: 0.2\n",
      "Average accuracy: 0.5020 for Hyperdim 0.2\n",
      "\n",
      "==> Flipping Percentage: 0.25\n",
      "Average accuracy: 0.5116 for Hyperdim 0.25\n",
      "\n",
      "==> Flipping Percentage: 0.30000000000000004\n",
      "Average accuracy: 0.5065 for Hyperdim 0.30000000000000004\n",
      "\n",
      "==> Flipping Percentage: 0.35000000000000003\n",
      "Average accuracy: 0.4952 for Hyperdim 0.35000000000000003\n",
      "\n",
      "==> Flipping Percentage: 0.4\n",
      "Average accuracy: 0.5133 for Hyperdim 0.4\n",
      "\n",
      "==> Flipping Percentage: 0.45\n",
      "Average accuracy: 0.4786 for Hyperdim 0.45\n",
      "\n",
      "==> Flipping Percentage: 0.5\n",
      "Average accuracy: 0.1653 for Hyperdim 0.5\n"
     ]
    }
   ],
   "source": [
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 10\n",
    "n_splits = 20\n",
    "split_size = len(test_data) // n_splits \n",
    "percs = np.arange(0.0, 0.55, 0.05)\n",
    "accuracies = np.zeros((len(percs), n_splits), dtype=float)\n",
    "for idx, perc in enumerate(percs):\n",
    "    print(f\"\\n==> Flipping Percentage: {perc}\")\n",
    "    for split_idx in range(n_splits):\n",
    "        indices = list(range(len(test_data)))\n",
    "        np.random.shuffle(indices)  # or random.shuffle(indices)\n",
    "        start_idx = split_idx * split_size\n",
    "        end_idx = start_idx + split_size\n",
    "        split_indices = indices[start_idx:end_idx]\n",
    "        base_HDVs  = generate_base_HDVs(hyperdims, B, device)\n",
    "        H_train    = encode_dataset_batched(X_train_tensor, base_HDVs, batch_size)\n",
    "        class_HDVs = encode_class_HDVs(H_train, y_train_tensor, C)\n",
    "        Xs, ys = X_test_tensor[split_indices], y_test_tensor[split_indices]\n",
    "\n",
    "        Hs    = encode_dataset_batched(Xs, base_HDVs, batch_size)\n",
    "        flip_bits_indexed_unique(Hs, perc)          # modifies Hs in-place\n",
    "        preds = predict(Hs, class_HDVs)\n",
    "    \n",
    "        accuracies[idx, split_idx] = (preds.cpu() == ys.cpu()).float().mean().item()\n",
    "        # print(f'Accuracy for split index {i}: {accuracies[idx, i]}')\n",
    "\n",
    "    print(f\"Average accuracy: {accuracies[idx].mean().item():.4f} for Hyperdim {perc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae22027-14d9-43c0-9d68-bc98499a97ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49557823, 0.51292517, 0.5095238 , 0.49625851, 0.50204081,\n",
       "       0.51156462, 0.50646258, 0.49523809, 0.51326531, 0.47857143,\n",
       "       0.16530612])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed3a33d6-7aed-404d-9d30-b857319cce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat(f'{dataset_name}_HoloGN.mat', {f'{dataset_name}_HoloGN': accuracies*100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "159e959d-1605-461f-80c3-a77e866df0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.57997969, 4.17356764, 2.73719713, 2.70809013, 4.4535745 ,\n",
       "       3.83977278, 4.23452296, 3.38499431, 4.89831306, 4.21700106,\n",
       "       2.61794305])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies*100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8da0f7-6086-470f-b488-6e225b32ef48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68721ba0-5b27-4ac2-bcfa-ab791ce562cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from utils import HDDataset\n",
    "from model import BModel\n",
    "from torchvision import datasets, transforms\n",
    "import scipy\n",
    "from encoder_1d import RandomFourierEncoder\n",
    "import main2_1d as main2 \n",
    "import importlib\n",
    "importlib.reload(main2)\n",
    "import csv\n",
    "from scipy.io import savemat, loadmat\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "from aeon.datasets import load_classification\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0a0d72-4f8f-4c2b-8395-080b2600eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620cb9b5-d21a-452b-ad0b-6b982b698af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'WalkingSittingStanding'\n",
    "# Load dataset\n",
    "X_train, y_train, metadata = load_classification(dataset_name, return_metadata=True, split='train')\n",
    "X_test, y_test = load_classification(dataset_name, split='test')\n",
    "if X_train.shape[0] < 200:\n",
    "    if X_test.shape[0] >= 200:\n",
    "        train_size = (X_train.shape[0] + X_test.shape[0]) * 3/4\n",
    "        x, y = load_classification(dataset_name)\n",
    "        X_train, y_train = x[:train_size, :], y[:train_size]\n",
    "        X_test, y_test = x[train_size:, :], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f67515-0a29-43a1-9e01-5158748cfbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "if X_train.ndim == 3:\n",
    "    input_channels = X_train.shape[1]\n",
    "seq_length = X_train.shape[-1]\n",
    "if y_train.dtype == object or isinstance(y_train[0], str):\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8385283-4eb0-494f-b1ba-b2d4360b326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "\n",
    "X_min = X_train_scaled.min(axis=0)\n",
    "X_max = X_train_scaled.max(axis=0)\n",
    "\n",
    "denom = (X_max - X_min)\n",
    "denom[denom == 0] = 1   # avoid division by zero\n",
    "\n",
    "X_train_norm = (X_train_scaled - X_min) / denom\n",
    "X_test_norm  = (X_test_scaled  - X_min) / denom\n",
    "\n",
    "# Optional: clip to [0,1] just in case\n",
    "X_train_norm = np.clip(X_train_norm, 0, 1)\n",
    "X_test_norm  = np.clip(X_test_norm, 0, 1)\n",
    "X_train_tensor = torch.tensor(X_train_norm, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_norm, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0590f23-1c9e-4389-82a7-a2d1ba5c0f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7352, 618])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e5ba87-4819-4c18-87a8-195ce1beeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50f3fb3-7333-4bb7-ade3-74f39967cc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0., device='cuda:0'),\n",
       " tensor(1., device='cuda:0'),\n",
       " array([0, 1, 2, 3, 4, 5]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(X_test_tensor), torch.max(X_test_tensor), np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de781430-e28f-459b-a60b-684a3b1eef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gorder = 2\n",
    "dim = 15000\n",
    "gamma = 0.3\n",
    "lr = 0.01\n",
    "classes = 10\n",
    "channels = 3\n",
    "epochs = 3\n",
    "train = main2.train\n",
    "test = main2.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "281b6c07-8e50-4ef8-bbb5-67b77bd83f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7352, 618])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ee39c3-aee3-4079-a1be-410ae3811164",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()                       # no autograd graph needed\n",
    "def flip_rows_(tensor: torch.Tensor, perc: float, *, inplace: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Flip the sign of `perc` fraction of elements **in every row** of `tensor`.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    tensor : torch.Tensor               # shape (N, D)\n",
    "        2-D tensor whose rows will be sign-flipped.\n",
    "    perc   : float                      # 0 ≤ perc ≤ 1\n",
    "        Fraction of positions per row to flip.\n",
    "    inplace: bool (default True)\n",
    "        If True, modify `tensor` in place and return it;\n",
    "        otherwise return a flipped clone.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The tensor with sign-flipped rows (same object if `inplace` is True).\n",
    "    \"\"\"\n",
    "    if not (0.0 <= perc <= 1.0):\n",
    "        raise ValueError(\"`perc` must be in the interval [0, 1].\")\n",
    "\n",
    "    # Short-circuit trivial cases\n",
    "    if perc == 0.0 or tensor.numel() == 0:\n",
    "        return tensor\n",
    "    if not inplace:\n",
    "        tensor = tensor.clone()\n",
    "\n",
    "    N, D = tensor.shape\n",
    "    k = int(round(D * perc))            # exact count per row\n",
    "    if k == 0:\n",
    "        return tensor                   # nothing to flip\n",
    "\n",
    "    device = tensor.device\n",
    "    for r in range(N):\n",
    "        # choose k unique positions in this row\n",
    "        idx = torch.randperm(D, device=device)[:k]\n",
    "        tensor[r, idx] *= -1            # in-place sign change\n",
    "\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28663ecd-1790-4f3c-bf20-b005afea5d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(618)\n",
      "Flipping Percentage: 0.0 ------------\n",
      "Average Accuracy for Flipping Percentage=0.0: 70.40816326530611\n",
      "Flipping Percentage: 0.05 ------------\n",
      "Average Accuracy for Flipping Percentage=0.05: 70.7482993197279\n",
      "Flipping Percentage: 0.1 ------------\n",
      "Average Accuracy for Flipping Percentage=0.1: 69.35374149659866\n",
      "Flipping Percentage: 0.15 ------------\n",
      "Average Accuracy for Flipping Percentage=0.15000000000000002: 68.46938775510203\n",
      "Flipping Percentage: 0.2 ------------\n",
      "Average Accuracy for Flipping Percentage=0.2: 71.46258503401359\n",
      "Flipping Percentage: 0.25 ------------\n",
      "Average Accuracy for Flipping Percentage=0.25: 66.59863945578232\n",
      "Flipping Percentage: 0.3 ------------\n",
      "Average Accuracy for Flipping Percentage=0.30000000000000004: 66.02040816326532\n",
      "Flipping Percentage: 0.35 ------------\n",
      "Average Accuracy for Flipping Percentage=0.35000000000000003: 63.9795918367347\n",
      "Flipping Percentage: 0.4 ------------\n",
      "Average Accuracy for Flipping Percentage=0.4: 56.666666666666664\n",
      "Flipping Percentage: 0.45 ------------\n",
      "Average Accuracy for Flipping Percentage=0.45: 38.06122448979592\n",
      "Flipping Percentage: 0.5 ------------\n",
      "Average Accuracy for Flipping Percentage=0.5: 13.26530612244898\n"
     ]
    }
   ],
   "source": [
    "n_splits = 20\n",
    "split_size = len(test_data) // n_splits\n",
    "flip_percs = np.arange(0.0, 0.51, 0.05)\n",
    "accuracies1 = np.zeros((len(flip_percs), n_splits))\n",
    "hyperdim = 15_000\n",
    "input_dim = torch.prod(torch.tensor(list(train_data[0][0].size())))\n",
    "print(input_dim)\n",
    "\n",
    "for i, perc in enumerate(flip_percs):\n",
    "    print(f'Flipping Percentage: {np.round(perc, 2)} ------------')\n",
    "    for split_idx in range(n_splits):\n",
    "        indices = list(range(len(test_data)))\n",
    "        np.random.shuffle(indices)  # or random.shuffle(indices)\n",
    "        start_idx = split_idx * split_size\n",
    "        end_idx = start_idx + split_size\n",
    "        split_indices = indices[start_idx:end_idx]\n",
    "        split_subset = Subset(test_data, split_indices)\n",
    "        # print(f'Round {j+1}')\n",
    "        # Train\n",
    "        encoder = RandomFourierEncoder(input_dim, gamma, gorder, output_dim=hyperdim)\n",
    "        encoder.build_item_mem()\n",
    "        train_hd, y_train = encoder.encode_data_extract_labels(train_data)\n",
    "        train_dataset = HDDataset(train_hd.cpu(), y_train.cpu())\n",
    "        trainloader = DataLoader(train_dataset, batch_size=10, shuffle=True, pin_memory=False, num_workers=0)\n",
    "        # Test\n",
    "        \n",
    "        test_hd, y_test = encoder.encode_data_extract_labels(split_subset)\n",
    "        flip_rows_(test_hd, perc=perc)  \n",
    "        # test_hd, y_test = encoder.encode_data_extract_labels(test_data)\n",
    "        test_dataset = HDDataset(test_hd, y_test)\n",
    "        testloader = DataLoader(test_dataset, batch_size=10, shuffle=False, pin_memory=False, num_workers=0)\n",
    "        accuracies1[i, split_idx] = train(trainloader, testloader, lr, hyperdim)\n",
    "        del testloader\n",
    "        del test_dataset\n",
    "        del test_hd\n",
    "\n",
    "        \n",
    "    del train_hd\n",
    "    del trainloader\n",
    "    del train_dataset\n",
    "    print(f'Average Accuracy for Flipping Percentage={perc}: {np.mean(accuracies1[i, :])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7187d6a-9d5a-4ab7-9ef0-efaca9d148c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.40816327, 70.74829932, 69.3537415 , 68.46938776, 71.46258503,\n",
       "       66.59863946, 66.02040816, 63.97959184, 56.66666667, 38.06122449,\n",
       "       13.26530612])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "860258ca-bf41-4796-8fa8-cf8450063a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat(f'{dataset_name}_RFFHDC.mat', {f'{dataset_name}_RFFHDC': accuracies1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b22245-d262-4920-b8d9-be2bd98d51c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

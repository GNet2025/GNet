{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008281be-1e20-4ebb-bb0d-de9c9705c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.io import savemat, loadmat\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df702028-5f8e-47f7-a4cb-a4e9c468e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3601, 500), Test shape: (1320, 500)\n",
      "tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def load_ucr(file):\n",
    "    data = np.loadtxt(file)\n",
    "    X = data[:, 1:]\n",
    "    y = data[:, 0]\n",
    "    y = np.where(y == 1, 1, 0)  # convert labels to 0/1\n",
    "    return X, y\n",
    "\n",
    "# Adjust file paths to your local files\n",
    "X_train, y_train = load_ucr(\"../FordA_TRAIN.txt\")\n",
    "X_test, y_test = load_ucr(\"../FordA_TEST.txt\")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "min_val = X_train_tensor.min()\n",
    "max_val = X_train_tensor.max()\n",
    "\n",
    "X_train_tensor = (X_train_tensor - min_val) / (max_val - min_val)\n",
    "X_test_tensor = (X_test_tensor - min_val) / (max_val - min_val)\n",
    "\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "print(torch.min(X_train_tensor), torch.max(X_train_tensor))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Generate bipolar lookup table\n",
    "def lookup_generate(dim: int, datatype: str, n_keys: int, device: torch.device):\n",
    "    if datatype != 'bipolar':\n",
    "        raise ValueError(\"Only 'bipolar' supported\")\n",
    "    tbl = torch.randint(0, 2, (n_keys, dim), device=device, dtype=torch.int8)\n",
    "    return tbl * 2 - 1  # map {0,1} → {-1,+1}\n",
    "\n",
    "# 2. Encode a batch of inputs into hypervectors\n",
    "@torch.no_grad()\n",
    "def encode_batch(X: torch.Tensor, position_table: torch.Tensor, grayscale_table: torch.Tensor):\n",
    "    \"\"\"\n",
    "    X:               (N, D_in) float tensor in [-3, +3]\n",
    "    position_table:  (D_in, dim)\n",
    "    grayscale_table: (n_keys, dim)\n",
    "    → returns (N, dim) int tensor\n",
    "    \"\"\"\n",
    "    n_keys = grayscale_table.shape[0]\n",
    "    X_normalized = ((X + 3) / 6) * (n_keys - 1)  # map [-3,3] → [0, n_keys-1]\n",
    "    X_indices = X_normalized.round().clamp(0, n_keys - 1).long()  # indices in [0, n_keys-1]\n",
    "    gray = grayscale_table[X_indices]            # (N, D_in, dim)\n",
    "    pos  = position_table.unsqueeze(0)           # (1, D_in, dim)\n",
    "    hv   = (pos * gray).sum(dim=1)               # (N, dim)\n",
    "    return hv\n",
    "\n",
    "# 3. Train associative memory by summing all encodings per class\n",
    "def train_am(X_train, Y_train, position_table, grayscale_table, dim: int):\n",
    "    H_train = encode_batch(X_train, position_table, grayscale_table).float()  # (N, dim)\n",
    "    C = int(Y_train.max().item()) + 1\n",
    "    am = torch.zeros((C, dim), device=X_train.device, dtype=torch.float32)\n",
    "    am = am.index_add(0, Y_train, H_train)\n",
    "    return am\n",
    "\n",
    "# 4. Single-image prediction (returns class and query HV)\n",
    "@torch.no_grad()\n",
    "def predict_(am, img, position_table, grayscale_table):\n",
    "    qhv = encode_batch(img.unsqueeze(0), position_table, grayscale_table).squeeze(0).float()\n",
    "    sims = F.cosine_similarity(qhv.unsqueeze(0), am, dim=1)  # (C,)\n",
    "    pred = int(sims.argmax().item())\n",
    "    return pred, qhv\n",
    "\n",
    "def predict(am, img, position_table, grayscale_table):\n",
    "    pred, _ = predict_(am, img, position_table, grayscale_table)\n",
    "    return pred\n",
    "\n",
    "# 5. Test on full set\n",
    "@torch.no_grad()\n",
    "def test(am, X_test, Y_test, position_table, grayscale_table):\n",
    "    H_test = encode_batch(X_test, position_table, grayscale_table).float()  # (N_test, dim)\n",
    "    h_norm = H_test.norm(dim=1, keepdim=True)                              # (N,1)\n",
    "    a_norm = am.norm(dim=1, keepdim=True).t()                              # (1,C)\n",
    "    sims   = (H_test @ am.t()) / (h_norm * a_norm)                         # (N,C)\n",
    "    preds  = sims.argmax(dim=1)                                            # (N,)\n",
    "    acc    = (preds == Y_test).float().mean().item()\n",
    "    print(f\"Testing accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "# 6. Load a saved model (AM + tables)\n",
    "def loadmodel(fpath: str, device: torch.device = None):\n",
    "    with open(fpath, 'rb') as f:\n",
    "        am_np, pos_np, gray_np = pickle.load(f)\n",
    "    am   = torch.from_numpy(am_np)\n",
    "    pos  = torch.from_numpy(pos_np)\n",
    "    gray = torch.from_numpy(gray_np)\n",
    "    if device is not None:\n",
    "        am, pos, gray = am.to(device), pos.to(device), gray.to(device)\n",
    "    return am, pos, gray\n",
    "\n",
    "# 7. Quantize the AM to a lower bit-width\n",
    "def quantize(am: torch.Tensor, before_bw: int, after_bw: int) -> torch.Tensor:\n",
    "    if before_bw <= after_bw:\n",
    "        return am.clone()\n",
    "    shift = before_bw - after_bw\n",
    "    return torch.round(am.float() / (2 ** shift)).to(am.dtype)\n",
    "\n",
    "# 8. Batched AM training\n",
    "@torch.no_grad()\n",
    "def train_am_batched(\n",
    "    X_train: torch.Tensor,\n",
    "    Y_train: torch.Tensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    dim: int,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> torch.Tensor:\n",
    "    N = X_train.shape[0]\n",
    "    C = int(Y_train.max().item()) + 1\n",
    "    am = torch.zeros(C, dim, device=device, dtype=torch.float32)\n",
    "    for i in tqdm(range(0, N, batch_size), desc=\"Training batches\"):\n",
    "        xb = X_train[i : i + batch_size]\n",
    "        yb = torch.as_tensor(Y_train[i : i + batch_size], device=device)  # <== ✅ fixed\n",
    "        hb = encode_batch(xb, position_table, grayscale_table).float()\n",
    "        am = am.index_add(0, yb, hb)\n",
    "    return am\n",
    "\n",
    "# 9. Test on a split (non-batched)\n",
    "@torch.no_grad()\n",
    "def test_split(am, X_split, Y_split, position_table, grayscale_table):\n",
    "    Hs   = encode_batch(X_split, position_table, grayscale_table).float()  # (M, dim)\n",
    "    sims = F.cosine_similarity(Hs.unsqueeze(1), am.unsqueeze(0), dim=2)   # (M, C)\n",
    "    preds = sims.argmax(dim=1)                                            # (M,)\n",
    "    return (preds == Y_split).float().mean().item()\n",
    "\n",
    "# 10. Test on a split (batched)\n",
    "@torch.no_grad()\n",
    "def test_split_batched(\n",
    "    am: torch.Tensor,\n",
    "    X: torch.Tensor,\n",
    "    Y: torch.Tensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    encode_fn,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> float:\n",
    "    correct, total = 0, 0\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        xb = X[i : i + batch_size].to(device)\n",
    "        yb = Y[i : i + batch_size].to(device)\n",
    "        hb = encode_fn(xb, position_table, grayscale_table).float()\n",
    "        sims  = F.cosine_similarity(hb.unsqueeze(1), am.unsqueeze(0), dim=2)\n",
    "        preds = sims.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total   += yb.size(0)\n",
    "    return correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def flip_rows_(tensor: torch.Tensor, perc: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    In-place sign flip of `perc` fraction of elements in *every* row.\n",
    "\n",
    "    tensor : (B, D)  – any real dtype (+1/-1 HVs work fine)\n",
    "    perc   : 0‒1     – fraction of dimensions to flip per row\n",
    "\n",
    "    Returns the same tensor object (for chaining).\n",
    "    \"\"\"\n",
    "    if not 0.0 <= perc <= 1.0:\n",
    "        raise ValueError(\"perc must be in [0,1]\")\n",
    "\n",
    "    # trivial cases\n",
    "    if perc == 0.0 or tensor.numel() == 0:\n",
    "        return tensor\n",
    "\n",
    "    B, D = tensor.shape\n",
    "    k = int(round(D * perc))            # exact #dims to flip / row\n",
    "    if k == 0:\n",
    "        return tensor\n",
    "\n",
    "    device = tensor.device\n",
    "    # --- vectorised selection of k unique indices per row -------------\n",
    "    # 1) random scores per entry\n",
    "    rnd = torch.rand(B, D, device=device)\n",
    "    # 2) take indices of the largest k scores along each row\n",
    "    _, idx = rnd.topk(k, dim=1, largest=True, sorted=False)  # (B,k)\n",
    "    # 3) convert (row, col) pairs → flat indices\n",
    "    base = torch.arange(B, device=device).unsqueeze(1) * D   # (B,1)\n",
    "    flat_idx = (idx + base).reshape(-1)                      # (B*k,)\n",
    "    # 4) flip in-place\n",
    "    tensor.view(-1)[flat_idx] *= -1\n",
    "    return tensor\n",
    "    \n",
    "# 11. Test on a split (batched)\n",
    "@torch.no_grad()\n",
    "def test_split_batched(\n",
    "    am: torch.Tensor,\n",
    "    X: torch.LongTensor,\n",
    "    Y: torch.LongTensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    encode_fn,\n",
    "    flip_perc=0.0,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> float:\n",
    "    correct, total = 0, 0\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        xb = X[i : i + batch_size].to(device)\n",
    "        yb = Y[i : i + batch_size].to(device)\n",
    "        hb = encode_fn(xb, position_table, grayscale_table).float()\n",
    "        flip_rows_(hb, perc=flip_perc)\n",
    "        sims  = F.cosine_similarity(hb.unsqueeze(1), am.unsqueeze(0), dim=2)\n",
    "        preds = sims.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total   += yb.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d3b43b-d3d4-4293-9200-f39ac4195037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf94b27-a954-4bd2-9130-68ffdffd58e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# X_train, Y_train, X_test, Y_test = load_dataset(cifar10_path, device)\n",
    "\n",
    "n_splits   = 20\n",
    "split_size = X_test.shape[0] // n_splits\n",
    "flip_percs = np.arange(0.0, 0.51, 0.05)\n",
    "accuracies = np.zeros((len(flip_percs), n_splits))\n",
    "n_class    = 2\n",
    "q_bit      = 16\n",
    "D = 15000\n",
    "subset_size = 500\n",
    "print(split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b686f64-e308-436c-bdcb-6688cf5f24dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(0.))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(X_train_tensor), torch.min(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a308187-2827-4782-aa30-51961733cf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Flip Percentage: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2569.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4835999999999999\n",
      "\n",
      "==> Flip Percentage: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2833.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4925\n",
      "\n",
      "==> Flip Percentage: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2807.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.49379999999999996\n",
      "\n",
      "==> Flip Percentage: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2804.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4888\n",
      "\n",
      "==> Flip Percentage: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2823.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4972\n",
      "\n",
      "==> Flip Percentage: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2815.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.49499999999999994\n",
      "\n",
      "==> Flip Percentage: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2823.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4901999999999999\n",
      "\n",
      "==> Flip Percentage: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2804.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.48250000000000004\n",
      "\n",
      "==> Flip Percentage: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2816.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.5056\n",
      "\n",
      "==> Flip Percentage: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2813.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.5035999999999999\n",
      "\n",
      "==> Flip Percentage: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2842.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.492\n"
     ]
    }
   ],
   "source": [
    "for i, perc in enumerate(flip_percs):\n",
    "    print(f\"\\n==> Flip Percentage: {np.round(perc, 2)}\")\n",
    "    \n",
    "    # Dynamically get input dimension\n",
    "    input_dim = X_train_tensor.shape[1]  # e.g., 3*206\n",
    "    n_keys = 64                   # number of quantization bins for [-3,+3]\n",
    "    \n",
    "    # a) lookup tables\n",
    "    position_table  = lookup_generate(D, 'bipolar', input_dim, device=device)\n",
    "    grayscale_table = lookup_generate(D, 'bipolar', n_keys, device=device)\n",
    "\n",
    "    # b) train AM\n",
    "    am = train_am_batched(\n",
    "        X_train_tensor, y_train_tensor,\n",
    "        position_table, grayscale_table,\n",
    "        dim=D,\n",
    "        batch_size=1,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # c) quantize AM\n",
    "    am_q = quantize(am, before_bw=16, after_bw=q_bit)\n",
    "\n",
    "    # d) evaluate on splits\n",
    "    for split_idx in range(n_splits):\n",
    "        split_indices = np.random.choice(len(X_test_tensor), size=subset_size, replace=False)\n",
    "        acc = test_split_batched(\n",
    "            am_q,\n",
    "            X_test_tensor[split_indices],\n",
    "            y_test_tensor[split_indices],\n",
    "            position_table,\n",
    "            grayscale_table,\n",
    "            encode_batch,  \n",
    "            flip_perc=perc,\n",
    "            batch_size=10,\n",
    "            device=device\n",
    "        )\n",
    "        accuracies[i, split_idx] = acc\n",
    "\n",
    "    print(\"Accuracy average for 20 rounds:\", accuracies[i].mean())\n",
    "\n",
    "    # Free GPU memory\n",
    "    del position_table, grayscale_table, am, am_q\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ed59b5-35d0-4aeb-adf8-284e71efc94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4836, 0.4925, 0.4938, 0.4888, 0.4972, 0.495 , 0.4902, 0.4825,\n",
       "       0.5056, 0.5036, 0.492 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f70c68-27d0-4bf5-8536-f61f1c75c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat('FordA_VanillaHDC.mat', {'FordA_VanillaHDC': accuracies*100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215e6f3-14d6-49ae-8bd5-8bda51dec278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e7529-8986-4fba-b0f6-d42ace416a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

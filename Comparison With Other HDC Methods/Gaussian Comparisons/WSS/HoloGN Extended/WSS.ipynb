{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b69b851-55f7-40d6-a309-4bb3fb2265f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets import load_classification\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat, savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc09c28c-1e2c-4c1f-9490-acd1ee5fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_name = 'WalkingSittingStanding'\n",
    "try:\n",
    "    NHDC = loadmat(f'../{dataset_name}_nHD.mat')[f'{dataset_name}_nHD']\n",
    "    hyperdims = np.mean(NHDC, axis=1, dtype=int)\n",
    "\n",
    "except:\n",
    "    hyperdims = range(1000, 5500, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a8d126-bd31-4614-9598-303feb4cb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'WalkingSittingStanding'\n",
    "# Load dataset\n",
    "X_train, y_train, metadata = load_classification(dataset_name, return_metadata=True, split='train')\n",
    "X_test, y_test = load_classification(dataset_name, split='test')\n",
    "if X_train.shape[0] < 200:\n",
    "    if X_test.shape[0] >= 200:\n",
    "        train_size = (X_train.shape[0] + X_test.shape[0]) * 1/4\n",
    "        x, y = load_classification(dataset_name)\n",
    "        X_train, y_train = x[:train_size, :], y[:train_size]\n",
    "        X_test, y_test = x[train_size:, :], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c546a0-c91b-48f6-ad06-d2a5ab0f8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "if X_train.ndim == 3:\n",
    "    input_channels = X_train.shape[1]\n",
    "seq_length = X_train.shape[-1]\n",
    "if y_train.dtype == object or isinstance(y_train[0], str):\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11cb8221-2fc5-48dd-899a-86bafc78c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "\n",
    "X_min = X_train_scaled.min(axis=0)\n",
    "X_max = X_train_scaled.max(axis=0)\n",
    "\n",
    "denom = (X_max - X_min)\n",
    "denom[denom == 0] = 1   # avoid division by zero\n",
    "\n",
    "X_train_norm = (X_train_scaled - X_min) / denom\n",
    "X_test_norm  = (X_test_scaled  - X_min) / denom\n",
    "\n",
    "# Optional: clip to [0,1] just in case\n",
    "X_train_norm = np.clip(X_train_norm, 0, 1)\n",
    "X_test_norm  = np.clip(X_test_norm, 0, 1)\n",
    "X_train_tensor = torch.tensor(X_train_norm, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_norm, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5603b7e3-1ea5-4492-a686-623fc080cdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 3, 206), (7352, 618), torch.Size([7352, 618]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_scaled.shape, X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9690abbb-bd05-4f5e-afa3-06967631dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "493da6c1-cb45-47ac-88cb-4916a19b02b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0') tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(X_train_tensor), torch.max(X_train_tensor))\n",
    "\n",
    "B = X_train_tensor.shape[1]    \n",
    "C = len(torch.unique(y_train_tensor))        # 10 classes\n",
    "n_rounds = 5\n",
    "\n",
    "# 3. HDC utility functions\n",
    "\n",
    "def generate_base_HDVs(D, B, device):\n",
    "    \"\"\"Generate a (B Ã— D) random binary matrix.\"\"\"\n",
    "    return (torch.rand(B, D, device=device) > 0.5).int()  # intTensor of 0/1\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_dataset_batched(X, base_HDVs, batch_size=128):\n",
    "    \"\"\"\n",
    "    Encode X in chunks to avoid OOM.\n",
    "    X:          (N, B) floatTensor {0,1}\n",
    "    base_HDVs:  (B, D) intTensor {0,1}\n",
    "    returns:    (N, D) intTensor {0,1}\n",
    "    \"\"\"\n",
    "    N, B = X.shape\n",
    "    D    = base_HDVs.shape[1]\n",
    "\n",
    "    # Precompute roll-shifted HDVs once\n",
    "    perm_HDVs = base_HDVs.roll(shifts=1, dims=1)  # (B, D)\n",
    "\n",
    "    # Expand for broadcasting\n",
    "    base = base_HDVs.unsqueeze(0)   # (1, B, D)\n",
    "    perm = perm_HDVs.unsqueeze(0)   # (1, B, D)\n",
    "\n",
    "    chunks = []\n",
    "    for i in (range(0, N, batch_size)):\n",
    "        xb    = X[i : i+batch_size].to(base_HDVs.device)           # (b, B)\n",
    "        xb_exp= xb.unsqueeze(-1)              # (b, B, 1)\n",
    "\n",
    "        # When pixel==1 pick perm, else pick base\n",
    "        weighted = xb_exp * perm + (1 - xb_exp) * base  # (b, B, D)\n",
    "        H_float  = weighted.mean(dim=1)                 # (b, D)\n",
    "        chunks.append(torch.round(H_float).int())       # (b, D)\n",
    "\n",
    "    return torch.cat(chunks, dim=0)  # (N, D)\n",
    "\n",
    "def encode_class_HDVs(H_train, y_train, C):\n",
    "    \"\"\"\n",
    "    Bundle all train-HDVs per class.\n",
    "    H_train: (N, D), y_train: (N,)\n",
    "    returns: (C, D)\n",
    "    \"\"\"\n",
    "    class_HDVs = []\n",
    "    for c in range(C):\n",
    "        subset = H_train[y_train == c]        # (Nc, D)\n",
    "        m      = subset.float().mean(dim=0)   # (D,)\n",
    "        class_HDVs.append(torch.round(m).int())\n",
    "    return torch.stack(class_HDVs, dim=0)    # (C, D)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(H_test, class_HDVs):\n",
    "    \"\"\"\n",
    "    Nearest-neighbor by Hamming distance.\n",
    "    H_test:     (M, D), class_HDVs: (C, D)\n",
    "    returns:    (M,) predicted labels\n",
    "    \"\"\"\n",
    "    diffs = H_test.unsqueeze(1) != class_HDVs.unsqueeze(0)  # (M, C, D)\n",
    "    dists = diffs.sum(dim=2)                                # (M, C)\n",
    "    return dists.argmin(dim=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e933d059-c1b0-4ac5-a518-71ab27853106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Hyperdimension: 6666\n",
      "Average accuracy: 0.5187 for Hyperdim 6666\n",
      "\n",
      "==> Hyperdimension: 7666\n",
      "Average accuracy: 0.5088 for Hyperdim 7666\n",
      "\n",
      "==> Hyperdimension: 8666\n",
      "Average accuracy: 0.5048 for Hyperdim 8666\n",
      "\n",
      "==> Hyperdimension: 10000\n",
      "Average accuracy: 0.4884 for Hyperdim 10000\n",
      "\n",
      "==> Hyperdimension: 11000\n",
      "Average accuracy: 0.5085 for Hyperdim 11000\n",
      "\n",
      "==> Hyperdimension: 12333\n",
      "Average accuracy: 0.5116 for Hyperdim 12333\n",
      "\n",
      "==> Hyperdimension: 13666\n",
      "Average accuracy: 0.4990 for Hyperdim 13666\n",
      "\n",
      "==> Hyperdimension: 14666\n",
      "Average accuracy: 0.5095 for Hyperdim 14666\n",
      "\n",
      "==> Hyperdimension: 15666\n",
      "Average accuracy: 0.5122 for Hyperdim 15666\n",
      "\n",
      "==> Hyperdimension: 17000\n",
      "Average accuracy: 0.5143 for Hyperdim 17000\n",
      "\n",
      "==> Hyperdimension: 18333\n",
      "Average accuracy: 0.5054 for Hyperdim 18333\n"
     ]
    }
   ],
   "source": [
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 10\n",
    "n_splits = 20\n",
    "split_size = len(test_data) // n_splits \n",
    "accuracies = np.zeros((len(hyperdims), n_splits), dtype=float)\n",
    "for idx, D in enumerate(hyperdims):\n",
    "    print(f\"\\n==> Hyperdimension: {D}\")\n",
    "    for split_idx in range(n_splits):\n",
    "        indices = list(range(len(test_data)))\n",
    "        np.random.shuffle(indices)  # or random.shuffle(indices)\n",
    "        start_idx = split_idx * split_size\n",
    "        end_idx = start_idx + split_size\n",
    "        split_indices = indices[start_idx:end_idx]\n",
    "        base_HDVs  = generate_base_HDVs(D, B, device)\n",
    "        H_train    = encode_dataset_batched(X_train_tensor, base_HDVs, batch_size)\n",
    "        class_HDVs = encode_class_HDVs(H_train, y_train_tensor, C)\n",
    "        Xs, ys = X_test_tensor[split_indices], y_test_tensor[split_indices]\n",
    "\n",
    "        Hs    = encode_dataset_batched(Xs, base_HDVs, batch_size)\n",
    "        preds = predict(Hs, class_HDVs)\n",
    "    \n",
    "        accuracies[idx, split_idx] = (preds.cpu() == ys.cpu()).float().mean().item()\n",
    "        # print(f'Accuracy for split index {i}: {accuracies[idx, i]}')\n",
    "\n",
    "    print(f\"Average accuracy: {accuracies[idx].mean().item():.4f} for Hyperdim {D}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fae22027-14d9-43c0-9d68-bc98499a97ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51870749, 0.50884354, 0.50476191, 0.48843537, 0.50850341,\n",
       "       0.51156463, 0.49897959, 0.50952381, 0.5122449 , 0.51428571,\n",
       "       0.50544218])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed3a33d6-7aed-404d-9d30-b857319cce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat(f'{dataset_name}_HoloGN.mat', {f'{dataset_name}_HoloGN': accuracies*100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "159e959d-1605-461f-80c3-a77e866df0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.16070449, 3.21675932, 3.51247111, 3.66085021, 3.38003551,\n",
       "       4.25156487, 4.18947645, 3.68792805, 4.01360488, 4.74437972,\n",
       "       3.7328287 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies*100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8da0f7-6086-470f-b488-6e225b32ef48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

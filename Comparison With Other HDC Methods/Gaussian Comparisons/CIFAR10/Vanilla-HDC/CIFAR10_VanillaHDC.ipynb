{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008281be-1e20-4ebb-bb0d-de9c9705c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.io import savemat, loadmat\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df702028-5f8e-47f7-a4cb-a4e9c468e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load CIFAR-10 into torch Tensors\n",
    "def load_dataset(cifar_path: str, device: torch.device):\n",
    "    ds_train = CIFAR10(cifar_path, train=True,  download=True)\n",
    "    ds_test  = CIFAR10(cifar_path, train=False, download=True)\n",
    "\n",
    "    # -- TRAIN --\n",
    "    X_train = torch.from_numpy(ds_train.data)        \\\n",
    "                    .reshape(-1, 3 * 32 * 32)        \\\n",
    "                    .to(device)                      \\\n",
    "                    .long()                          # (N, 3072)\n",
    "    Y_train = torch.tensor(ds_train.targets, device=device)\n",
    "\n",
    "    # -- TEST --\n",
    "    X_test  = torch.from_numpy(ds_test.data)         \\\n",
    "                    .reshape(-1, 3 * 32 * 32)        \\\n",
    "                    .to(device)                      \\\n",
    "                    .long()                          # (N_test, 3072)\n",
    "    Y_test  = torch.tensor(ds_test.targets, device=device)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "# 2. Build bipolar lookup table (torch version)\n",
    "def lookup_generate(dim: int, datatype: str, n_keys: int, device: torch.device):\n",
    "    torch.manual_seed(n_keys)\n",
    "    if datatype != 'bipolar':\n",
    "        raise ValueError(\"Only 'bipolar' supported\")\n",
    "    tbl = torch.randint(0, 2, (n_keys, dim), device=device, dtype=torch.int8)\n",
    "    return tbl * 2 - 1  # map {0,1} → {-1,+1}\n",
    "\n",
    "# 3. Encode a batch of images into hypervectors\n",
    "@torch.no_grad()\n",
    "def encode_batch(X: torch.LongTensor, position_table: torch.Tensor, grayscale_table: torch.Tensor):\n",
    "    \"\"\"\n",
    "    X:               (N,3072) int tensor in [0..255]\n",
    "    position_table:  (3072, dim)\n",
    "    grayscale_table: (256,  dim)\n",
    "    → returns (N, dim) int tensor\n",
    "    \"\"\"\n",
    "    gray = grayscale_table[X]              # (N,3072,dim)\n",
    "    pos  = position_table.unsqueeze(0)     # (1,3072,dim)\n",
    "    hv   = (pos * gray).sum(dim=1)         # (N,dim)\n",
    "    return hv\n",
    "\n",
    "# 4. Train associative memory by summing all encodings per class\n",
    "def train_am(X_train, Y_train, position_table, grayscale_table, dim: int):\n",
    "    H_train = encode_batch(X_train, position_table, grayscale_table).float()  # (N,dim)\n",
    "    C = int(Y_train.max().item()) + 1\n",
    "    am = torch.zeros((C, dim), device=X_train.device, dtype=torch.float32)\n",
    "    am = am.index_add(0, Y_train, H_train)\n",
    "    return am\n",
    "\n",
    "# 5. Single‐image prediction (returns class and query HV)\n",
    "@torch.no_grad()\n",
    "def predict_(am, img, position_table, grayscale_table):\n",
    "    qhv = encode_batch(img.unsqueeze(0), position_table, grayscale_table).squeeze(0).float()\n",
    "    sims = F.cosine_similarity(qhv.unsqueeze(0), am, dim=1)  # (C,)\n",
    "    pred = int(sims.argmax().item())\n",
    "    return pred, qhv\n",
    "\n",
    "def predict(am, img, position_table, grayscale_table):\n",
    "    pred, _ = predict_(am, img, position_table, grayscale_table)\n",
    "    return pred\n",
    "\n",
    "# 6. Test on full set\n",
    "@torch.no_grad()\n",
    "def test(am, X_test, Y_test, position_table, grayscale_table):\n",
    "    H_test = encode_batch(X_test, position_table, grayscale_table).float()  # (N_test,dim)\n",
    "    h_norm = H_test.norm(dim=1, keepdim=True)                              # (N,1)\n",
    "    a_norm = am.norm(dim=1, keepdim=True).t()                              # (1,C)\n",
    "    sims   = (H_test @ am.t()) / (h_norm * a_norm)                         # (N,C)\n",
    "    preds  = sims.argmax(dim=1)                                            # (N,)\n",
    "    acc    = (preds == Y_test).float().mean().item()\n",
    "    print(f\"Testing accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "# 7. Load a saved model (AM + tables)\n",
    "def loadmodel(fpath: str, device: torch.device = None):\n",
    "    with open(fpath, 'rb') as f:\n",
    "        am_np, pos_np, gray_np = pickle.load(f)\n",
    "    am   = torch.from_numpy(am_np)\n",
    "    pos  = torch.from_numpy(pos_np)\n",
    "    gray = torch.from_numpy(gray_np)\n",
    "    if device is not None:\n",
    "        am, pos, gray = am.to(device), pos.to(device), gray.to(device)\n",
    "    return am, pos, gray\n",
    "\n",
    "# 8. Quantize the AM to a lower bit‐width\n",
    "def quantize(am: torch.Tensor, before_bw: int, after_bw: int) -> torch.Tensor:\n",
    "    if before_bw <= after_bw:\n",
    "        return am.clone()\n",
    "    shift = before_bw - after_bw\n",
    "    return torch.round(am.float() / (2 ** shift)).to(am.dtype)\n",
    "\n",
    "# 9. Batched AM training\n",
    "@torch.no_grad()\n",
    "def train_am_batched(\n",
    "    X_train: torch.LongTensor,\n",
    "    Y_train: torch.LongTensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    dim: int,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> torch.Tensor:\n",
    "    N = X_train.size(0)\n",
    "    C = int(Y_train.max().item()) + 1\n",
    "    am = torch.zeros(C, dim, device=device, dtype=torch.float32)\n",
    "    for i in tqdm(range(0, N, batch_size), desc=\"Training batches\"):\n",
    "        xb = X_train[i : i + batch_size]\n",
    "        yb = Y_train[i : i + batch_size]\n",
    "        hb = encode_batch(xb, position_table, grayscale_table).float()\n",
    "        am = am.index_add(0, yb, hb)\n",
    "    return am\n",
    "\n",
    "# 10. Test on a split (non-batched)\n",
    "@torch.no_grad()\n",
    "def test_split(am, X_split, Y_split, position_table, grayscale_table):\n",
    "    Hs   = encode_batch(X_split, position_table, grayscale_table).float()  # (M,dim)\n",
    "    sims = F.cosine_similarity(Hs.unsqueeze(1), am.unsqueeze(0), dim=2)   # (M,C)\n",
    "    preds = sims.argmax(dim=1)                                            # (M,)\n",
    "    return (preds == Y_split).float().mean().item()\n",
    "\n",
    "# 11. Test on a split (batched)\n",
    "@torch.no_grad()\n",
    "def test_split_batched(\n",
    "    am: torch.Tensor,\n",
    "    X: torch.LongTensor,\n",
    "    Y: torch.LongTensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    encode_fn,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> float:\n",
    "    correct, total = 0, 0\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        xb = X[i : i + batch_size].to(device)\n",
    "        yb = Y[i : i + batch_size].to(device)\n",
    "        hb = encode_fn(xb, position_table, grayscale_table).float()\n",
    "        sims  = F.cosine_similarity(hb.unsqueeze(1), am.unsqueeze(0), dim=2)\n",
    "        preds = sims.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total   += yb.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b6da55-5a3c-46b6-b0f0-39266d1168a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_path = '../../Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bb8dd7-b853-481f-bd21-5073a49aa182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15000, 17250, 19000, 21250, 23250, 25250, 27000, 29000, 31000,\n",
       "       33000, 35000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperdims = loadmat('../EHDGNet_CIFAR10_nHD.mat')['EHDGNet_CIFAR10_nHD']\n",
    "hyperdims = np.mean(hyperdims, axis=1, dtype=int)\n",
    "hyperdims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf94b27-a954-4bd2-9130-68ffdffd58e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_dataset(cifar10_path, device)\n",
    "\n",
    "n_splits   = 20\n",
    "split_size = X_test.size(0) // n_splits\n",
    "hyperdims = hyperdims\n",
    "accuracies = np.zeros((len(hyperdims), n_splits))\n",
    "n_class    = 10\n",
    "q_bit      = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a308187-2827-4782-aa30-51961733cf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Hyperdimension: 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [01:13<00:00, 678.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.258\n",
      "\n",
      "==> Hyperdimension: 17250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [01:25<00:00, 581.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.26739999999999997\n",
      "\n",
      "==> Hyperdimension: 19000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [01:32<00:00, 537.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.2705\n",
      "\n",
      "==> Hyperdimension: 21250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [01:44<00:00, 478.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.2677\n",
      "\n",
      "==> Hyperdimension: 23250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [01:54<00:00, 437.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.2693\n",
      "\n",
      "==> Hyperdimension: 25250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [02:04<00:00, 403.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.2657\n",
      "\n",
      "==> Hyperdimension: 27000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [02:12<00:00, 377.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.27049999999999996\n",
      "\n",
      "==> Hyperdimension: 29000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [02:21<00:00, 353.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.26979999999999993\n",
      "\n",
      "==> Hyperdimension: 31000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [02:32<00:00, 328.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.27080000000000004\n",
      "\n",
      "==> Hyperdimension: 33000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [02:40<00:00, 310.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.27220000000000005\n",
      "\n",
      "==> Hyperdimension: 35000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 50000/50000 [02:50<00:00, 293.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 splits: 0.2758999999999999\n"
     ]
    }
   ],
   "source": [
    "for i, D in enumerate(hyperdims):\n",
    "    print(f\"\\n==> Hyperdimension: {D}\")\n",
    "    # a) lookup tables\n",
    "    position_table  = lookup_generate(D, 'bipolar', 3*32*32, device=device)\n",
    "    grayscale_table = lookup_generate(D, 'bipolar', 256, device=device)\n",
    "\n",
    "    # b) train AM\n",
    "    am = train_am_batched(\n",
    "        X_train, Y_train,\n",
    "        position_table, grayscale_table,\n",
    "        dim=D,\n",
    "        batch_size=1,\n",
    "        device=device\n",
    "    )\n",
    "    # c) quantize AM\n",
    "    am_q = quantize(am, before_bw=16, after_bw=q_bit)\n",
    "\n",
    "    # d) evaluate on splits\n",
    "    for split_idx in range(n_splits):\n",
    "        start = split_idx * split_size\n",
    "        end   = start + split_size\n",
    "\n",
    "        acc = test_split_batched(\n",
    "            am_q,\n",
    "            X_test[start:end],\n",
    "            Y_test[start:end],\n",
    "            position_table,\n",
    "            grayscale_table,\n",
    "            encode_batch,  \n",
    "            batch_size=10,\n",
    "            device=device\n",
    "        )\n",
    "        accuracies[i, split_idx] = acc\n",
    "\n",
    "    print(\"Accuracy average for 20 splits:\", accuracies[i].mean())\n",
    "\n",
    "    # ─── Free GPU memory ───────────────────────────────\n",
    "    # Delete the large tensors you no longer need\n",
    "    del position_table, grayscale_table, am, am_q\n",
    "    # Run empty_cache so PyTorch can reuse that memory immediately\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ed59b5-35d0-4aeb-adf8-284e71efc94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.258 , 0.2674, 0.2705, 0.2677, 0.2693, 0.2657, 0.2705, 0.2698,\n",
       "       0.2708, 0.2722, 0.2759])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f70c68-27d0-4bf5-8536-f61f1c75c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat('VanillaHDC_CIFAR10.mat', {'VanillaHHDC_CIFAR10': accuracies*100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931acf81-bb61-4b21-bc2a-8a8035948364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09bba484-669d-4f7d-8876-f272fcf9addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "# import torch\n",
    "# from torchvision.datasets import FashionMNIST, MNIST\n",
    "# from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.io import loadmat, savemat\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63fe9f4-eba1-4c7f-b7e2-131a31dbec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15000, 17250, 19000, 21250, 23250, 25250, 27000, 29000, 31000,\n",
       "       33000, 35000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperdims = loadmat('../EHDGNet_CIFAR10_nHD.mat')\n",
    "hyperdims = hyperdims['EHDGNet_CIFAR10_nHD']\n",
    "hyperdims = np.mean(hyperdims, axis=1, dtype=int)\n",
    "hyperdims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e423a0-bdf6-43fe-a882-8f8d3bc2391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "3072 num features\n"
     ]
    }
   ],
   "source": [
    "# 1. Device and hyperparameters\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_splits   = 20\n",
    "hyperdims  = hyperdims\n",
    "batch_size = 1\n",
    "\n",
    "# 2. Load & preprocess MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                           # → [0,1], shape (1,28,28)\n",
    "    transforms.Lambda(lambda x: (x > 0.5).float()),  # binarize\n",
    "    transforms.Lambda(lambda x: x.view(-1))         # flatten → (784,)\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root='../../Data', train=True,  download=True, transform=transform)\n",
    "test_ds  = datasets.CIFAR10(root='../../Data', train=False, download=True, transform=transform)\n",
    "\n",
    "X_train = torch.stack([img for img, _ in train_ds], dim=0).to(device)  # (60000, 784)\n",
    "y_train = torch.tensor([lbl for _, lbl in train_ds], device=device)\n",
    "\n",
    "X_test  = torch.stack([img for img, _ in test_ds],  dim=0).to(device)  # (10000, 784)\n",
    "y_test  = torch.tensor([lbl for _, lbl in test_ds],  device=device)\n",
    "\n",
    "B = X_train.size(1)                   # 784 pixels\n",
    "print(B, 'num features')\n",
    "C = len(torch.unique(y_train))        # 10 classes\n",
    "split_size = X_test.size(0) // n_splits\n",
    "\n",
    "# 3. HDC utility functions\n",
    "\n",
    "def generate_base_HDVs(D, B, device, seed=42):\n",
    "    \"\"\"Generate a (B × D) random binary matrix.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    return (torch.rand(B, D, device=device) > 0.5).int()  # intTensor of 0/1\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_dataset_batched(X, base_HDVs, batch_size=128):\n",
    "    \"\"\"\n",
    "    Encode X in chunks to avoid OOM.\n",
    "    X:          (N, B) floatTensor {0,1}\n",
    "    base_HDVs:  (B, D) intTensor {0,1}\n",
    "    returns:    (N, D) intTensor {0,1}\n",
    "    \"\"\"\n",
    "    N, B = X.shape\n",
    "    D    = base_HDVs.shape[1]\n",
    "\n",
    "    # Precompute roll-shifted HDVs once\n",
    "    perm_HDVs = base_HDVs.roll(shifts=1, dims=1)  # (B, D)\n",
    "\n",
    "    # Expand for broadcasting\n",
    "    base = base_HDVs.unsqueeze(0)   # (1, B, D)\n",
    "    perm = perm_HDVs.unsqueeze(0)   # (1, B, D)\n",
    "\n",
    "    chunks = []\n",
    "    for i in (range(0, N, batch_size)):\n",
    "        xb    = X[i : i+batch_size]           # (b, B)\n",
    "        xb_exp= xb.unsqueeze(-1)              # (b, B, 1)\n",
    "\n",
    "        # When pixel==1 pick perm, else pick base\n",
    "        weighted = xb_exp * perm + (1 - xb_exp) * base  # (b, B, D)\n",
    "        H_float  = weighted.mean(dim=1)                 # (b, D)\n",
    "        chunks.append(torch.round(H_float).int())       # (b, D)\n",
    "\n",
    "    return torch.cat(chunks, dim=0)  # (N, D)\n",
    "\n",
    "def encode_class_HDVs(H_train, y_train, C):\n",
    "    \"\"\"\n",
    "    Bundle all train-HDVs per class.\n",
    "    H_train: (N, D), y_train: (N,)\n",
    "    returns: (C, D)\n",
    "    \"\"\"\n",
    "    class_HDVs = []\n",
    "    for c in range(C):\n",
    "        subset = H_train[y_train == c]        # (Nc, D)\n",
    "        m      = subset.float().mean(dim=0)   # (D,)\n",
    "        class_HDVs.append(torch.round(m).int())\n",
    "    return torch.stack(class_HDVs, dim=0)    # (C, D)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(H_test, class_HDVs):\n",
    "    \"\"\"\n",
    "    Nearest-neighbor by Hamming distance.\n",
    "    H_test:     (M, D), class_HDVs: (C, D)\n",
    "    returns:    (M,) predicted labels\n",
    "    \"\"\"\n",
    "    diffs = H_test.unsqueeze(1) != class_HDVs.unsqueeze(0)  # (M, C, D)\n",
    "    dists = diffs.sum(dim=2)                                # (M, C)\n",
    "    return dists.argmin(dim=1)                              # (M,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4f8603-d210-4341-a6ed-d2c2304b49f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15000 17250 19000 21250 23250 25250 27000 29000 31000 33000 35000]\n"
     ]
    }
   ],
   "source": [
    "# hyperdims = hyperdims // 100\n",
    "print(hyperdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecad34f-a084-4791-8cb8-50bd89bf91d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Hyperdimension: 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:17<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2730 for Hyperdim 15000\n",
      "\n",
      "==> Hyperdimension: 17250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:20<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2740 for Hyperdim 17250\n",
      "\n",
      "==> Hyperdimension: 19000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2714 for Hyperdim 19000\n",
      "\n",
      "==> Hyperdimension: 21250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:25<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2738 for Hyperdim 21250\n",
      "\n",
      "==> Hyperdimension: 23250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2709 for Hyperdim 23250\n",
      "\n",
      "==> Hyperdimension: 25250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:29<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2728 for Hyperdim 25250\n",
      "\n",
      "==> Hyperdimension: 27000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2734 for Hyperdim 27000\n",
      "\n",
      "==> Hyperdimension: 29000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:33<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2760 for Hyperdim 29000\n",
      "\n",
      "==> Hyperdimension: 31000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:36<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2713 for Hyperdim 31000\n",
      "\n",
      "==> Hyperdimension: 33000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:38<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2767 for Hyperdim 33000\n",
      "\n",
      "==> Hyperdimension: 35000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:40<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.2752 for Hyperdim 35000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits   = 20\n",
    "accuracies = np.zeros((len(hyperdims), n_splits), dtype=float)\n",
    "for idx, D in enumerate(hyperdims):\n",
    "    print(f\"\\n==> Hyperdimension: {D}\")\n",
    "    torch.manual_seed(idx)\n",
    "    np.random.seed(idx)\n",
    "    random.seed(idx)\n",
    "    base_HDVs  = generate_base_HDVs(D, B, device, seed=idx)\n",
    "    H_train    = encode_dataset_batched(X_train, base_HDVs, batch_size)\n",
    "    class_HDVs = encode_class_HDVs(H_train, y_train, C)\n",
    "\n",
    "    for i in tqdm(range(n_splits)):\n",
    "        s, e = i * split_size, (i + 1) * split_size\n",
    "        Xs, ys = X_test[s:e], y_test[s:e]\n",
    "\n",
    "        Hs    = encode_dataset_batched(Xs, base_HDVs, batch_size)\n",
    "        preds = predict(Hs, class_HDVs)\n",
    "    \n",
    "        accuracies[idx, i] = (preds == ys).float().mean().item()\n",
    "        # print(f'Accuracy for split index {i}: {accuracies[idx, i]}')\n",
    "\n",
    "    print(f\"Average accuracy: {accuracies[idx].mean().item():.4f} for Hyperdim {D}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "719833bb-f58b-47c9-a9b8-df2157a414ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat, loadmat\n",
    "savemat('HoloGN_CIFAR10.mat', {'HoloGN_CIFAR10': accuracies*100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96528463-249b-423f-b9f6-5cbf50b70157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([27.30000131, 27.40000106, 27.14000128, 27.38000073, 27.09000126,\n",
       "        27.28000127, 27.34000131, 27.60000132, 27.13000111, 27.67000124,\n",
       "        27.52000131]),\n",
       " array([1.90840236, 2.03076367, 2.19827214, 2.00189911, 1.94676688,\n",
       "        1.98937191, 1.78896647, 2.00698792, 2.12252235, 2.01124322,\n",
       "        2.20671725]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies*100, axis=1), np.std(accuracies*100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738f8ff0-53e4-47df-b796-9bede3b64051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

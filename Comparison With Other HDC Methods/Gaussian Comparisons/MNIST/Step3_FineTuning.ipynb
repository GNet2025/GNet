{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b205922c-74f0-4af8-a50d-c8b71836fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "# from Modules import ConvBN, PoolConvBN, PoolLinearBN, SharpCosSim2d, SharpCosSimLinear, LReLU\n",
    "\n",
    "from ConvBN import ConvBN as ConvBN_BiasTrick\n",
    "from LinearBN import LinearBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4ea2e3-7ceb-4c26-9486-6aed180b8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LReLU, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(5.0)) \n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.alpha*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b5c134-e7ca-46ee-b611-95c60897ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize with mean 0.5 and std 0.5\n",
    "])\n",
    "\n",
    "batch_size= 2000\n",
    "num_workers=2\n",
    "pin_memory=True\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root='../', train=True, download=True, transform=transform)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [58000, 2000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='../', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "291b17b9-fa3d-4d1e-a240-8b99507b068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254cdf0d-6db0-45cb-91bd-6a5e562be96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1_out = 32\n",
    "        self.conv1_size = 5\n",
    "        self.conv1_padding = 2\n",
    "\n",
    "\n",
    "        self.conv2_out = 64\n",
    "        self.conv2_size = 5\n",
    "        self.conv2_padding = 2\n",
    "\n",
    "        self.fc1_out = 512\n",
    "        self.fc2_out = 10\n",
    "\n",
    "        self.q = 1e-6\n",
    "        self.bias_trick_par = nn.Parameter(torch.tensor(0.00005))\n",
    "\n",
    "        # First Convolutional Block\n",
    "\n",
    "        self.block1 = ConvBN_BiasTrick(in_channels=1, out_channels=self.conv1_out, kernel_size=self.conv1_size, padding=self.conv1_padding, std = .05, bias_par_init=0.001)\n",
    "        self.block2 = ConvBN_BiasTrick(in_channels=self.conv1_out, out_channels=self.conv2_out, kernel_size=self.conv2_size, padding=self.conv2_padding, std = .05, bias_par_init=0.01)\n",
    "\n",
    "        # Second Convolutional Block\n",
    "       \n",
    "        self.block3 = LinearBN(in_features = self.conv2_out * (28//2//2) * (28//2//2), out_features=self.fc1_out, std=.3)\n",
    "        \n",
    "        \n",
    "        # torch.manual_seed(0)\n",
    "        self.w2 = nn.Parameter(torch.randn(self.fc1_out, self.fc2_out))\n",
    "        nn.init.normal_(self.w2, mean=0.0, std=.6)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.relu = LReLU()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(self.relu(self.block1(x)), (2,2), padding=0)\n",
    "        x = F.max_pool2d(self.relu(self.block2(x)), (2,2), padding=0)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.relu(self.block3(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x + self.bias_trick_par\n",
    "        x_norm = x / (x.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize input x\n",
    "        w2_norm = self.w2 / (self.w2.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize weights\n",
    "        x = torch.matmul(x_norm, w2_norm) # Matrix multiplication \n",
    "\n",
    "        # Return raw logits (no softmax here, CrossEntropyLoss handles it)\n",
    "        return x\n",
    "\n",
    "    def custom_round(self, n):\n",
    "        remainder = n % 1000\n",
    "        base = n - remainder\n",
    "        if remainder >= 101:\n",
    "            return base + 1000\n",
    "        elif remainder <= 100:\n",
    "            return base\n",
    "            \n",
    "\n",
    "    def init_hdc(self, ratio, seed):\n",
    "        if not isinstance(ratio, (tuple)):\n",
    "            raise TypeError(\"ratio must be a tuple of size 3\")\n",
    "\n",
    "        if not isinstance(seed, (tuple)):\n",
    "            raise TypeError(\"seed must be a tuple of size 3\")\n",
    "        \n",
    "        self.block1.init_hdc(ratio = ratio[0], seed = seed[0])\n",
    "        self.block2.init_hdc(ratio = ratio[1], seed = seed[1])\n",
    "        self.block3.init_hdc(ratio = ratio[2], seed = seed[2])\n",
    "                \n",
    "        n_last = self.w2.size(0)\n",
    "        nHDC_last = int(self.custom_round(ratio[3] * n_last))\n",
    "        torch.manual_seed(seed[3])\n",
    "        self.g = torch.randn(self.w2.size(0), nHDC_last, device=self.w2.device).to(torch.half)\n",
    "        self.wg = torch.sign(torch.matmul(self.g.t(), self.w2.to(torch.half)))\n",
    "\n",
    "        print(f'Block1: {self.block1.nHDC}, Block2: {self.block2.nHDC}, Block3: {self.block3.nHDC}, Classification Layer: {nHDC_last}')\n",
    "\n",
    "    def hdc(self, x):\n",
    "        x = F.max_pool2d(self.relu(self.block1.hdc(x)), (2,2), padding=0)\n",
    "        x = F.max_pool2d(self.relu(self.block2.hdc(x)), (2,2), padding=0)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.block3.hdc(x))\n",
    "\n",
    "        x = x + self.bias_trick_par\n",
    "        x = torch.sign(torch.matmul(x.to(torch.half), self.g))\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def classification_layer(self, x):\n",
    "        x = x @ self.wg\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788067b5-08fc-4c48-b997-4c94a5a0bf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block1: 10000, Block2: 10000, Block3: 10000, Classification Layer: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train hdc: 100%|█████████████████████████████████████████████████████████████████| 60000/60000 [55:48<00:00, 17.92it/s]\n",
      "test hdc: 100%|██████████████████████████████████████████████████████████████████| 10000/10000 [09:25<00:00, 17.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.nn.parallel import data_parallel\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = Network().to(device)\n",
    "model.load_state_dict(torch.load('MNIST_GNet_Training_99.35.pth', weights_only = True))\n",
    "\n",
    "\n",
    "model.to(torch.half).to(device)\n",
    "model.eval()\n",
    "\n",
    "ratio = (12, 1.15/6, 3, 18)\n",
    "torch.manual_seed(0)\n",
    "random_seeds = tuple(torch.randint(0, 1000, (1,)).item() for _ in range(4))\n",
    "model.init_hdc(ratio, random_seeds)\n",
    "\n",
    "batch_size=1\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='../', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='../', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "train_outputs = []\n",
    "train_labels = []\n",
    "test_outputs = []\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(trainloader, desc='train hdc'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = model.hdc(images.to(torch.half))\n",
    "        train_outputs.append(output.cpu())\n",
    "        train_labels.append(labels.cpu())\n",
    "\n",
    "    for images, labels in tqdm(testloader, desc='test hdc'):\n",
    "        images = images.to(device).to(torch.half)\n",
    "        output = model.hdc(images)\n",
    "        test_outputs.append(output.cpu())\n",
    "        test_labels.append(labels.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "717da94d-0eda-4e6c-a6e8-2b120515ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_outputs = torch.cat(train_outputs, dim=0)\n",
    "train_labels = torch.cat(train_labels, dim=0)\n",
    "trainset = TensorDataset(train_outputs, train_labels)\n",
    "trainloader_hdc = DataLoader(trainset, batch_size=420, shuffle=False)\n",
    "\n",
    "test_outputs = torch.cat(test_outputs, dim=0)\n",
    "test_labels = torch.cat(test_labels, dim=0)\n",
    "testset = TensorDataset(test_outputs, test_labels)\n",
    "testloader_hdc = DataLoader(testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ce0cee-994c-4ed1-8d7b-c27265a6189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear(nn.Module):\n",
    "    def __init__(self, hyperdim, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.Tensor(hyperdim, num_classes))\n",
    "        nn.init.xavier_normal_(self.w)\n",
    "        self.hyperdim=hyperdim\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x @ self.w\n",
    "        x = x * (1 / self.hyperdim**0.5)\n",
    "\n",
    "        return x        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eabddd9-fc09-42fa-b2ef-c225ca63426f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:05<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "wg3 = linear(hyperdim=10000, num_classes=10) # Hyperdim should be the same as the classification layer nHDC\n",
    "wg3_half = wg3.to(torch.half)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(wg3.parameters(), lr = 1e-4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wg3 = wg3.to(device).to(torch.float32)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    wg3 = torch.nn.DataParallel(wg3)\n",
    "num_epochs = 100\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    wg3.train()\n",
    "    for hdc_input, labels in trainloader_hdc:\n",
    "        hdc_input, labels = hdc_input.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = wg3(hdc_input.to(torch.float32))\n",
    "        if torch.isnan(outputs).any():\n",
    "            print('here')\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "          \n",
    "        # with torch.no_grad():\n",
    "            # wg3.w.data = torch.clamp(wg3.w.data, -1.0, 1.0)\n",
    "            \n",
    "    # if epoch % 5 == 0:\n",
    "wg3.w.data = torch.sign(wg3.w.data)\n",
    "model.wg.data = torch.sign(wg3.w.data).to(torch.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbdd96c0-b2f7-43d0-ad42-7d84e397c46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.17\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader):\n",
    "    # model.load_state_dict(torch.load('saved_model.pth'))\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.cuda(non_blocking=True), labels.cuda(non_blocking=True)  # Move data to GPU\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "\n",
    "print(test(wg3.to(torch.half), testloader_hdc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759207c-13ce-47d3-9bec-47d270ff8b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

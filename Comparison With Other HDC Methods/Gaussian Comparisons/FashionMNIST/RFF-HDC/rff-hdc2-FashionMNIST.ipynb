{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db26120b-d35f-4a1b-9a0e-55492ec9fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from utils import HDDataset\n",
    "from model import BModel\n",
    "from torchvision import datasets, transforms\n",
    "import scipy\n",
    "from encoder import RandomFourierEncoder\n",
    "import main2_fmnist \n",
    "import importlib\n",
    "importlib.reload(main2_fmnist)\n",
    "import csv\n",
    "from scipy.io import savemat, loadmat\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4b9127-d38c-49d7-a86e-b16874c0a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e6ccde-949a-443c-8624-34d66f7a8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "gorder = 2\n",
    "dim = 10000\n",
    "gamma = 0.3\n",
    "lr = 0.01\n",
    "classes = 10\n",
    "channels = 3\n",
    "epochs = 3\n",
    "train = main2_fmnist.train\n",
    "test = main2_fmnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33a62c-6f81-4e5c-aed4-5404383a38ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5000  7333  9000 11333 13333 15000 17333 19000 21333 23000 25000]\n",
      "tensor(784)\n",
      "nHDC: 5000 ------------\n",
      "the threshold to discretize fourier features to group elements tensor([0.])\n",
      "Split Index: 1\n",
      "Split Index: 2\n",
      "Split Index: 3\n",
      "Split Index: 4\n",
      "Split Index: 5\n",
      "Split Index: 6\n",
      "Split Index: 7\n",
      "Split Index: 8\n",
      "Split Index: 9\n",
      "Split Index: 10\n",
      "Split Index: 11\n",
      "Split Index: 12\n",
      "Split Index: 13\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.FashionMNIST(root='../../Data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = datasets.FashionMNIST(root='../../Data', train=False, download=True, transform=transforms.ToTensor())\n",
    "n_splits = 20\n",
    "split_size = len(testset) // n_splits\n",
    "accuracies1 = np.zeros((11, n_splits))\n",
    "hyperdims = loadmat('../EHDGNet_FashionMNIST_nHD.mat')['EHDGNet_FashionMNIST_nHD']\n",
    "hyperdims = np.mean(hyperdims, axis=1, dtype=int)\n",
    "print(hyperdims)\n",
    "input_dim = torch.prod(torch.tensor(list(trainset[0][0].size())))\n",
    "print(input_dim)\n",
    "for i, nHDC in enumerate(hyperdims):\n",
    "    print(f'nHDC: {nHDC} ------------')\n",
    "    encoder = RandomFourierEncoder(input_dim, gamma, gorder, output_dim=nHDC)\n",
    "    encoder.build_item_mem()\n",
    "    train_hd, y_train = encoder.encode_data_extract_labels(trainset)\n",
    "    train_dataset = HDDataset(train_hd, y_train)\n",
    "    trainloader = DataLoader(train_dataset, batch_size=1024, shuffle=True, pin_memory=True, num_workers=2)\n",
    "    for split_idx in range(n_splits):\n",
    "        # Test\n",
    "        print(f'Split Index: {split_idx+1}')\n",
    "        start_idx = split_idx * split_size\n",
    "        end_idx = start_idx + split_size\n",
    "        split_subset = Subset(testset, range(start_idx, end_idx))\n",
    "        test_hd, y_test = encoder.encode_data_extract_labels(split_subset)\n",
    "        test_dataset = HDDataset(test_hd, y_test)\n",
    "        testloader = DataLoader(test_dataset, batch_size=512, shuffle=False, pin_memory=True, num_workers=2)\n",
    "        accuracies1[i, split_idx] = train(trainloader, testloader, lr, nHDC)\n",
    "        del testloader\n",
    "        del test_dataset\n",
    "        del test_hd\n",
    "        \n",
    "    del train_hd\n",
    "    del trainloader\n",
    "    del train_dataset\n",
    "    print(f'nHDC: {nHDC} ----------- Finished')\n",
    "    print(f'Average Accuracy for nHDC={nHDC}: {np.mean(accuracies1[i, :])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3fffc-ced3-496d-80cd-28ebdc6085ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a1610cd-f9bf-43d0-a1d9-5688e0e45054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73.97, 80.94, 81.12, 82.32, 82.08, 83.99, 83.02, 84.76, 84.73,\n",
       "       85.3 , 84.53])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd1d5f32-33f1-49ef-8303-a61dc3bd53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('RFFHDC_FashionMNIST.mat', {'RFFHDC_FashionMNIST': accuracies1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2612b-3fd4-4f56-bd6f-9ea02c1a2f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e724f-b6b0-4a8e-bbec-2d3fec31dfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fdf28c-f372-4dd7-bd54-a7aa2ed65849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "# from Modules import ConvBN, PoolConvBN, PoolLinearBN, SharpCosSim2d, SharpCosSimLinear, LReLU\n",
    "\n",
    "from ConvBN import ConvBN as ConvBN_BiasTrick\n",
    "from LinearBN import LinearBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748ecd3a-7ffc-4bbb-8694-a567b6e10082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LReLU, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(5.0)) \n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.alpha*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff8a703-c4d7-4c63-98fc-97d8ef46a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize with mean 0.5 and std 0.5\n",
    "])\n",
    "\n",
    "batch_size= 2000\n",
    "num_workers=2\n",
    "pin_memory=True\n",
    "\n",
    "dataset = torchvision.datasets.FashionMNIST(root='../', train=True, download=True, transform=transform)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [58000, 2000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(root='../', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aced529a-d3ba-4a60-980e-2623e755c88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7565906-2310-4a40-b7a7-627f2e2de45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1_out = 32\n",
    "        self.conv1_size = 3\n",
    "        self.conv1_padding = 1\n",
    "\n",
    "\n",
    "        # self.conv2_out = 16\n",
    "        # self.conv2_size = 5\n",
    "        # self.conv2_padding = 0\n",
    "\n",
    "        self.fc1_out = 512\n",
    "        self.fc2_out = 10\n",
    "\n",
    "        self.q = 1e-6\n",
    "        self.bias_trick_par = nn.Parameter(torch.tensor(0.00005))\n",
    "\n",
    "        # First Convolutional Block\n",
    "\n",
    "        self.block1 = ConvBN_BiasTrick(in_channels=1, out_channels=self.conv1_out, kernel_size=self.conv1_size, padding=self.conv1_padding, std = .7)\n",
    "\n",
    "        # Second Convolutional Block\n",
    "       \n",
    "        self.block3 = LinearBN(in_features = self.conv1_out * (28//2) * (28//2), out_features=self.fc1_out, std=.01)\n",
    "        \n",
    "        \n",
    "        # torch.manual_seed(0)\n",
    "        self.w2 = nn.Parameter(torch.randn(self.fc1_out, self.fc2_out))\n",
    "        nn.init.normal_(self.w2, mean=0.0, std=.6)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.dropout2d = nn.Dropout2d(0.25)\n",
    "\n",
    "        self.relu = LReLU()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(self.relu(self.block1(x)), (2,2), padding=0)\n",
    "        x = self.dropout2d(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.relu(self.block3(x))\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = x + self.bias_trick_par\n",
    "        x_norm = x / (x.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize input x\n",
    "        w2_norm = self.w2 / (self.w2.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize weights\n",
    "        x = torch.matmul(x_norm, w2_norm) # Matrix multiplication \n",
    "\n",
    "        # Return raw logits (no softmax here, CrossEntropyLoss handles it)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab82256-86aa-432f-a31d-a6f210a08745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.00063 accuracy: 0.6223 val loss: 0.00035 val accuracy: 0.7625 time: 5.23 seconds\n",
      "[epoch 2] loss: 0.00031 accuracy: 0.7849 val loss: 0.00025 val accuracy: 0.8395 time: 5.13 seconds\n",
      "[epoch 3] loss: 0.00025 accuracy: 0.8356 val loss: 0.00021 val accuracy: 0.8610 time: 4.78 seconds\n",
      "[epoch 4] loss: 0.00022 accuracy: 0.8590 val loss: 0.00019 val accuracy: 0.8805 time: 4.90 seconds\n",
      "[epoch 5] loss: 0.00019 accuracy: 0.8741 val loss: 0.00018 val accuracy: 0.8725 time: 4.77 seconds\n",
      "[epoch 6] loss: 0.00018 accuracy: 0.8809 val loss: 0.00016 val accuracy: 0.8915 time: 5.04 seconds\n",
      "[epoch 7] loss: 0.00017 accuracy: 0.8854 val loss: 0.00015 val accuracy: 0.8995 time: 5.09 seconds\n",
      "[epoch 8] loss: 0.00016 accuracy: 0.8940 val loss: 0.00014 val accuracy: 0.9080 time: 4.91 seconds\n",
      "[epoch 9] loss: 0.00015 accuracy: 0.8979 val loss: 0.00015 val accuracy: 0.8975 time: 4.86 seconds\n",
      "[epoch 10] loss: 0.00014 accuracy: 0.9016 val loss: 0.00013 val accuracy: 0.9085 time: 5.15 seconds\n",
      "[epoch 11] loss: 0.00014 accuracy: 0.9039 val loss: 0.00014 val accuracy: 0.8990 time: 4.97 seconds\n",
      "[epoch 12] loss: 0.00013 accuracy: 0.9092 val loss: 0.00013 val accuracy: 0.9070 time: 5.07 seconds\n",
      "[epoch 13] loss: 0.00013 accuracy: 0.9091 val loss: 0.00012 val accuracy: 0.9105 time: 4.92 seconds\n",
      "[epoch 14] loss: 0.00013 accuracy: 0.9152 val loss: 0.00012 val accuracy: 0.9120 time: 4.96 seconds\n",
      "[epoch 15] loss: 0.00013 accuracy: 0.9146 val loss: 0.00013 val accuracy: 0.9115 time: 4.91 seconds\n",
      "[epoch 16] loss: 0.00013 accuracy: 0.9144 val loss: 0.00012 val accuracy: 0.9095 time: 5.05 seconds\n",
      "[epoch 17] loss: 0.00012 accuracy: 0.9180 val loss: 0.00012 val accuracy: 0.9130 time: 4.95 seconds\n",
      "[epoch 18] loss: 0.00012 accuracy: 0.9167 val loss: 0.00012 val accuracy: 0.9115 time: 4.83 seconds\n",
      "[epoch 19] loss: 0.00012 accuracy: 0.9161 val loss: 0.00013 val accuracy: 0.9060 time: 4.92 seconds\n",
      "[epoch 20] loss: 0.00012 accuracy: 0.9198 val loss: 0.00011 val accuracy: 0.9215 time: 5.00 seconds\n",
      "[epoch 21] loss: 0.00011 accuracy: 0.9243 val loss: 0.00012 val accuracy: 0.9155 time: 4.76 seconds\n",
      "[epoch 22] loss: 0.00012 accuracy: 0.9191 val loss: 0.00012 val accuracy: 0.9175 time: 4.95 seconds\n",
      "[epoch 23] loss: 0.00011 accuracy: 0.9246 val loss: 0.00012 val accuracy: 0.9215 time: 5.09 seconds\n",
      "[epoch 24] loss: 0.00011 accuracy: 0.9271 val loss: 0.00012 val accuracy: 0.9220 time: 5.21 seconds\n",
      "[epoch 25] loss: 0.00011 accuracy: 0.9279 val loss: 0.00012 val accuracy: 0.9160 time: 4.98 seconds\n",
      "[epoch 26] loss: 0.00011 accuracy: 0.9296 val loss: 0.00012 val accuracy: 0.9160 time: 4.93 seconds\n",
      "[epoch 27] loss: 0.00011 accuracy: 0.9272 val loss: 0.00013 val accuracy: 0.9100 time: 4.88 seconds\n",
      "[epoch 28] loss: 0.00011 accuracy: 0.9272 val loss: 0.00012 val accuracy: 0.9140 time: 4.95 seconds\n",
      "[epoch 29] loss: 0.00011 accuracy: 0.9284 val loss: 0.00012 val accuracy: 0.9215 time: 5.04 seconds\n",
      "[epoch 30] loss: 0.00011 accuracy: 0.9293 val loss: 0.00012 val accuracy: 0.9175 time: 5.20 seconds\n",
      "[epoch 31] loss: 0.00011 accuracy: 0.9249 val loss: 0.00012 val accuracy: 0.9185 time: 4.91 seconds\n",
      "[epoch 32] loss: 0.00009 accuracy: 0.9430 val loss: 0.00011 val accuracy: 0.9250 time: 4.92 seconds\n",
      "[epoch 33] loss: 0.00008 accuracy: 0.9521 val loss: 0.00011 val accuracy: 0.9265 time: 4.79 seconds\n",
      "[epoch 34] loss: 0.00008 accuracy: 0.9562 val loss: 0.00010 val accuracy: 0.9300 time: 5.02 seconds\n",
      "[epoch 35] loss: 0.00007 accuracy: 0.9582 val loss: 0.00010 val accuracy: 0.9315 time: 5.06 seconds\n",
      "[epoch 36] loss: 0.00007 accuracy: 0.9611 val loss: 0.00011 val accuracy: 0.9280 time: 4.84 seconds\n",
      "[epoch 37] loss: 0.00007 accuracy: 0.9621 val loss: 0.00010 val accuracy: 0.9290 time: 4.75 seconds\n",
      "[epoch 38] loss: 0.00007 accuracy: 0.9645 val loss: 0.00011 val accuracy: 0.9280 time: 4.94 seconds\n",
      "[epoch 39] loss: 0.00006 accuracy: 0.9667 val loss: 0.00010 val accuracy: 0.9255 time: 5.03 seconds\n",
      "[epoch 40] loss: 0.00006 accuracy: 0.9668 val loss: 0.00011 val accuracy: 0.9295 time: 4.99 seconds\n",
      "[epoch 41] loss: 0.00006 accuracy: 0.9685 val loss: 0.00010 val accuracy: 0.9320 time: 4.85 seconds\n",
      "[epoch 42] loss: 0.00006 accuracy: 0.9701 val loss: 0.00010 val accuracy: 0.9320 time: 4.77 seconds\n",
      "[epoch 43] loss: 0.00006 accuracy: 0.9701 val loss: 0.00010 val accuracy: 0.9325 time: 4.86 seconds\n",
      "[epoch 44] loss: 0.00006 accuracy: 0.9697 val loss: 0.00011 val accuracy: 0.9290 time: 4.81 seconds\n",
      "[epoch 45] loss: 0.00006 accuracy: 0.9719 val loss: 0.00010 val accuracy: 0.9315 time: 5.15 seconds\n",
      "[epoch 46] loss: 0.00006 accuracy: 0.9735 val loss: 0.00010 val accuracy: 0.9350 time: 4.88 seconds\n",
      "[epoch 47] loss: 0.00006 accuracy: 0.9726 val loss: 0.00010 val accuracy: 0.9320 time: 5.14 seconds\n",
      "[epoch 48] loss: 0.00006 accuracy: 0.9741 val loss: 0.00010 val accuracy: 0.9325 time: 4.98 seconds\n",
      "[epoch 49] loss: 0.00005 accuracy: 0.9754 val loss: 0.00010 val accuracy: 0.9330 time: 5.03 seconds\n",
      "[epoch 50] loss: 0.00006 accuracy: 0.9745 val loss: 0.00010 val accuracy: 0.9315 time: 5.15 seconds\n",
      "[epoch 51] loss: 0.00005 accuracy: 0.9755 val loss: 0.00010 val accuracy: 0.9305 time: 5.03 seconds\n",
      "[epoch 52] loss: 0.00005 accuracy: 0.9770 val loss: 0.00010 val accuracy: 0.9295 time: 5.27 seconds\n",
      "[epoch 53] loss: 0.00005 accuracy: 0.9760 val loss: 0.00011 val accuracy: 0.9345 time: 4.79 seconds\n",
      "[epoch 54] loss: 0.00005 accuracy: 0.9776 val loss: 0.00011 val accuracy: 0.9330 time: 4.86 seconds\n",
      "[epoch 55] loss: 0.00005 accuracy: 0.9761 val loss: 0.00010 val accuracy: 0.9350 time: 4.93 seconds\n",
      "[epoch 56] loss: 0.00005 accuracy: 0.9771 val loss: 0.00010 val accuracy: 0.9315 time: 4.98 seconds\n",
      "[epoch 57] loss: 0.00005 accuracy: 0.9798 val loss: 0.00010 val accuracy: 0.9360 time: 4.77 seconds\n",
      "[epoch 58] loss: 0.00004 accuracy: 0.9833 val loss: 0.00010 val accuracy: 0.9345 time: 4.91 seconds\n",
      "[epoch 59] loss: 0.00004 accuracy: 0.9854 val loss: 0.00010 val accuracy: 0.9335 time: 4.81 seconds\n",
      "[epoch 60] loss: 0.00004 accuracy: 0.9853 val loss: 0.00010 val accuracy: 0.9350 time: 4.87 seconds\n",
      "[epoch 61] loss: 0.00004 accuracy: 0.9862 val loss: 0.00010 val accuracy: 0.9340 time: 4.93 seconds\n",
      "[epoch 62] loss: 0.00004 accuracy: 0.9867 val loss: 0.00010 val accuracy: 0.9340 time: 4.75 seconds\n",
      "[epoch 63] loss: 0.00004 accuracy: 0.9871 val loss: 0.00010 val accuracy: 0.9330 time: 4.88 seconds\n",
      "[epoch 64] loss: 0.00004 accuracy: 0.9869 val loss: 0.00010 val accuracy: 0.9345 time: 4.95 seconds\n",
      "[epoch 65] loss: 0.00004 accuracy: 0.9875 val loss: 0.00010 val accuracy: 0.9340 time: 4.85 seconds\n",
      "[epoch 66] loss: 0.00004 accuracy: 0.9869 val loss: 0.00010 val accuracy: 0.9340 time: 4.94 seconds\n",
      "[epoch 67] loss: 0.00004 accuracy: 0.9880 val loss: 0.00010 val accuracy: 0.9320 time: 4.83 seconds\n",
      "[epoch 68] loss: 0.00004 accuracy: 0.9881 val loss: 0.00010 val accuracy: 0.9340 time: 4.75 seconds\n",
      "[epoch 69] loss: 0.00004 accuracy: 0.9887 val loss: 0.00010 val accuracy: 0.9330 time: 5.10 seconds\n",
      "[epoch 70] loss: 0.00004 accuracy: 0.9884 val loss: 0.00010 val accuracy: 0.9330 time: 5.04 seconds\n",
      "[epoch 71] loss: 0.00004 accuracy: 0.9884 val loss: 0.00010 val accuracy: 0.9335 time: 4.93 seconds\n",
      "[epoch 72] loss: 0.00004 accuracy: 0.9885 val loss: 0.00010 val accuracy: 0.9340 time: 4.74 seconds\n",
      "[epoch 73] loss: 0.00004 accuracy: 0.9893 val loss: 0.00010 val accuracy: 0.9340 time: 5.11 seconds\n",
      "[epoch 74] loss: 0.00004 accuracy: 0.9891 val loss: 0.00010 val accuracy: 0.9335 time: 5.02 seconds\n",
      "[epoch 75] loss: 0.00004 accuracy: 0.9888 val loss: 0.00010 val accuracy: 0.9340 time: 4.89 seconds\n",
      "[epoch 76] loss: 0.00004 accuracy: 0.9888 val loss: 0.00010 val accuracy: 0.9340 time: 4.94 seconds\n",
      "[epoch 77] loss: 0.00004 accuracy: 0.9890 val loss: 0.00010 val accuracy: 0.9350 time: 4.86 seconds\n",
      "[epoch 78] loss: 0.00004 accuracy: 0.9887 val loss: 0.00010 val accuracy: 0.9350 time: 4.85 seconds\n",
      "[epoch 79] loss: 0.00004 accuracy: 0.9889 val loss: 0.00010 val accuracy: 0.9340 time: 4.88 seconds\n",
      "[epoch 80] loss: 0.00004 accuracy: 0.9890 val loss: 0.00010 val accuracy: 0.9340 time: 4.99 seconds\n",
      "[epoch 81] loss: 0.00004 accuracy: 0.9890 val loss: 0.00010 val accuracy: 0.9340 time: 5.08 seconds\n",
      "[epoch 82] loss: 0.00004 accuracy: 0.9892 val loss: 0.00010 val accuracy: 0.9340 time: 4.88 seconds\n",
      "[epoch 83] loss: 0.00004 accuracy: 0.9889 val loss: 0.00010 val accuracy: 0.9340 time: 5.02 seconds\n",
      "[epoch 84] loss: 0.00004 accuracy: 0.9882 val loss: 0.00010 val accuracy: 0.9340 time: 4.84 seconds\n",
      "[epoch 85] loss: 0.00004 accuracy: 0.9891 val loss: 0.00010 val accuracy: 0.9345 time: 4.94 seconds\n",
      "[epoch 86] loss: 0.00004 accuracy: 0.9891 val loss: 0.00010 val accuracy: 0.9345 time: 4.88 seconds\n",
      "[epoch 87] loss: 0.00004 accuracy: 0.9885 val loss: 0.00010 val accuracy: 0.9340 time: 4.97 seconds\n",
      "[epoch 88] loss: 0.00004 accuracy: 0.9892 val loss: 0.00010 val accuracy: 0.9345 time: 5.17 seconds\n",
      "[epoch 89] loss: 0.00004 accuracy: 0.9885 val loss: 0.00010 val accuracy: 0.9345 time: 5.01 seconds\n",
      "[epoch 90] loss: 0.00004 accuracy: 0.9885 val loss: 0.00010 val accuracy: 0.9345 time: 5.03 seconds\n",
      "[epoch 91] loss: 0.00004 accuracy: 0.9892 val loss: 0.00010 val accuracy: 0.9345 time: 4.92 seconds\n",
      "[epoch 92] loss: 0.00004 accuracy: 0.9896 val loss: 0.00010 val accuracy: 0.9345 time: 4.72 seconds\n",
      "[epoch 93] loss: 0.00004 accuracy: 0.9886 val loss: 0.00010 val accuracy: 0.9345 time: 4.85 seconds\n",
      "[epoch 94] loss: 0.00004 accuracy: 0.9888 val loss: 0.00010 val accuracy: 0.9345 time: 4.73 seconds\n",
      "[epoch 95] loss: 0.00004 accuracy: 0.9889 val loss: 0.00010 val accuracy: 0.9345 time: 5.23 seconds\n",
      "[epoch 96] loss: 0.00004 accuracy: 0.9889 val loss: 0.00010 val accuracy: 0.9345 time: 5.04 seconds\n",
      "[epoch 97] loss: 0.00004 accuracy: 0.9889 val loss: 0.00010 val accuracy: 0.9345 time: 4.94 seconds\n",
      "[epoch 98] loss: 0.00004 accuracy: 0.9886 val loss: 0.00010 val accuracy: 0.9345 time: 4.85 seconds\n",
      "[epoch 99] loss: 0.00004 accuracy: 0.9889 val loss: 0.00010 val accuracy: 0.9345 time: 4.77 seconds\n",
      "[epoch 100] loss: 0.00004 accuracy: 0.9893 val loss: 0.00010 val accuracy: 0.9345 time: 4.78 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time  # Import time module\n",
    "\n",
    "train = True\n",
    "model = Network().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Trained 100 Epochs with lr=0.025, 50 epochs with 0.005 and 50 epochs with 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.025, weight_decay=0.00001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "if train:\n",
    "    \n",
    "    loss_hist, acc_hist = [], []\n",
    "    loss_hist_val, acc_hist_val = [], []\n",
    "    \n",
    "    # Initialize variable to track the lowest validation accuracy\n",
    "    best_val_acc = -float('inf')  # Set to negative infinity initially to track the maximum accuracy\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        start_time = time.time()  # Record the start time of the epoch\n",
    "    \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        for data in train_loader:\n",
    "            batch, labels = data\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Compute training statistics\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "        avg_loss = running_loss / len(train_set)\n",
    "        avg_acc = correct / len(train_set)\n",
    "        loss_hist.append(avg_loss)\n",
    "        acc_hist.append(avg_acc)\n",
    "    \n",
    "        # Validation statistics\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.0\n",
    "            correct_val = 0\n",
    "            for data in val_loader:\n",
    "                batch, labels = data\n",
    "                batch, labels = batch.to(device), labels.to(device)\n",
    "                outputs = model(batch)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                loss_val += loss.item()\n",
    "            avg_loss_val = loss_val / len(val_set)\n",
    "            avg_acc_val = correct_val / len(val_set)\n",
    "            loss_hist_val.append(avg_loss_val)\n",
    "            acc_hist_val.append(avg_acc_val)\n",
    "        model.train()\n",
    "    \n",
    "        scheduler.step(avg_loss_val)\n",
    "    \n",
    "        # Check if the current validation accuracy is the best we've seen\n",
    "        if avg_acc_val > best_val_acc:\n",
    "            best_val_acc = avg_acc_val\n",
    "            # Save the model with the highest validation accuracy\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                torch.save(model.module.state_dict(), 'best_model_fashionmnist.pt')\n",
    "            else:\n",
    "                torch.save(model.state_dict(), 'best_model_fashionmnist.pt')\n",
    "    \n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.time() - start_time  # Calculate the time taken for this epoch\n",
    "    \n",
    "        print('[epoch %d] loss: %.5f accuracy: %.4f val loss: %.5f val accuracy: %.4f time: %.2f seconds' %\n",
    "              (epoch + 1, avg_loss, avg_acc, avg_loss_val, avg_acc_val, elapsed_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a83be87-bf65-4a82-95b6-89acf3fb356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.00012, Test accuracy: 0.9263\n"
     ]
    }
   ],
   "source": [
    "# Load the best model saved during training\n",
    "# model.load_state_dict(torch.load('best_model_fashionmnist.pt', weights_only=True))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=2000, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Get predictions and update the correct count\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute average loss and accuracy for the test set\n",
    "avg_test_loss = test_loss / len(test_set)\n",
    "avg_test_acc = correct_test / len(test_set)\n",
    "\n",
    "print(f\"Test loss: {avg_test_loss:.5f}, Test accuracy: {avg_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76533a3f-95b0-4a0c-b98a-91062a5a5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Fashionmnist_GNet_Training_92.63.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905783f-98c1-45ed-8a65-9ed6882107c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d20aaf5-4b1b-4071-8a0b-2aa72e6d3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.io import savemat, loadmat\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "from aeon.datasets import load_classification\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4cd7c8-5638-4539-95de-0541279dea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_name = 'Epilepsy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01554b4a-d8c9-4a2e-b2fb-f9f0cac273d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, metadata = load_classification(dataset_name, return_metadata=True, split='train')\n",
    "X_test, y_test = load_classification(dataset_name, split='test')\n",
    "if X_train.shape[0] < 200:\n",
    "    if X_test.shape[0] >= 200:\n",
    "        train_size = int((X_train.shape[0] + X_test.shape[0]) * 1/4)\n",
    "        x, y = load_classification(dataset_name)\n",
    "        X_train, y_train = x[:train_size, :], y[:train_size]\n",
    "        X_test, y_test = x[train_size:, :], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a612a5-9390-477b-a4d7-d55d0e093d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "if X_train.ndim == 3:\n",
    "    input_channels = X_train.shape[1]\n",
    "seq_length = X_train.shape[-1]\n",
    "if y_train.dtype == object or isinstance(y_train[0], str):\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6527de72-9784-4fa0-94a3-46f9258c0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "\n",
    "X_min = X_train_scaled.min(axis=0)\n",
    "X_max = X_train_scaled.max(axis=0)\n",
    "\n",
    "denom = (X_max - X_min)\n",
    "denom[denom == 0] = 1   # avoid division by zero\n",
    "\n",
    "X_train_norm = (X_train_scaled - X_min) / denom\n",
    "X_test_norm  = (X_test_scaled  - X_min) / denom\n",
    "\n",
    "# Optional: clip to [0,1] just in case\n",
    "X_train_norm = np.clip(X_train_norm, 0, 1)\n",
    "X_test_norm  = np.clip(X_test_norm, 0, 1)\n",
    "X_train_tensor = torch.tensor(X_train_norm, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_norm, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2634afb-9e0e-42bd-8e2f-41137c2a4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa900725-946b-475e-9814-d59361b25c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate bipolar lookup table\n",
    "def lookup_generate(dim: int, datatype: str, n_keys: int, device: torch.device):\n",
    "    if datatype != 'bipolar':\n",
    "        raise ValueError(\"Only 'bipolar' supported\")\n",
    "    tbl = torch.randint(0, 2, (n_keys, dim), device=device, dtype=torch.int8)\n",
    "    return tbl * 2 - 1  # map {0,1} → {-1,+1}\n",
    "\n",
    "# 2. Encode a batch of inputs into hypervectors\n",
    "@torch.no_grad()\n",
    "def encode_batch(X: torch.Tensor, position_table: torch.Tensor, grayscale_table: torch.Tensor):\n",
    "    n_keys = grayscale_table.shape[0]\n",
    "    X_normalized = ((X + 3) / 6) * (n_keys - 1)  # map [-3,3] → [0, n_keys-1]\n",
    "    X_indices = X_normalized.round().clamp(0, n_keys - 1).long()  # indices in [0, n_keys-1]\n",
    "    gray = grayscale_table[X_indices]            # (N, D_in, dim)\n",
    "    pos  = position_table.unsqueeze(0)           # (1, D_in, dim)\n",
    "    hv   = (pos * gray).sum(dim=1)               # (N, dim)\n",
    "    return hv\n",
    "\n",
    "# 3. Train associative memory by summing all encodings per class\n",
    "def train_am(X_train, Y_train, position_table, grayscale_table, dim: int):\n",
    "    H_train = encode_batch(X_train, position_table, grayscale_table).float()  # (N, dim)\n",
    "    C = int(Y_train.max().item()) + 1\n",
    "    am = torch.zeros((C, dim), device=X_train.device, dtype=torch.float32)\n",
    "    am = am.index_add(0, Y_train, H_train)\n",
    "    return am\n",
    "\n",
    "# 4. Single-image prediction (returns class and query HV)\n",
    "@torch.no_grad()\n",
    "def predict_(am, img, position_table, grayscale_table):\n",
    "    qhv = encode_batch(img.unsqueeze(0), position_table, grayscale_table).squeeze(0).float()\n",
    "    sims = F.cosine_similarity(qhv.unsqueeze(0), am, dim=1)  # (C,)\n",
    "    pred = int(sims.argmax().item())\n",
    "    return pred, qhv\n",
    "\n",
    "def predict(am, img, position_table, grayscale_table):\n",
    "    pred, _ = predict_(am, img, position_table, grayscale_table)\n",
    "    return pred\n",
    "\n",
    "# 5. Test on full set\n",
    "@torch.no_grad()\n",
    "def test(am, X_test, Y_test, position_table, grayscale_table):\n",
    "    H_test = encode_batch(X_test, position_table, grayscale_table).float()  # (N_test, dim)\n",
    "    h_norm = H_test.norm(dim=1, keepdim=True)                              # (N,1)\n",
    "    a_norm = am.norm(dim=1, keepdim=True).t()                              # (1,C)\n",
    "    sims   = (H_test @ am.t()) / (h_norm * a_norm)                         # (N,C)\n",
    "    preds  = sims.argmax(dim=1)                                            # (N,)\n",
    "    acc    = (preds == Y_test).float().mean().item()\n",
    "    print(f\"Testing accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "# 6. Load a saved model (AM + tables)\n",
    "def loadmodel(fpath: str, device: torch.device = None):\n",
    "    with open(fpath, 'rb') as f:\n",
    "        am_np, pos_np, gray_np = pickle.load(f)\n",
    "    am   = torch.from_numpy(am_np)\n",
    "    pos  = torch.from_numpy(pos_np)\n",
    "    gray = torch.from_numpy(gray_np)\n",
    "    if device is not None:\n",
    "        am, pos, gray = am.to(device), pos.to(device), gray.to(device)\n",
    "    return am, pos, gray\n",
    "\n",
    "# 7. Quantize the AM to a lower bit-width\n",
    "def quantize(am: torch.Tensor, before_bw: int, after_bw: int) -> torch.Tensor:\n",
    "    if before_bw <= after_bw:\n",
    "        return am.clone()\n",
    "    shift = before_bw - after_bw\n",
    "    return torch.round(am.float() / (2 ** shift)).to(am.dtype)\n",
    "\n",
    "# 8. Batched AM training\n",
    "@torch.no_grad()\n",
    "def train_am_batched(\n",
    "    X_train: torch.Tensor,\n",
    "    Y_train: torch.Tensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    dim: int,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> torch.Tensor:\n",
    "    N = X_train.shape[0]\n",
    "    C = int(Y_train.max().item()) + 1\n",
    "    am = torch.zeros(C, dim, device=device, dtype=torch.float32)\n",
    "    for i in (range(0, N, batch_size)):\n",
    "        xb = X_train[i : i + batch_size]\n",
    "        yb = torch.as_tensor(Y_train[i : i + batch_size], device=device)  # <== ✅ fixed\n",
    "        hb = encode_batch(xb, position_table, grayscale_table).float()\n",
    "        am = am.index_add(0, yb, hb)\n",
    "    return am\n",
    "\n",
    "# 9. Test on a split (non-batched)\n",
    "@torch.no_grad()\n",
    "def test_split(am, X_split, Y_split, position_table, grayscale_table):\n",
    "    Hs   = encode_batch(X_split, position_table, grayscale_table).float()  # (M, dim)\n",
    "    sims = F.cosine_similarity(Hs.unsqueeze(1), am.unsqueeze(0), dim=2)   # (M, C)\n",
    "    preds = sims.argmax(dim=1)                                            # (M,)\n",
    "    return (preds == Y_split).float().mean().item()\n",
    "\n",
    "# 10. Test on a split (batched)\n",
    "@torch.no_grad()\n",
    "def test_split_batched(\n",
    "    am: torch.Tensor,\n",
    "    X: torch.Tensor,\n",
    "    Y: torch.Tensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    encode_fn,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> float:\n",
    "    correct, total = 0, 0\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        xb = X[i : i + batch_size].to(device)\n",
    "        yb = Y[i : i + batch_size].to(device)\n",
    "        hb = encode_fn(xb, position_table, grayscale_table).float()\n",
    "        sims  = F.cosine_similarity(hb.unsqueeze(1), am.unsqueeze(0), dim=2)\n",
    "        preds = sims.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total   += yb.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89259e64-1712-41c6-820a-9717756be4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5666  6333  7333  8666  9666 10666 12000 13000 13666 14666 16000]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    hyperdims = np.mean(loadmat(f'../{dataset_name}_nHD.mat')[f'{dataset_name}_nHD'], \n",
    "                    axis=1, dtype=int)\n",
    "\n",
    "except:\n",
    "    hyperdims = range(5000, 15000, 2500)\n",
    "print(hyperdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296c6b84-bc6a-48d4-a900-f112ac138bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# n_rounds   = 20\n",
    "n_splits = 20\n",
    "split_size = len(test_data) // n_splits\n",
    "# hyperdims = range(20000, 23000, 1000)\n",
    "accuracies = np.zeros((len(hyperdims), n_splits))\n",
    "n_class    = num_classes\n",
    "q_bit      = 16\n",
    "print(split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aa5e183-a531-4935-a4b6-c229bd2f6672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137, 3, 206), (138, 3, 206))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e00421ac-c756-4410-b9e5-2e83525f3192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Hyperdimension: 5666\n",
      "Accuracy average for 20 rounds: 83.18840579710145\n",
      "\n",
      "==> Hyperdimension: 6333\n",
      "Accuracy average for 20 rounds: 83.55072463768116\n",
      "\n",
      "==> Hyperdimension: 7333\n",
      "Accuracy average for 20 rounds: 83.22463768115942\n",
      "\n",
      "==> Hyperdimension: 8666\n",
      "Accuracy average for 20 rounds: 83.44202898550726\n",
      "\n",
      "==> Hyperdimension: 9666\n",
      "Accuracy average for 20 rounds: 84.27536231884059\n",
      "\n",
      "==> Hyperdimension: 10666\n",
      "Accuracy average for 20 rounds: 83.65942028985508\n",
      "\n",
      "==> Hyperdimension: 12000\n",
      "Accuracy average for 20 rounds: 83.8768115942029\n",
      "\n",
      "==> Hyperdimension: 13000\n",
      "Accuracy average for 20 rounds: 83.29710144927536\n",
      "\n",
      "==> Hyperdimension: 13666\n",
      "Accuracy average for 20 rounds: 83.51449275362319\n",
      "\n",
      "==> Hyperdimension: 14666\n",
      "Accuracy average for 20 rounds: 84.38405797101449\n",
      "\n",
      "==> Hyperdimension: 16000\n",
      "Accuracy average for 20 rounds: 83.91304347826085\n"
     ]
    }
   ],
   "source": [
    "for i, D in enumerate(hyperdims):\n",
    "    print(f\"\\n==> Hyperdimension: {D}\")\n",
    "    for split_idx in range(n_splits):\n",
    "        # Dynamically get input dimension\n",
    "        input_dim = X_train_tensor.shape[1] \n",
    "        n_keys = 64                   \n",
    "        position_table  = lookup_generate(D, 'bipolar', input_dim, device=device)\n",
    "        grayscale_table = lookup_generate(D, 'bipolar', n_keys, device=device)\n",
    "        am = train_am_batched(\n",
    "            X_train_tensor, y_train_tensor,\n",
    "            position_table, grayscale_table,\n",
    "            dim=D,\n",
    "            batch_size=1,\n",
    "            device=device\n",
    "        )\n",
    "        indices = list(range(len(X_test_tensor)))\n",
    "        np.random.shuffle(indices)  # or random.shuffle(indices)\n",
    "        am_q = quantize(am, before_bw=16, after_bw=q_bit)\n",
    "        acc = test_split_batched(\n",
    "            am_q,\n",
    "            X_test_tensor,\n",
    "            y_test_tensor,\n",
    "            # X_test_tensor,\n",
    "            # y_test_tensor,\n",
    "            position_table,\n",
    "            grayscale_table,\n",
    "            encode_batch,  \n",
    "            batch_size=10,\n",
    "            device=device\n",
    "        )\n",
    "        accuracies[i, split_idx] = acc*100\n",
    "\n",
    "    print(\"Accuracy average for 20 rounds:\", accuracies[i].mean())\n",
    "\n",
    "    # Free GPU memory\n",
    "    del position_table, grayscale_table, am, am_q\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "add588f2-29f3-42b3-a87e-b30f34ab1935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([83.1884058 , 83.55072464, 83.22463768, 83.44202899, 84.27536232,\n",
       "       83.65942029, 83.87681159, 83.29710145, 83.51449275, 84.38405797,\n",
       "       83.91304348])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a04b8e16-c91a-43b6-b62d-a9ac02676db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat(f'{dataset_name}_VanillaHDC.mat', {f'{dataset_name}_VanillaHDC': accuracies})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcdac05b-eb44-4f73-bb47-87eb805aea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8130429 , 1.43287826, 1.28150284, 1.30182929, 0.94758673,\n",
       "       1.2440786 , 1.02158494, 1.30585662, 1.31387423, 1.22279254,\n",
       "       1.4051246 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84236d48-41f2-4c68-8880-649b2e97e66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b69b851-55f7-40d6-a309-4bb3fb2265f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets import load_classification\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat, savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc09c28c-1e2c-4c1f-9490-acd1ee5fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_name = 'Epilepsy'\n",
    "try:\n",
    "    NHDC = loadmat(f'../{dataset_name}_nHD.mat')[f'{dataset_name}_nHD']\n",
    "    hyperdims = np.mean(NHDC, axis=1, dtype=int)\n",
    "\n",
    "except:\n",
    "    hyperdims = range(1000, 5500, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a8d126-bd31-4614-9598-303feb4cb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Epilepsy'\n",
    "# Load dataset\n",
    "X_train, y_train, metadata = load_classification(dataset_name, return_metadata=True, split='train')\n",
    "X_test, y_test = load_classification(dataset_name, split='test')\n",
    "if X_train.shape[0] < 200:\n",
    "    if X_test.shape[0] >= 200:\n",
    "        train_size = (X_train.shape[0] + X_test.shape[0]) * 1/4\n",
    "        x, y = load_classification(dataset_name)\n",
    "        X_train, y_train = x[:train_size, :], y[:train_size]\n",
    "        X_test, y_test = x[train_size:, :], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c546a0-c91b-48f6-ad06-d2a5ab0f8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "if X_train.ndim == 3:\n",
    "    input_channels = X_train.shape[1]\n",
    "seq_length = X_train.shape[-1]\n",
    "if y_train.dtype == object or isinstance(y_train[0], str):\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11cb8221-2fc5-48dd-899a-86bafc78c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "\n",
    "X_min = X_train_scaled.min(axis=0)\n",
    "X_max = X_train_scaled.max(axis=0)\n",
    "\n",
    "denom = (X_max - X_min)\n",
    "denom[denom == 0] = 1   # avoid division by zero\n",
    "\n",
    "X_train_norm = (X_train_scaled - X_min) / denom\n",
    "X_test_norm  = (X_test_scaled  - X_min) / denom\n",
    "\n",
    "# Optional: clip to [0,1] just in case\n",
    "X_train_norm = np.clip(X_train_norm, 0, 1)\n",
    "X_test_norm  = np.clip(X_test_norm, 0, 1)\n",
    "X_train_tensor = torch.tensor(X_train_norm, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_norm, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5603b7e3-1ea5-4492-a686-623fc080cdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137, 3, 206), (137, 618), torch.Size([137, 618]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_scaled.shape, X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9690abbb-bd05-4f5e-afa3-06967631dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "493da6c1-cb45-47ac-88cb-4916a19b02b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0') tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(X_train_tensor), torch.max(X_train_tensor))\n",
    "\n",
    "B = X_train_tensor.shape[1]    \n",
    "C = len(torch.unique(y_train_tensor))        # 10 classes\n",
    "n_rounds = 5\n",
    "\n",
    "# 3. HDC utility functions\n",
    "\n",
    "def generate_base_HDVs(D, B, device):\n",
    "    \"\"\"Generate a (B Ã— D) random binary matrix.\"\"\"\n",
    "    return (torch.rand(B, D, device=device) > 0.5).int()  # intTensor of 0/1\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_dataset_batched(X, base_HDVs, batch_size=128):\n",
    "    \"\"\"\n",
    "    Encode X in chunks to avoid OOM.\n",
    "    X:          (N, B) floatTensor {0,1}\n",
    "    base_HDVs:  (B, D) intTensor {0,1}\n",
    "    returns:    (N, D) intTensor {0,1}\n",
    "    \"\"\"\n",
    "    N, B = X.shape\n",
    "    D    = base_HDVs.shape[1]\n",
    "\n",
    "    # Precompute roll-shifted HDVs once\n",
    "    perm_HDVs = base_HDVs.roll(shifts=1, dims=1)  # (B, D)\n",
    "\n",
    "    # Expand for broadcasting\n",
    "    base = base_HDVs.unsqueeze(0)   # (1, B, D)\n",
    "    perm = perm_HDVs.unsqueeze(0)   # (1, B, D)\n",
    "\n",
    "    chunks = []\n",
    "    for i in (range(0, N, batch_size)):\n",
    "        xb    = X[i : i+batch_size].to(base_HDVs.device)           # (b, B)\n",
    "        xb_exp= xb.unsqueeze(-1)              # (b, B, 1)\n",
    "\n",
    "        # When pixel==1 pick perm, else pick base\n",
    "        weighted = xb_exp * perm + (1 - xb_exp) * base  # (b, B, D)\n",
    "        H_float  = weighted.mean(dim=1)                 # (b, D)\n",
    "        chunks.append(torch.round(H_float).int())       # (b, D)\n",
    "\n",
    "    return torch.cat(chunks, dim=0)  # (N, D)\n",
    "\n",
    "def encode_class_HDVs(H_train, y_train, C):\n",
    "    \"\"\"\n",
    "    Bundle all train-HDVs per class.\n",
    "    H_train: (N, D), y_train: (N,)\n",
    "    returns: (C, D)\n",
    "    \"\"\"\n",
    "    class_HDVs = []\n",
    "    for c in range(C):\n",
    "        subset = H_train[y_train == c]        # (Nc, D)\n",
    "        m      = subset.float().mean(dim=0)   # (D,)\n",
    "        class_HDVs.append(torch.round(m).int())\n",
    "    return torch.stack(class_HDVs, dim=0)    # (C, D)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(H_test, class_HDVs):\n",
    "    \"\"\"\n",
    "    Nearest-neighbor by Hamming distance.\n",
    "    H_test:     (M, D), class_HDVs: (C, D)\n",
    "    returns:    (M,) predicted labels\n",
    "    \"\"\"\n",
    "    diffs = H_test.unsqueeze(1) != class_HDVs.unsqueeze(0)  # (M, C, D)\n",
    "    dists = diffs.sum(dim=2)                                # (M, C)\n",
    "    return dists.argmin(dim=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e933d059-c1b0-4ac5-a518-71ab27853106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Hyperdimension: 5666\n",
      "Average accuracy: 48.2609 for Hyperdim 5666\n",
      "\n",
      "==> Hyperdimension: 6333\n",
      "Average accuracy: 47.8986 for Hyperdim 6333\n",
      "\n",
      "==> Hyperdimension: 7333\n",
      "Average accuracy: 47.7174 for Hyperdim 7333\n",
      "\n",
      "==> Hyperdimension: 8666\n",
      "Average accuracy: 48.7319 for Hyperdim 8666\n",
      "\n",
      "==> Hyperdimension: 9666\n",
      "Average accuracy: 47.9710 for Hyperdim 9666\n",
      "\n",
      "==> Hyperdimension: 10666\n",
      "Average accuracy: 48.4420 for Hyperdim 10666\n",
      "\n",
      "==> Hyperdimension: 12000\n",
      "Average accuracy: 48.6594 for Hyperdim 12000\n",
      "\n",
      "==> Hyperdimension: 13000\n",
      "Average accuracy: 49.0580 for Hyperdim 13000\n",
      "\n",
      "==> Hyperdimension: 13666\n",
      "Average accuracy: 48.6957 for Hyperdim 13666\n",
      "\n",
      "==> Hyperdimension: 14666\n",
      "Average accuracy: 48.8406 for Hyperdim 14666\n",
      "\n",
      "==> Hyperdimension: 16000\n",
      "Average accuracy: 49.1304 for Hyperdim 16000\n"
     ]
    }
   ],
   "source": [
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 10\n",
    "n_splits = 20\n",
    "split_size = len(test_data) // n_splits \n",
    "accuracies = np.zeros((len(hyperdims), n_splits), dtype=float)\n",
    "for idx, D in enumerate(hyperdims):\n",
    "    print(f\"\\n==> Hyperdimension: {D}\")\n",
    "    for split_idx in range(n_splits):        \n",
    "        base_HDVs  = generate_base_HDVs(D, B, device)\n",
    "        H_train    = encode_dataset_batched(X_train_tensor, base_HDVs, batch_size)\n",
    "        class_HDVs = encode_class_HDVs(H_train, y_train_tensor, C)\n",
    "        Xs, ys = X_test_tensor, y_test_tensor\n",
    "\n",
    "        Hs    = encode_dataset_batched(Xs, base_HDVs, batch_size)\n",
    "        preds = predict(Hs, class_HDVs)\n",
    "    \n",
    "        accuracies[idx, split_idx] = (preds.cpu() == ys.cpu()).float().mean().item() * 100\n",
    "        # print(f'Accuracy for split index {i}: {accuracies[idx, i]}')\n",
    "\n",
    "    print(f\"Average accuracy: {accuracies[idx].mean().item():.4f} for Hyperdim {D}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fae22027-14d9-43c0-9d68-bc98499a97ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48.26086998, 47.89855123, 47.7173917 , 48.73188436, 47.97101498,\n",
       "       48.44202936, 48.65942061, 49.05797124, 48.69565248, 48.84057999,\n",
       "       49.13043499])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed3a33d6-7aed-404d-9d30-b857319cce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat(f'{dataset_name}_HoloGN.mat', {f'{dataset_name}_HoloGN': accuracies})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "159e959d-1605-461f-80c3-a77e866df0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.75116567, 1.61871758, 1.62478894, 1.74327665, 0.78045848,\n",
       "       1.41768064, 1.4360809 , 1.53889533, 1.28814381, 1.49211995,\n",
       "       1.13654952])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8da0f7-6086-470f-b488-6e225b32ef48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008281be-1e20-4ebb-bb0d-de9c9705c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.io import savemat, loadmat\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df702028-5f8e-47f7-a4cb-a4e9c468e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3601, 500), Test shape: (1320, 500)\n",
      "tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def load_ucr(file):\n",
    "    data = np.loadtxt(file)\n",
    "    X = data[:, 1:]\n",
    "    y = data[:, 0]\n",
    "    y = np.where(y == 1, 1, 0)  # convert labels to 0/1\n",
    "    return X, y\n",
    "\n",
    "# Adjust file paths to your local files\n",
    "X_train, y_train = load_ucr(\"../FordA_TRAIN.txt\")\n",
    "X_test, y_test = load_ucr(\"../FordA_TEST.txt\")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "min_val = X_train_tensor.min()\n",
    "max_val = X_train_tensor.max()\n",
    "\n",
    "X_train_tensor = (X_train_tensor - min_val) / (max_val - min_val)\n",
    "X_test_tensor = (X_test_tensor - min_val) / (max_val - min_val)\n",
    "\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "print(torch.min(X_train_tensor), torch.max(X_train_tensor))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Generate bipolar lookup table\n",
    "def lookup_generate(dim: int, datatype: str, n_keys: int, device: torch.device):\n",
    "    if datatype != 'bipolar':\n",
    "        raise ValueError(\"Only 'bipolar' supported\")\n",
    "    tbl = torch.randint(0, 2, (n_keys, dim), device=device, dtype=torch.int8)\n",
    "    return tbl * 2 - 1  # map {0,1} → {-1,+1}\n",
    "\n",
    "# 2. Encode a batch of inputs into hypervectors\n",
    "@torch.no_grad()\n",
    "def encode_batch(X: torch.Tensor, position_table: torch.Tensor, grayscale_table: torch.Tensor):\n",
    "    \"\"\"\n",
    "    X:               (N, D_in) float tensor in [-3, +3]\n",
    "    position_table:  (D_in, dim)\n",
    "    grayscale_table: (n_keys, dim)\n",
    "    → returns (N, dim) int tensor\n",
    "    \"\"\"\n",
    "    n_keys = grayscale_table.shape[0]\n",
    "    X_normalized = ((X + 3) / 6) * (n_keys - 1)  # map [-3,3] → [0, n_keys-1]\n",
    "    X_indices = X_normalized.round().clamp(0, n_keys - 1).long()  # indices in [0, n_keys-1]\n",
    "    gray = grayscale_table[X_indices]            # (N, D_in, dim)\n",
    "    pos  = position_table.unsqueeze(0)           # (1, D_in, dim)\n",
    "    hv   = (pos * gray).sum(dim=1)               # (N, dim)\n",
    "    return hv\n",
    "\n",
    "# 3. Train associative memory by summing all encodings per class\n",
    "def train_am(X_train, Y_train, position_table, grayscale_table, dim: int):\n",
    "    H_train = encode_batch(X_train, position_table, grayscale_table).float()  # (N, dim)\n",
    "    C = int(Y_train.max().item()) + 1\n",
    "    am = torch.zeros((C, dim), device=X_train.device, dtype=torch.float32)\n",
    "    am = am.index_add(0, Y_train, H_train)\n",
    "    return am\n",
    "\n",
    "# 4. Single-image prediction (returns class and query HV)\n",
    "@torch.no_grad()\n",
    "def predict_(am, img, position_table, grayscale_table):\n",
    "    qhv = encode_batch(img.unsqueeze(0), position_table, grayscale_table).squeeze(0).float()\n",
    "    sims = F.cosine_similarity(qhv.unsqueeze(0), am, dim=1)  # (C,)\n",
    "    pred = int(sims.argmax().item())\n",
    "    return pred, qhv\n",
    "\n",
    "def predict(am, img, position_table, grayscale_table):\n",
    "    pred, _ = predict_(am, img, position_table, grayscale_table)\n",
    "    return pred\n",
    "\n",
    "# 5. Test on full set\n",
    "@torch.no_grad()\n",
    "def test(am, X_test, Y_test, position_table, grayscale_table):\n",
    "    H_test = encode_batch(X_test, position_table, grayscale_table).float()  # (N_test, dim)\n",
    "    h_norm = H_test.norm(dim=1, keepdim=True)                              # (N,1)\n",
    "    a_norm = am.norm(dim=1, keepdim=True).t()                              # (1,C)\n",
    "    sims   = (H_test @ am.t()) / (h_norm * a_norm)                         # (N,C)\n",
    "    preds  = sims.argmax(dim=1)                                            # (N,)\n",
    "    acc    = (preds == Y_test).float().mean().item()\n",
    "    print(f\"Testing accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "# 6. Load a saved model (AM + tables)\n",
    "def loadmodel(fpath: str, device: torch.device = None):\n",
    "    with open(fpath, 'rb') as f:\n",
    "        am_np, pos_np, gray_np = pickle.load(f)\n",
    "    am   = torch.from_numpy(am_np)\n",
    "    pos  = torch.from_numpy(pos_np)\n",
    "    gray = torch.from_numpy(gray_np)\n",
    "    if device is not None:\n",
    "        am, pos, gray = am.to(device), pos.to(device), gray.to(device)\n",
    "    return am, pos, gray\n",
    "\n",
    "# 7. Quantize the AM to a lower bit-width\n",
    "def quantize(am: torch.Tensor, before_bw: int, after_bw: int) -> torch.Tensor:\n",
    "    if before_bw <= after_bw:\n",
    "        return am.clone()\n",
    "    shift = before_bw - after_bw\n",
    "    return torch.round(am.float() / (2 ** shift)).to(am.dtype)\n",
    "\n",
    "# 8. Batched AM training\n",
    "@torch.no_grad()\n",
    "def train_am_batched(\n",
    "    X_train: torch.Tensor,\n",
    "    Y_train: torch.Tensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    dim: int,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> torch.Tensor:\n",
    "    N = X_train.shape[0]\n",
    "    C = int(Y_train.max().item()) + 1\n",
    "    am = torch.zeros(C, dim, device=device, dtype=torch.float32)\n",
    "    for i in tqdm(range(0, N, batch_size), desc=\"Training batches\"):\n",
    "        xb = X_train[i : i + batch_size]\n",
    "        yb = torch.as_tensor(Y_train[i : i + batch_size], device=device)  # <== ✅ fixed\n",
    "        hb = encode_batch(xb, position_table, grayscale_table).float()\n",
    "        am = am.index_add(0, yb, hb)\n",
    "    return am\n",
    "\n",
    "# 9. Test on a split (non-batched)\n",
    "@torch.no_grad()\n",
    "def test_split(am, X_split, Y_split, position_table, grayscale_table):\n",
    "    Hs   = encode_batch(X_split, position_table, grayscale_table).float()  # (M, dim)\n",
    "    sims = F.cosine_similarity(Hs.unsqueeze(1), am.unsqueeze(0), dim=2)   # (M, C)\n",
    "    preds = sims.argmax(dim=1)                                            # (M,)\n",
    "    return (preds == Y_split).float().mean().item()\n",
    "\n",
    "# 10. Test on a split (batched)\n",
    "@torch.no_grad()\n",
    "def test_split_batched(\n",
    "    am: torch.Tensor,\n",
    "    X: torch.Tensor,\n",
    "    Y: torch.Tensor,\n",
    "    position_table: torch.Tensor,\n",
    "    grayscale_table: torch.Tensor,\n",
    "    encode_fn,\n",
    "    batch_size: int = 128,\n",
    "    device: torch.device = None\n",
    ") -> float:\n",
    "    correct, total = 0, 0\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        xb = X[i : i + batch_size].to(device)\n",
    "        yb = Y[i : i + batch_size].to(device)\n",
    "        hb = encode_fn(xb, position_table, grayscale_table).float()\n",
    "        sims  = F.cosine_similarity(hb.unsqueeze(1), am.unsqueeze(0), dim=2)\n",
    "        preds = sims.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total   += yb.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b6da55-5a3c-46b6-b0f0-39266d1168a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = '../../'\n",
    "fmnist_path = '../../'\n",
    "cifar10_path = '../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bb8dd7-b853-481f-bd21-5073a49aa182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(5000, 21000, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperdims = range(5000, 21000, 1000)\n",
    "hyperdims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d3b43b-d3d4-4293-9200-f39ac4195037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf94b27-a954-4bd2-9130-68ffdffd58e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# X_train, Y_train, X_test, Y_test = load_dataset(cifar10_path, device)\n",
    "\n",
    "n_splits   = 10\n",
    "split_size = X_test.shape[0] // n_splits\n",
    "hyperdims = hyperdims\n",
    "accuracies = np.zeros((len(hyperdims), n_splits))\n",
    "n_class    = 2\n",
    "q_bit      = 16\n",
    "print(split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b686f64-e308-436c-bdcb-6688cf5f24dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(0.))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(X_train_tensor), torch.min(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a308187-2827-4782-aa30-51961733cf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Hyperdimension: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:00<00:00, 4084.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.47727272727272724\n",
      "\n",
      "==> Hyperdimension: 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:00<00:00, 4548.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4871212121212121\n",
      "\n",
      "==> Hyperdimension: 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:00<00:00, 4317.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4962121212121212\n",
      "\n",
      "==> Hyperdimension: 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:00<00:00, 4027.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4840909090909092\n",
      "\n",
      "==> Hyperdimension: 9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:00<00:00, 3795.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.5015151515151516\n",
      "\n",
      "==> Hyperdimension: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 3583.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.5007575757575757\n",
      "\n",
      "==> Hyperdimension: 11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 3365.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.48636363636363633\n",
      "\n",
      "==> Hyperdimension: 12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 3217.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.48106060606060613\n",
      "\n",
      "==> Hyperdimension: 13000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 3062.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4901515151515152\n",
      "\n",
      "==> Hyperdimension: 14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2925.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.49469696969696975\n",
      "\n",
      "==> Hyperdimension: 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2745.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4962121212121212\n",
      "\n",
      "==> Hyperdimension: 16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2696.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.49318181818181817\n",
      "\n",
      "==> Hyperdimension: 17000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2583.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.49015151515151506\n",
      "\n",
      "==> Hyperdimension: 18000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2477.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4962121212121212\n",
      "\n",
      "==> Hyperdimension: 19000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2388.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.48636363636363633\n",
      "\n",
      "==> Hyperdimension: 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 3601/3601 [00:01<00:00, 2310.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average for 20 rounds: 0.4871212121212121\n"
     ]
    }
   ],
   "source": [
    "for i, D in enumerate(hyperdims):\n",
    "    print(f\"\\n==> Hyperdimension: {D}\")\n",
    "    \n",
    "    # Dynamically get input dimension\n",
    "    input_dim = X_train_tensor.shape[1]  # e.g., 3*206\n",
    "    n_keys = 64                   # number of quantization bins for [-3,+3]\n",
    "    \n",
    "    # a) lookup tables\n",
    "    position_table  = lookup_generate(D, 'bipolar', input_dim, device=device)\n",
    "    grayscale_table = lookup_generate(D, 'bipolar', n_keys, device=device)\n",
    "\n",
    "    # b) train AM\n",
    "    am = train_am_batched(\n",
    "        X_train_tensor, y_train_tensor,\n",
    "        position_table, grayscale_table,\n",
    "        dim=D,\n",
    "        batch_size=1,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # c) quantize AM\n",
    "    am_q = quantize(am, before_bw=16, after_bw=q_bit)\n",
    "\n",
    "    # d) evaluate on splits\n",
    "    for split_idx in range(n_splits):\n",
    "        start = split_idx * split_size\n",
    "        end   = start + split_size\n",
    "\n",
    "        acc = test_split_batched(\n",
    "            am_q,\n",
    "            X_test_tensor[start:end],\n",
    "            y_test_tensor[start:end],\n",
    "            position_table,\n",
    "            grayscale_table,\n",
    "            encode_batch,  \n",
    "            batch_size=10,\n",
    "            device=device\n",
    "        )\n",
    "        accuracies[i, split_idx] = acc\n",
    "\n",
    "    print(\"Accuracy average for 20 rounds:\", accuracies[i].mean())\n",
    "\n",
    "    # Free GPU memory\n",
    "    del position_table, grayscale_table, am, am_q\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ed59b5-35d0-4aeb-adf8-284e71efc94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47727273, 0.48712121, 0.49621212, 0.48409091, 0.50151515,\n",
       "       0.50075758, 0.48636364, 0.48106061, 0.49015152, 0.49469697,\n",
       "       0.49621212, 0.49318182, 0.49015152, 0.49621212, 0.48636364,\n",
       "       0.48712121])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f70c68-27d0-4bf5-8536-f61f1c75c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat('FordA_VanillaHDC.mat', {'FordA_VanillaHDC': accuracies*100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2fcf9-710a-487b-83fb-b3cd079aacef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

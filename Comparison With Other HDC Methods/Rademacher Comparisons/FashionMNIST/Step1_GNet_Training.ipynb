{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85fdf28c-f372-4dd7-bd54-a7aa2ed65849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "# from Modules import ConvBN, PoolConvBN, PoolLinearBN, SharpCosSim2d, SharpCosSimLinear, LReLU\n",
    "\n",
    "from ConvBN import ConvBN as ConvBN_BiasTrick\n",
    "from LinearBN import LinearBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748ecd3a-7ffc-4bbb-8694-a567b6e10082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LReLU, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(5.0)) \n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.alpha*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff8a703-c4d7-4c63-98fc-97d8ef46a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize with mean 0.5 and std 0.5\n",
    "])\n",
    "\n",
    "batch_size= 2000\n",
    "num_workers=2\n",
    "pin_memory=True\n",
    "\n",
    "dataset = torchvision.datasets.FashionMNIST(root='../', train=True, download=True, transform=transform)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [58000, 2000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(root='../', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aced529a-d3ba-4a60-980e-2623e755c88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7565906-2310-4a40-b7a7-627f2e2de45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1_out = 32\n",
    "        self.conv1_size = 3\n",
    "        self.conv1_padding = 1\n",
    "\n",
    "\n",
    "        # self.conv2_out = 16\n",
    "        # self.conv2_size = 5\n",
    "        # self.conv2_padding = 0\n",
    "\n",
    "        self.fc1_out = 512\n",
    "        self.fc2_out = 10\n",
    "\n",
    "        self.q = 1e-6\n",
    "        self.bias_trick_par = nn.Parameter(torch.tensor(0.00005))\n",
    "\n",
    "        # First Convolutional Block\n",
    "\n",
    "        self.block1 = ConvBN_BiasTrick(in_channels=1, out_channels=self.conv1_out, kernel_size=self.conv1_size, padding=self.conv1_padding, std = .15)\n",
    "\n",
    "        # Second Convolutional Block\n",
    "       \n",
    "        self.block3 = LinearBN(in_features = self.conv1_out * (28//2) * (28//2), out_features=self.fc1_out, std=.15)\n",
    "        \n",
    "        \n",
    "        # torch.manual_seed(0)\n",
    "        self.w2 = nn.Parameter(torch.randn(self.fc1_out, self.fc2_out))\n",
    "        nn.init.normal_(self.w2, mean=0.0, std=.15)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.dropout2d = nn.Dropout2d(0.25)\n",
    "\n",
    "        self.relu = LReLU()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(self.relu(self.block1(x)), (2,2), padding=0)\n",
    "        x = self.dropout2d(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.relu(self.block3(x))\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = x + self.bias_trick_par\n",
    "        x_norm = x / (x.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize input x\n",
    "        w2_norm = self.w2 / (self.w2.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize weights\n",
    "        x = torch.matmul(x_norm, w2_norm) # Matrix multiplication \n",
    "\n",
    "        # Return raw logits (no softmax here, CrossEntropyLoss handles it)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fab82256-86aa-432f-a31d-a6f210a08745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.00047 accuracy: 0.6783 val loss: 0.00024 val accuracy: 0.8275 time: 5.62 seconds\n",
      "[epoch 2] loss: 0.00021 accuracy: 0.8582 val loss: 0.00018 val accuracy: 0.8770 time: 5.96 seconds\n",
      "[epoch 3] loss: 0.00017 accuracy: 0.8820 val loss: 0.00016 val accuracy: 0.8860 time: 5.65 seconds\n",
      "[epoch 4] loss: 0.00016 accuracy: 0.8911 val loss: 0.00015 val accuracy: 0.8850 time: 5.50 seconds\n",
      "[epoch 5] loss: 0.00014 accuracy: 0.8996 val loss: 0.00015 val accuracy: 0.8865 time: 5.62 seconds\n",
      "[epoch 6] loss: 0.00014 accuracy: 0.9027 val loss: 0.00015 val accuracy: 0.8960 time: 5.62 seconds\n",
      "[epoch 7] loss: 0.00014 accuracy: 0.9028 val loss: 0.00014 val accuracy: 0.9055 time: 5.64 seconds\n",
      "[epoch 8] loss: 0.00013 accuracy: 0.9083 val loss: 0.00013 val accuracy: 0.9025 time: 5.78 seconds\n",
      "[epoch 9] loss: 0.00013 accuracy: 0.9110 val loss: 0.00013 val accuracy: 0.9055 time: 5.82 seconds\n",
      "[epoch 10] loss: 0.00013 accuracy: 0.9101 val loss: 0.00014 val accuracy: 0.8980 time: 5.57 seconds\n",
      "[epoch 11] loss: 0.00013 accuracy: 0.9119 val loss: 0.00013 val accuracy: 0.9015 time: 5.45 seconds\n",
      "[epoch 12] loss: 0.00013 accuracy: 0.9099 val loss: 0.00013 val accuracy: 0.9080 time: 5.58 seconds\n",
      "[epoch 13] loss: 0.00012 accuracy: 0.9161 val loss: 0.00014 val accuracy: 0.9020 time: 5.52 seconds\n",
      "[epoch 14] loss: 0.00013 accuracy: 0.9121 val loss: 0.00014 val accuracy: 0.8975 time: 5.41 seconds\n",
      "[epoch 15] loss: 0.00012 accuracy: 0.9174 val loss: 0.00013 val accuracy: 0.9025 time: 5.45 seconds\n",
      "[epoch 16] loss: 0.00013 accuracy: 0.9106 val loss: 0.00014 val accuracy: 0.9015 time: 5.43 seconds\n",
      "[epoch 17] loss: 0.00012 accuracy: 0.9158 val loss: 0.00012 val accuracy: 0.9130 time: 5.70 seconds\n",
      "[epoch 18] loss: 0.00012 accuracy: 0.9182 val loss: 0.00014 val accuracy: 0.9025 time: 5.56 seconds\n",
      "[epoch 19] loss: 0.00012 accuracy: 0.9144 val loss: 0.00013 val accuracy: 0.9050 time: 5.45 seconds\n",
      "[epoch 20] loss: 0.00012 accuracy: 0.9168 val loss: 0.00013 val accuracy: 0.9095 time: 5.46 seconds\n",
      "[epoch 21] loss: 0.00012 accuracy: 0.9188 val loss: 0.00014 val accuracy: 0.8935 time: 5.40 seconds\n",
      "[epoch 22] loss: 0.00012 accuracy: 0.9169 val loss: 0.00013 val accuracy: 0.9085 time: 5.52 seconds\n",
      "[epoch 23] loss: 0.00012 accuracy: 0.9187 val loss: 0.00012 val accuracy: 0.9075 time: 5.48 seconds\n",
      "[epoch 24] loss: 0.00012 accuracy: 0.9172 val loss: 0.00014 val accuracy: 0.9020 time: 5.46 seconds\n",
      "[epoch 25] loss: 0.00012 accuracy: 0.9169 val loss: 0.00013 val accuracy: 0.9090 time: 5.48 seconds\n",
      "[epoch 26] loss: 0.00012 accuracy: 0.9187 val loss: 0.00013 val accuracy: 0.9030 time: 5.50 seconds\n",
      "[epoch 27] loss: 0.00012 accuracy: 0.9212 val loss: 0.00013 val accuracy: 0.9075 time: 5.42 seconds\n",
      "[epoch 28] loss: 0.00012 accuracy: 0.9209 val loss: 0.00013 val accuracy: 0.9100 time: 5.48 seconds\n",
      "[epoch 29] loss: 0.00010 accuracy: 0.9344 val loss: 0.00012 val accuracy: 0.9145 time: 5.60 seconds\n",
      "[epoch 30] loss: 0.00009 accuracy: 0.9461 val loss: 0.00011 val accuracy: 0.9180 time: 5.68 seconds\n",
      "[epoch 31] loss: 0.00008 accuracy: 0.9503 val loss: 0.00011 val accuracy: 0.9215 time: 5.73 seconds\n",
      "[epoch 32] loss: 0.00008 accuracy: 0.9547 val loss: 0.00011 val accuracy: 0.9200 time: 5.50 seconds\n",
      "[epoch 33] loss: 0.00007 accuracy: 0.9568 val loss: 0.00012 val accuracy: 0.9210 time: 5.56 seconds\n",
      "[epoch 34] loss: 0.00007 accuracy: 0.9581 val loss: 0.00011 val accuracy: 0.9220 time: 5.68 seconds\n",
      "[epoch 35] loss: 0.00007 accuracy: 0.9606 val loss: 0.00011 val accuracy: 0.9205 time: 5.45 seconds\n",
      "[epoch 36] loss: 0.00007 accuracy: 0.9632 val loss: 0.00011 val accuracy: 0.9240 time: 5.62 seconds\n",
      "[epoch 37] loss: 0.00007 accuracy: 0.9639 val loss: 0.00011 val accuracy: 0.9235 time: 5.46 seconds\n",
      "[epoch 38] loss: 0.00006 accuracy: 0.9663 val loss: 0.00011 val accuracy: 0.9205 time: 5.51 seconds\n",
      "[epoch 39] loss: 0.00006 accuracy: 0.9667 val loss: 0.00012 val accuracy: 0.9170 time: 5.52 seconds\n",
      "[epoch 40] loss: 0.00006 accuracy: 0.9681 val loss: 0.00011 val accuracy: 0.9245 time: 5.65 seconds\n",
      "[epoch 41] loss: 0.00006 accuracy: 0.9679 val loss: 0.00011 val accuracy: 0.9200 time: 5.47 seconds\n",
      "[epoch 42] loss: 0.00006 accuracy: 0.9697 val loss: 0.00011 val accuracy: 0.9170 time: 5.42 seconds\n",
      "[epoch 43] loss: 0.00006 accuracy: 0.9695 val loss: 0.00011 val accuracy: 0.9195 time: 5.51 seconds\n",
      "[epoch 44] loss: 0.00006 accuracy: 0.9706 val loss: 0.00012 val accuracy: 0.9210 time: 5.50 seconds\n",
      "[epoch 45] loss: 0.00006 accuracy: 0.9718 val loss: 0.00012 val accuracy: 0.9190 time: 5.40 seconds\n",
      "[epoch 46] loss: 0.00006 accuracy: 0.9715 val loss: 0.00012 val accuracy: 0.9165 time: 5.43 seconds\n",
      "[epoch 47] loss: 0.00006 accuracy: 0.9737 val loss: 0.00011 val accuracy: 0.9220 time: 5.50 seconds\n",
      "[epoch 48] loss: 0.00006 accuracy: 0.9738 val loss: 0.00011 val accuracy: 0.9230 time: 5.48 seconds\n",
      "[epoch 49] loss: 0.00005 accuracy: 0.9797 val loss: 0.00011 val accuracy: 0.9215 time: 5.44 seconds\n",
      "[epoch 50] loss: 0.00005 accuracy: 0.9821 val loss: 0.00011 val accuracy: 0.9250 time: 5.58 seconds\n",
      "[epoch 51] loss: 0.00004 accuracy: 0.9830 val loss: 0.00011 val accuracy: 0.9215 time: 5.56 seconds\n",
      "[epoch 52] loss: 0.00004 accuracy: 0.9832 val loss: 0.00011 val accuracy: 0.9230 time: 5.48 seconds\n",
      "[epoch 53] loss: 0.00004 accuracy: 0.9837 val loss: 0.00011 val accuracy: 0.9215 time: 5.44 seconds\n",
      "[epoch 54] loss: 0.00004 accuracy: 0.9842 val loss: 0.00011 val accuracy: 0.9220 time: 5.48 seconds\n",
      "[epoch 55] loss: 0.00004 accuracy: 0.9852 val loss: 0.00011 val accuracy: 0.9225 time: 5.49 seconds\n",
      "[epoch 56] loss: 0.00004 accuracy: 0.9849 val loss: 0.00011 val accuracy: 0.9220 time: 5.47 seconds\n",
      "[epoch 57] loss: 0.00004 accuracy: 0.9852 val loss: 0.00011 val accuracy: 0.9240 time: 5.59 seconds\n",
      "[epoch 58] loss: 0.00004 accuracy: 0.9860 val loss: 0.00011 val accuracy: 0.9220 time: 5.47 seconds\n",
      "[epoch 59] loss: 0.00004 accuracy: 0.9855 val loss: 0.00011 val accuracy: 0.9225 time: 5.52 seconds\n",
      "[epoch 60] loss: 0.00004 accuracy: 0.9870 val loss: 0.00011 val accuracy: 0.9215 time: 5.51 seconds\n",
      "[epoch 61] loss: 0.00004 accuracy: 0.9860 val loss: 0.00011 val accuracy: 0.9215 time: 5.54 seconds\n",
      "[epoch 62] loss: 0.00004 accuracy: 0.9867 val loss: 0.00011 val accuracy: 0.9215 time: 5.55 seconds\n",
      "[epoch 63] loss: 0.00004 accuracy: 0.9865 val loss: 0.00011 val accuracy: 0.9210 time: 5.50 seconds\n",
      "[epoch 64] loss: 0.00004 accuracy: 0.9862 val loss: 0.00011 val accuracy: 0.9220 time: 5.59 seconds\n",
      "[epoch 65] loss: 0.00004 accuracy: 0.9865 val loss: 0.00011 val accuracy: 0.9220 time: 5.50 seconds\n",
      "[epoch 66] loss: 0.00004 accuracy: 0.9867 val loss: 0.00011 val accuracy: 0.9215 time: 5.67 seconds\n",
      "[epoch 67] loss: 0.00004 accuracy: 0.9866 val loss: 0.00011 val accuracy: 0.9210 time: 5.49 seconds\n",
      "[epoch 68] loss: 0.00004 accuracy: 0.9867 val loss: 0.00011 val accuracy: 0.9210 time: 5.61 seconds\n",
      "[epoch 69] loss: 0.00004 accuracy: 0.9868 val loss: 0.00011 val accuracy: 0.9215 time: 5.60 seconds\n",
      "[epoch 70] loss: 0.00004 accuracy: 0.9870 val loss: 0.00011 val accuracy: 0.9205 time: 5.84 seconds\n",
      "[epoch 71] loss: 0.00004 accuracy: 0.9869 val loss: 0.00011 val accuracy: 0.9215 time: 5.44 seconds\n",
      "[epoch 72] loss: 0.00004 accuracy: 0.9869 val loss: 0.00011 val accuracy: 0.9215 time: 5.81 seconds\n",
      "[epoch 73] loss: 0.00004 accuracy: 0.9868 val loss: 0.00011 val accuracy: 0.9220 time: 5.60 seconds\n",
      "[epoch 74] loss: 0.00004 accuracy: 0.9872 val loss: 0.00011 val accuracy: 0.9220 time: 5.50 seconds\n",
      "[epoch 75] loss: 0.00004 accuracy: 0.9862 val loss: 0.00011 val accuracy: 0.9215 time: 5.69 seconds\n",
      "[epoch 76] loss: 0.00004 accuracy: 0.9869 val loss: 0.00011 val accuracy: 0.9220 time: 5.66 seconds\n",
      "[epoch 77] loss: 0.00004 accuracy: 0.9867 val loss: 0.00011 val accuracy: 0.9220 time: 5.57 seconds\n",
      "[epoch 78] loss: 0.00004 accuracy: 0.9862 val loss: 0.00011 val accuracy: 0.9220 time: 5.54 seconds\n",
      "[epoch 79] loss: 0.00004 accuracy: 0.9862 val loss: 0.00011 val accuracy: 0.9220 time: 5.56 seconds\n",
      "[epoch 80] loss: 0.00004 accuracy: 0.9873 val loss: 0.00011 val accuracy: 0.9220 time: 5.66 seconds\n",
      "[epoch 81] loss: 0.00004 accuracy: 0.9864 val loss: 0.00011 val accuracy: 0.9215 time: 5.41 seconds\n",
      "[epoch 82] loss: 0.00004 accuracy: 0.9871 val loss: 0.00011 val accuracy: 0.9215 time: 5.50 seconds\n",
      "[epoch 83] loss: 0.00004 accuracy: 0.9866 val loss: 0.00011 val accuracy: 0.9215 time: 5.48 seconds\n",
      "[epoch 84] loss: 0.00004 accuracy: 0.9866 val loss: 0.00011 val accuracy: 0.9215 time: 5.79 seconds\n",
      "[epoch 85] loss: 0.00004 accuracy: 0.9871 val loss: 0.00011 val accuracy: 0.9215 time: 5.53 seconds\n",
      "[epoch 86] loss: 0.00004 accuracy: 0.9866 val loss: 0.00011 val accuracy: 0.9215 time: 5.47 seconds\n",
      "[epoch 87] loss: 0.00004 accuracy: 0.9868 val loss: 0.00011 val accuracy: 0.9215 time: 5.55 seconds\n",
      "[epoch 88] loss: 0.00004 accuracy: 0.9867 val loss: 0.00011 val accuracy: 0.9215 time: 5.45 seconds\n",
      "[epoch 89] loss: 0.00004 accuracy: 0.9870 val loss: 0.00011 val accuracy: 0.9215 time: 5.49 seconds\n",
      "[epoch 90] loss: 0.00004 accuracy: 0.9871 val loss: 0.00011 val accuracy: 0.9215 time: 5.49 seconds\n",
      "[epoch 91] loss: 0.00004 accuracy: 0.9866 val loss: 0.00011 val accuracy: 0.9215 time: 5.43 seconds\n",
      "[epoch 92] loss: 0.00004 accuracy: 0.9865 val loss: 0.00011 val accuracy: 0.9215 time: 5.44 seconds\n",
      "[epoch 93] loss: 0.00004 accuracy: 0.9869 val loss: 0.00011 val accuracy: 0.9215 time: 5.47 seconds\n",
      "[epoch 94] loss: 0.00004 accuracy: 0.9871 val loss: 0.00011 val accuracy: 0.9215 time: 5.47 seconds\n",
      "[epoch 95] loss: 0.00004 accuracy: 0.9866 val loss: 0.00011 val accuracy: 0.9215 time: 5.48 seconds\n",
      "[epoch 96] loss: 0.00004 accuracy: 0.9863 val loss: 0.00011 val accuracy: 0.9215 time: 5.45 seconds\n",
      "[epoch 97] loss: 0.00004 accuracy: 0.9864 val loss: 0.00011 val accuracy: 0.9215 time: 5.47 seconds\n",
      "[epoch 98] loss: 0.00004 accuracy: 0.9865 val loss: 0.00011 val accuracy: 0.9215 time: 5.44 seconds\n",
      "[epoch 99] loss: 0.00004 accuracy: 0.9871 val loss: 0.00011 val accuracy: 0.9215 time: 5.52 seconds\n",
      "[epoch 100] loss: 0.00004 accuracy: 0.9863 val loss: 0.00011 val accuracy: 0.9215 time: 5.48 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time  # Import time module\n",
    "\n",
    "train = True\n",
    "model = Network().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Trained 100 Epochs with lr=0.025, 50 epochs with 0.005 and 50 epochs with 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.025, weight_decay=0.00001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "if train:\n",
    "    \n",
    "    loss_hist, acc_hist = [], []\n",
    "    loss_hist_val, acc_hist_val = [], []\n",
    "    \n",
    "    # Initialize variable to track the lowest validation accuracy\n",
    "    best_val_acc = -float('inf')  # Set to negative infinity initially to track the maximum accuracy\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        start_time = time.time()  # Record the start time of the epoch\n",
    "    \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        for data in train_loader:\n",
    "            batch, labels = data\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Compute training statistics\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "        avg_loss = running_loss / len(train_set)\n",
    "        avg_acc = correct / len(train_set)\n",
    "        loss_hist.append(avg_loss)\n",
    "        acc_hist.append(avg_acc)\n",
    "    \n",
    "        # Validation statistics\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.0\n",
    "            correct_val = 0\n",
    "            for data in val_loader:\n",
    "                batch, labels = data\n",
    "                batch, labels = batch.to(device), labels.to(device)\n",
    "                outputs = model(batch)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                loss_val += loss.item()\n",
    "            avg_loss_val = loss_val / len(val_set)\n",
    "            avg_acc_val = correct_val / len(val_set)\n",
    "            loss_hist_val.append(avg_loss_val)\n",
    "            acc_hist_val.append(avg_acc_val)\n",
    "        model.train()\n",
    "    \n",
    "        scheduler.step(avg_loss_val)\n",
    "    \n",
    "        # Check if the current validation accuracy is the best we've seen\n",
    "        if avg_acc_val > best_val_acc:\n",
    "            best_val_acc = avg_acc_val\n",
    "            # Save the model with the highest validation accuracy\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                torch.save(model.module.state_dict(), 'best_model_fashionmnist.pt')\n",
    "            else:\n",
    "                torch.save(model.state_dict(), 'best_model_fashionmnist.pt')\n",
    "    \n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.time() - start_time  # Calculate the time taken for this epoch\n",
    "    \n",
    "        print('[epoch %d] loss: %.5f accuracy: %.4f val loss: %.5f val accuracy: %.4f time: %.2f seconds' %\n",
    "              (epoch + 1, avg_loss, avg_acc, avg_loss_val, avg_acc_val, elapsed_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a83be87-bf65-4a82-95b6-89acf3fb356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.00012, Test accuracy: 0.9258\n"
     ]
    }
   ],
   "source": [
    "# Load the best model saved during training\n",
    "# model.load_state_dict(torch.load('best_model_fashionmnist.pt', weights_only=True))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=2000, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Get predictions and update the correct count\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute average loss and accuracy for the test set\n",
    "avg_test_loss = test_loss / len(test_set)\n",
    "avg_test_acc = correct_test / len(test_set)\n",
    "\n",
    "print(f\"Test loss: {avg_test_loss:.5f}, Test accuracy: {avg_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76533a3f-95b0-4a0c-b98a-91062a5a5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Fashionmnist_GNet_Training_92.58.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905783f-98c1-45ed-8a65-9ed6882107c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

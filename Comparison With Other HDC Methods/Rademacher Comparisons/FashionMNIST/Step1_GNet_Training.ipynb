{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fdf28c-f372-4dd7-bd54-a7aa2ed65849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "# from Modules import ConvBN, PoolConvBN, PoolLinearBN, SharpCosSim2d, SharpCosSimLinear, LReLU\n",
    "\n",
    "from ConvBN import ConvBN as ConvBN_BiasTrick\n",
    "from LinearBN import LinearBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748ecd3a-7ffc-4bbb-8694-a567b6e10082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LReLU, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(5.0)) \n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.alpha*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff8a703-c4d7-4c63-98fc-97d8ef46a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize with mean 0.5 and std 0.5\n",
    "])\n",
    "\n",
    "batch_size= 2000\n",
    "num_workers=2\n",
    "pin_memory=True\n",
    "\n",
    "dataset = torchvision.datasets.FashionMNIST(root='../', train=True, download=True, transform=transform)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [58000, 2000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(root='../', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aced529a-d3ba-4a60-980e-2623e755c88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7565906-2310-4a40-b7a7-627f2e2de45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1_out = 32\n",
    "        self.conv1_size = 3\n",
    "        self.conv1_padding = 1\n",
    "\n",
    "\n",
    "        # self.conv2_out = 16\n",
    "        # self.conv2_size = 5\n",
    "        # self.conv2_padding = 0\n",
    "\n",
    "        self.fc1_out = 512\n",
    "        self.fc2_out = 10\n",
    "\n",
    "        self.q = 1e-6\n",
    "        self.bias_trick_par = nn.Parameter(torch.tensor(0.00005))\n",
    "\n",
    "        # First Convolutional Block\n",
    "\n",
    "        self.block1 = ConvBN_BiasTrick(in_channels=1, out_channels=self.conv1_out, kernel_size=self.conv1_size, padding=self.conv1_padding, std = .15)\n",
    "\n",
    "        # Second Convolutional Block\n",
    "       \n",
    "        self.block3 = LinearBN(in_features = self.conv1_out * (28//2) * (28//2), out_features=self.fc1_out, std=.25)\n",
    "        \n",
    "        \n",
    "        self.w2 = nn.Parameter(torch.randn(self.fc1_out, self.fc2_out))\n",
    "        nn.init.normal_(self.w2, mean=0.0, std=.15)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.dropout2d = nn.Dropout2d(0.25)\n",
    "\n",
    "        self.relu = LReLU()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(self.relu(self.block1(x)), (2,2), padding=0)\n",
    "        x = self.dropout2d(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.relu(self.block3(x))\n",
    "        # x = self.dropout(x)\n",
    "\n",
    "        x = x + self.bias_trick_par\n",
    "        x_norm = x / (x.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize input x\n",
    "        w2_norm = self.w2 / (self.w2.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize weights\n",
    "        x = torch.matmul(x_norm, w2_norm) # Matrix multiplication \n",
    "\n",
    "        # Return raw logits (no softmax here, CrossEntropyLoss handles it)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fab82256-86aa-432f-a31d-a6f210a08745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.00043 accuracy: 0.7014 val loss: 0.00023 val accuracy: 0.8455 time: 4.73 seconds\n",
      "[epoch 2] loss: 0.00021 accuracy: 0.8618 val loss: 0.00017 val accuracy: 0.8755 time: 4.74 seconds\n",
      "[epoch 3] loss: 0.00017 accuracy: 0.8819 val loss: 0.00015 val accuracy: 0.8890 time: 4.71 seconds\n",
      "[epoch 4] loss: 0.00015 accuracy: 0.8934 val loss: 0.00014 val accuracy: 0.8965 time: 4.78 seconds\n",
      "[epoch 5] loss: 0.00015 accuracy: 0.8986 val loss: 0.00013 val accuracy: 0.9075 time: 4.75 seconds\n",
      "[epoch 6] loss: 0.00015 accuracy: 0.8981 val loss: 0.00013 val accuracy: 0.9035 time: 4.82 seconds\n",
      "[epoch 7] loss: 0.00013 accuracy: 0.9065 val loss: 0.00013 val accuracy: 0.9100 time: 4.85 seconds\n",
      "[epoch 8] loss: 0.00013 accuracy: 0.9090 val loss: 0.00012 val accuracy: 0.9160 time: 4.78 seconds\n",
      "[epoch 9] loss: 0.00013 accuracy: 0.9092 val loss: 0.00012 val accuracy: 0.9130 time: 4.68 seconds\n",
      "[epoch 10] loss: 0.00013 accuracy: 0.9111 val loss: 0.00012 val accuracy: 0.9185 time: 4.84 seconds\n",
      "[epoch 11] loss: 0.00013 accuracy: 0.9091 val loss: 0.00013 val accuracy: 0.9090 time: 4.72 seconds\n",
      "[epoch 12] loss: 0.00013 accuracy: 0.9122 val loss: 0.00012 val accuracy: 0.9180 time: 4.80 seconds\n",
      "[epoch 13] loss: 0.00013 accuracy: 0.9131 val loss: 0.00012 val accuracy: 0.9190 time: 4.72 seconds\n",
      "[epoch 14] loss: 0.00013 accuracy: 0.9109 val loss: 0.00012 val accuracy: 0.9115 time: 4.65 seconds\n",
      "[epoch 15] loss: 0.00013 accuracy: 0.9138 val loss: 0.00012 val accuracy: 0.9130 time: 4.77 seconds\n",
      "[epoch 16] loss: 0.00013 accuracy: 0.9091 val loss: 0.00012 val accuracy: 0.9105 time: 4.74 seconds\n",
      "[epoch 17] loss: 0.00012 accuracy: 0.9145 val loss: 0.00012 val accuracy: 0.9170 time: 4.64 seconds\n",
      "[epoch 18] loss: 0.00013 accuracy: 0.9142 val loss: 0.00013 val accuracy: 0.9100 time: 4.74 seconds\n",
      "[epoch 19] loss: 0.00012 accuracy: 0.9133 val loss: 0.00012 val accuracy: 0.9135 time: 4.70 seconds\n",
      "[epoch 20] loss: 0.00012 accuracy: 0.9144 val loss: 0.00012 val accuracy: 0.9155 time: 4.65 seconds\n",
      "[epoch 21] loss: 0.00012 accuracy: 0.9153 val loss: 0.00012 val accuracy: 0.9120 time: 4.69 seconds\n",
      "[epoch 22] loss: 0.00013 accuracy: 0.9117 val loss: 0.00012 val accuracy: 0.9150 time: 4.73 seconds\n",
      "[epoch 23] loss: 0.00012 accuracy: 0.9155 val loss: 0.00012 val accuracy: 0.9115 time: 4.73 seconds\n",
      "[epoch 24] loss: 0.00010 accuracy: 0.9319 val loss: 0.00011 val accuracy: 0.9250 time: 4.76 seconds\n",
      "[epoch 25] loss: 0.00009 accuracy: 0.9416 val loss: 0.00011 val accuracy: 0.9250 time: 4.72 seconds\n",
      "[epoch 26] loss: 0.00009 accuracy: 0.9464 val loss: 0.00010 val accuracy: 0.9235 time: 4.73 seconds\n",
      "[epoch 27] loss: 0.00008 accuracy: 0.9511 val loss: 0.00010 val accuracy: 0.9275 time: 4.71 seconds\n",
      "[epoch 28] loss: 0.00008 accuracy: 0.9520 val loss: 0.00011 val accuracy: 0.9250 time: 4.97 seconds\n",
      "[epoch 29] loss: 0.00008 accuracy: 0.9549 val loss: 0.00010 val accuracy: 0.9300 time: 4.76 seconds\n",
      "[epoch 30] loss: 0.00007 accuracy: 0.9572 val loss: 0.00010 val accuracy: 0.9310 time: 4.82 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time  # Import time module\n",
    "\n",
    "train = True\n",
    "model = Network().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Trained 100 Epochs with lr=0.025, 50 epochs with 0.005 and 50 epochs with 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.025, weight_decay=0.00001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "if train:\n",
    "    \n",
    "    loss_hist, acc_hist = [], []\n",
    "    loss_hist_val, acc_hist_val = [], []\n",
    "    \n",
    "    # Initialize variable to track the lowest validation accuracy\n",
    "    best_val_acc = -float('inf')  # Set to negative infinity initially to track the maximum accuracy\n",
    "    \n",
    "    for epoch in range(30):\n",
    "        start_time = time.time()  # Record the start time of the epoch\n",
    "    \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        for data in train_loader:\n",
    "            batch, labels = data\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Compute training statistics\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "        avg_loss = running_loss / len(train_set)\n",
    "        avg_acc = correct / len(train_set)\n",
    "        loss_hist.append(avg_loss)\n",
    "        acc_hist.append(avg_acc)\n",
    "    \n",
    "        # Validation statistics\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.0\n",
    "            correct_val = 0\n",
    "            for data in val_loader:\n",
    "                batch, labels = data\n",
    "                batch, labels = batch.to(device), labels.to(device)\n",
    "                outputs = model(batch)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                loss_val += loss.item()\n",
    "            avg_loss_val = loss_val / len(val_set)\n",
    "            avg_acc_val = correct_val / len(val_set)\n",
    "            loss_hist_val.append(avg_loss_val)\n",
    "            acc_hist_val.append(avg_acc_val)\n",
    "        model.train()\n",
    "    \n",
    "        scheduler.step(avg_loss_val)\n",
    "    \n",
    "        # Check if the current validation accuracy is the best we've seen\n",
    "        if avg_acc_val > best_val_acc:\n",
    "            best_val_acc = avg_acc_val\n",
    "            # Save the model with the highest validation accuracy\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                torch.save(model.module.state_dict(), 'best_model_fashionmnist.pt')\n",
    "            else:\n",
    "                torch.save(model.state_dict(), 'best_model_fashionmnist.pt')\n",
    "    \n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.time() - start_time  # Calculate the time taken for this epoch\n",
    "    \n",
    "        print('[epoch %d] loss: %.5f accuracy: %.4f val loss: %.5f val accuracy: %.4f time: %.2f seconds' %\n",
    "              (epoch + 1, avg_loss, avg_acc, avg_loss_val, avg_acc_val, elapsed_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a83be87-bf65-4a82-95b6-89acf3fb356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.00012, Test accuracy: 0.9214\n"
     ]
    }
   ],
   "source": [
    "# Load the best model saved during training\n",
    "# model.load_state_dict(torch.load('best_model_fashionmnist.pt', weights_only=True))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=2000, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Get predictions and update the correct count\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute average loss and accuracy for the test set\n",
    "avg_test_loss = test_loss / len(test_set)\n",
    "avg_test_acc = correct_test / len(test_set)\n",
    "\n",
    "print(f\"Test loss: {avg_test_loss:.5f}, Test accuracy: {avg_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76533a3f-95b0-4a0c-b98a-91062a5a5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Fashionmnist_GNet_Training.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1905783f-98c1-45ed-8a65-9ed6882107c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(5.7197, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.relu.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b89e98f-18ee-44f7-b9d6-bb51f45b889f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(0.9152, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.block1.bias_trick_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73df69e8-870f-46e3-821d-345d4f26750d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(-0.0180, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias_trick_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9828ff6-0347-4838-bddf-569fadf6a6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0aa16-9624-44e4-92fc-bdd1ae53b97c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

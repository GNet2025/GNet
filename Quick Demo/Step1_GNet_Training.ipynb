{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fdf28c-f372-4dd7-bd54-a7aa2ed65849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "from ConvBN import ConvBN as ConvBN\n",
    "from LinearBN import LinearBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62f4095-da17-4568-b6ae-098b4b69ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(43)\n",
    "np.random.seed(43)\n",
    "torch.manual_seed(43)\n",
    "torch.cuda.manual_seed_all(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748ecd3a-7ffc-4bbb-8694-a567b6e10082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LReLU, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(5.0)) \n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.alpha*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff8a703-c4d7-4c63-98fc-97d8ef46a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize with mean 0.5 and std 0.5\n",
    "])\n",
    "\n",
    "batch_size= 1500\n",
    "num_workers=2\n",
    "pin_memory=True\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root='../Data', train=True, download=True, transform=transform)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [58000, 2000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory, generator=g)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='../Data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aced529a-d3ba-4a60-980e-2623e755c88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7565906-2310-4a40-b7a7-627f2e2de45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1_out = 32\n",
    "        self.conv1_size = 3\n",
    "        self.conv1_padding = 1\n",
    "\n",
    "\n",
    "        self.conv2_out = 64\n",
    "        self.conv2_size = 5\n",
    "        self.conv2_padding = 2\n",
    "\n",
    "        self.fc1_out = 512\n",
    "        self.fc2_out = 10\n",
    "\n",
    "        self.q = 1e-6\n",
    "        self.bias_trick_par = nn.Parameter(torch.tensor(0.00005))\n",
    "\n",
    "        # First Convolutional Block\n",
    "\n",
    "        self.block1 = ConvBN(in_channels=1, out_channels=self.conv1_out, kernel_size=self.conv1_size, padding=self.conv1_padding, std = .05)\n",
    "        self.block2 = ConvBN(in_channels=self.conv1_out, out_channels=self.conv2_out, kernel_size=self.conv2_size, padding=self.conv2_padding, std = .05)\n",
    "\n",
    "        # Second Convolutional Block\n",
    "       \n",
    "        self.block3 = LinearBN(in_features = self.conv2_out * (28//2//2) * (28//2//2), out_features=self.fc1_out, std=.3)\n",
    "        \n",
    "        \n",
    "        torch.manual_seed(0)\n",
    "        self.w2 = nn.Parameter(torch.randn(self.fc1_out, self.fc2_out))\n",
    "        nn.init.normal_(self.w2, mean=0.0, std=.6)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.relu = LReLU()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(self.relu(self.block1(x)), (2,2), padding=0)\n",
    "        x = F.max_pool2d(self.relu(self.block2(x)), (2,2), padding=0)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.relu(self.block3(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x + self.bias_trick_par\n",
    "        x_norm = x / (x.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize input x\n",
    "        w2_norm = self.w2 / (self.w2.norm(p=2, dim=1, keepdim=True) + self.q)  # Normalize weights\n",
    "        x = torch.matmul(x_norm, w2_norm) # Matrix multiplication \n",
    "\n",
    "        # Return raw logits (no softmax here, CrossEntropyLoss handles it)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fab82256-86aa-432f-a31d-a6f210a08745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 0.00069 accuracy: 0.7182 val loss: 0.00017 val accuracy: 0.9550 time: 6.04 seconds\n",
      "[epoch 2] loss: 0.00013 accuracy: 0.9723 val loss: 0.00008 val accuracy: 0.9805 time: 4.62 seconds\n",
      "[epoch 3] loss: 0.00008 accuracy: 0.9863 val loss: 0.00005 val accuracy: 0.9880 time: 4.85 seconds\n",
      "[epoch 4] loss: 0.00007 accuracy: 0.9893 val loss: 0.00005 val accuracy: 0.9875 time: 4.76 seconds\n",
      "[epoch 5] loss: 0.00006 accuracy: 0.9912 val loss: 0.00004 val accuracy: 0.9865 time: 4.82 seconds\n",
      "[epoch 6] loss: 0.00007 accuracy: 0.9900 val loss: 0.00006 val accuracy: 0.9850 time: 4.82 seconds\n",
      "[epoch 7] loss: 0.00006 accuracy: 0.9920 val loss: 0.00005 val accuracy: 0.9885 time: 4.79 seconds\n",
      "[epoch 8] loss: 0.00005 accuracy: 0.9934 val loss: 0.00005 val accuracy: 0.9880 time: 4.91 seconds\n",
      "[epoch 9] loss: 0.00005 accuracy: 0.9929 val loss: 0.00005 val accuracy: 0.9890 time: 4.80 seconds\n",
      "[epoch 10] loss: 0.00008 accuracy: 0.9828 val loss: 0.00012 val accuracy: 0.9690 time: 4.96 seconds\n",
      "[epoch 11] loss: 0.00008 accuracy: 0.9814 val loss: 0.00005 val accuracy: 0.9870 time: 4.85 seconds\n",
      "[epoch 12] loss: 0.00005 accuracy: 0.9911 val loss: 0.00004 val accuracy: 0.9900 time: 4.83 seconds\n",
      "[epoch 13] loss: 0.00005 accuracy: 0.9928 val loss: 0.00004 val accuracy: 0.9900 time: 4.75 seconds\n",
      "[epoch 14] loss: 0.00010 accuracy: 0.9750 val loss: 0.00008 val accuracy: 0.9765 time: 4.78 seconds\n",
      "[epoch 15] loss: 0.00007 accuracy: 0.9866 val loss: 0.00005 val accuracy: 0.9885 time: 4.71 seconds\n",
      "[epoch 16] loss: 0.00005 accuracy: 0.9918 val loss: 0.00005 val accuracy: 0.9875 time: 4.72 seconds\n",
      "[epoch 17] loss: 0.00005 accuracy: 0.9935 val loss: 0.00004 val accuracy: 0.9865 time: 4.80 seconds\n",
      "[epoch 18] loss: 0.00005 accuracy: 0.9945 val loss: 0.00005 val accuracy: 0.9885 time: 4.76 seconds\n",
      "[epoch 19] loss: 0.00005 accuracy: 0.9948 val loss: 0.00004 val accuracy: 0.9900 time: 4.83 seconds\n",
      "[epoch 20] loss: 0.00005 accuracy: 0.9948 val loss: 0.00004 val accuracy: 0.9885 time: 4.72 seconds\n",
      "[epoch 21] loss: 0.00009 accuracy: 0.9764 val loss: 0.00017 val accuracy: 0.9570 time: 4.90 seconds\n",
      "[epoch 22] loss: 0.00009 accuracy: 0.9793 val loss: 0.00006 val accuracy: 0.9835 time: 4.79 seconds\n",
      "[epoch 23] loss: 0.00006 accuracy: 0.9901 val loss: 0.00005 val accuracy: 0.9870 time: 4.78 seconds\n",
      "[epoch 24] loss: 0.00005 accuracy: 0.9911 val loss: 0.00004 val accuracy: 0.9875 time: 4.80 seconds\n",
      "[epoch 25] loss: 0.00004 accuracy: 0.9948 val loss: 0.00004 val accuracy: 0.9890 time: 4.91 seconds\n",
      "[epoch 26] loss: 0.00004 accuracy: 0.9965 val loss: 0.00004 val accuracy: 0.9895 time: 4.78 seconds\n",
      "[epoch 27] loss: 0.00004 accuracy: 0.9970 val loss: 0.00004 val accuracy: 0.9890 time: 4.70 seconds\n",
      "[epoch 28] loss: 0.00004 accuracy: 0.9974 val loss: 0.00004 val accuracy: 0.9900 time: 4.71 seconds\n",
      "[epoch 29] loss: 0.00004 accuracy: 0.9978 val loss: 0.00004 val accuracy: 0.9900 time: 4.87 seconds\n",
      "[epoch 30] loss: 0.00004 accuracy: 0.9980 val loss: 0.00004 val accuracy: 0.9895 time: 4.91 seconds\n",
      "[epoch 31] loss: 0.00003 accuracy: 0.9983 val loss: 0.00004 val accuracy: 0.9900 time: 4.80 seconds\n",
      "[epoch 32] loss: 0.00003 accuracy: 0.9985 val loss: 0.00004 val accuracy: 0.9895 time: 4.85 seconds\n",
      "[epoch 33] loss: 0.00003 accuracy: 0.9986 val loss: 0.00004 val accuracy: 0.9900 time: 4.83 seconds\n",
      "[epoch 34] loss: 0.00003 accuracy: 0.9986 val loss: 0.00004 val accuracy: 0.9895 time: 5.08 seconds\n",
      "[epoch 35] loss: 0.00003 accuracy: 0.9989 val loss: 0.00004 val accuracy: 0.9895 time: 4.80 seconds\n",
      "[epoch 36] loss: 0.00003 accuracy: 0.9991 val loss: 0.00004 val accuracy: 0.9895 time: 4.82 seconds\n",
      "[epoch 37] loss: 0.00003 accuracy: 0.9991 val loss: 0.00004 val accuracy: 0.9900 time: 4.87 seconds\n",
      "[epoch 38] loss: 0.00003 accuracy: 0.9991 val loss: 0.00004 val accuracy: 0.9900 time: 4.73 seconds\n",
      "[epoch 39] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9900 time: 4.78 seconds\n",
      "[epoch 40] loss: 0.00003 accuracy: 0.9991 val loss: 0.00004 val accuracy: 0.9900 time: 4.90 seconds\n",
      "[epoch 41] loss: 0.00003 accuracy: 0.9991 val loss: 0.00004 val accuracy: 0.9900 time: 4.76 seconds\n",
      "[epoch 42] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9895 time: 4.79 seconds\n",
      "[epoch 43] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9895 time: 4.83 seconds\n",
      "[epoch 44] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9900 time: 4.82 seconds\n",
      "[epoch 45] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9895 time: 4.78 seconds\n",
      "[epoch 46] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.78 seconds\n",
      "[epoch 47] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.89 seconds\n",
      "[epoch 48] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.80 seconds\n",
      "[epoch 49] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.80 seconds\n",
      "[epoch 50] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.79 seconds\n",
      "[epoch 51] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.79 seconds\n",
      "[epoch 52] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.85 seconds\n",
      "[epoch 53] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.72 seconds\n",
      "[epoch 54] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.79 seconds\n",
      "[epoch 55] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.89 seconds\n",
      "[epoch 56] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.73 seconds\n",
      "[epoch 57] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.74 seconds\n",
      "[epoch 58] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.70 seconds\n",
      "[epoch 59] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.75 seconds\n",
      "[epoch 60] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.70 seconds\n",
      "[epoch 61] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.79 seconds\n",
      "[epoch 62] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.77 seconds\n",
      "[epoch 63] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.82 seconds\n",
      "[epoch 64] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.80 seconds\n",
      "[epoch 65] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.73 seconds\n",
      "[epoch 66] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.79 seconds\n",
      "[epoch 67] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.83 seconds\n",
      "[epoch 68] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.83 seconds\n",
      "[epoch 69] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.79 seconds\n",
      "[epoch 70] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.79 seconds\n",
      "[epoch 71] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.88 seconds\n",
      "[epoch 72] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.78 seconds\n",
      "[epoch 73] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.95 seconds\n",
      "[epoch 74] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.77 seconds\n",
      "[epoch 75] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.85 seconds\n",
      "[epoch 76] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.74 seconds\n",
      "[epoch 77] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.74 seconds\n",
      "[epoch 78] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.73 seconds\n",
      "[epoch 79] loss: 0.00003 accuracy: 0.9993 val loss: 0.00004 val accuracy: 0.9890 time: 4.90 seconds\n",
      "[epoch 80] loss: 0.00003 accuracy: 0.9992 val loss: 0.00004 val accuracy: 0.9890 time: 4.71 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time  # Import time module\n",
    "\n",
    "train = True\n",
    "model = Network().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.025, weight_decay=0.00001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "if train:\n",
    "    \n",
    "    loss_hist, acc_hist = [], []\n",
    "    loss_hist_val, acc_hist_val = [], []\n",
    "    \n",
    "    best_val_acc = -float('inf')  \n",
    "    \n",
    "    for epoch in range(80):\n",
    "        start_time = time.time()  \n",
    "    \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        for data in train_loader:\n",
    "            batch, labels = data\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Compute training statistics\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "        avg_loss = running_loss / len(train_set)\n",
    "        avg_acc = correct / len(train_set)\n",
    "        loss_hist.append(avg_loss)\n",
    "        acc_hist.append(avg_acc)\n",
    "    \n",
    "        # Validation statistics\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.0\n",
    "            correct_val = 0\n",
    "            for data in val_loader:\n",
    "                batch, labels = data\n",
    "                batch, labels = batch.to(device), labels.to(device)\n",
    "                outputs = model(batch)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                loss_val += loss.item()\n",
    "            avg_loss_val = loss_val / len(val_set)\n",
    "            avg_acc_val = correct_val / len(val_set)\n",
    "            loss_hist_val.append(avg_loss_val)\n",
    "            acc_hist_val.append(avg_acc_val)\n",
    "        model.train()\n",
    "    \n",
    "        scheduler.step(avg_loss_val)\n",
    "    \n",
    "        if avg_acc_val > best_val_acc:\n",
    "            best_val_acc = avg_acc_val\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                torch.save(model.module.state_dict(), 'best_model_mnist.pt')\n",
    "            else:\n",
    "                torch.save(model.state_dict(), 'best_model_mnist.pt')\n",
    "    \n",
    "        elapsed_time = time.time() - start_time \n",
    "    \n",
    "        print('[epoch %d] loss: %.5f accuracy: %.4f val loss: %.5f val accuracy: %.4f time: %.2f seconds' %\n",
    "              (epoch + 1, avg_loss, avg_acc, avg_loss_val, avg_acc_val, elapsed_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a83be87-bf65-4a82-95b6-89acf3fb356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.00002, Test accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=2000, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Get predictions and update the correct count\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute average loss and accuracy for the test set\n",
    "avg_test_loss = test_loss / len(test_set)\n",
    "avg_test_acc = correct_test / len(test_set)\n",
    "\n",
    "print(f\"Test loss: {avg_test_loss:.5f}, Test accuracy: {avg_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4543d09-eeda-4d63-bb0b-2ed70bd18758",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MNIST_GNet_Training_99.30.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be5560-e2ef-44a9-bc44-63f3df2dd0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
